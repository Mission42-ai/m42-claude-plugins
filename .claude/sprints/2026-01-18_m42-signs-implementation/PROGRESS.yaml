sprint-id: 2026-01-18_m42-signs-implementation
status: in-progress
phases:
  - id: preflight
    status: completed
    prompt: >
      Create comprehensive sprint context that ALL subsequent phases will reference.


      ## Your Task

      Analyze the entire sprint scope and generate shared context documents.


      ## Step 1: Create Sprint Branch

      ```bash

      git checkout -b sprint/2026-01-18_m42-signs-implementation 2>/dev/null || git checkout sprint/2026-01-18_m42-signs-implementation

      ```


      ## Step 2: Analyze Sprint Scope

      Read SPRINT.yaml to understand:

      - All steps and their relationships

      - Overall sprint goal

      - Technical requirements across all steps

      - Potential dependencies between steps


      ## Step 3: Research Project Context

      Investigate the codebase to understand:

      - Project architecture and structure

      - Key patterns and conventions used

      - Relevant types and interfaces

      - Build/test/lint commands

      - Dependencies (internal modules, external packages)


      ## Step 4: Generate Shared Context

      Create: context/_shared-context.md


      ```markdown

      # Shared Sprint Context


      ## Project Architecture

      [High-level architecture overview relevant to this sprint]


      ## Key Patterns

      - [Pattern 1]: [Where and how it's used]

      - [Pattern 2]: [Where and how it's used]

      ...


      ## Conventions

      - Naming: [Naming conventions]

      - File structure: [File organization patterns]

      - Testing: [Testing patterns and frameworks]

      - Error handling: [Error handling patterns]


      ## Commands

      - Build: `[build command]`

      - Test: `[test command]`

      - Lint: `[lint command]`

      - TypeCheck: `[typecheck command]`


      ## Dependencies

      ### Internal Modules

      - [Module]: [Purpose]


      ### External Packages

      - [Package]: [Usage]


      ## Types and Interfaces

      [Key types relevant to this sprint]

      ```


      ## Step 5: Generate Sprint Plan

      Create: context/sprint-plan.md


      ```markdown

      # Sprint Plan: 2026-01-18_m42-signs-implementation


      ## Goal

      [One paragraph describing what this sprint accomplishes]


      ## Success Criteria

      - [ ] [Measurable criterion 1]

      - [ ] [Measurable criterion 2]

      ...


      ## Step Breakdown


      ### Step 0: [Step title from prompt]

      **Scope**: [What this step does]

      **Files**: [Expected files to create/modify]

      **Dependencies**: [What it depends on]

      **Risk**: Low/Medium/High - [reason]


      ### Step 1: ...

      [Continue for all steps]


      ## Step Dependency Graph

      ```

      step-0 → step-1 → step-2





























































































































































                ↓
              step-3
      ```

      [Or describe dependencies textually]


      ## Risk Assessment

      | Risk | Impact | Mitigation |

      |------|--------|------------|

      | [Risk 1] | [Impact] | [How to mitigate] |


      ## Estimated Complexity

      | Step | Complexity | Reason |

      |------|------------|--------|

      | step-0 | Low/Medium/High | [Brief reason] |

      ```


      ## Output

      - Sprint branch created/checked out

      - context/_shared-context.md with project patterns

      - context/sprint-plan.md with step analysis

      - Commit preflight artifacts:





























































































































































        ```bash
        git add context/
        git commit -m "preflight: add shared context and sprint plan"
        ```
    started-at: "2026-01-17T23:59:16Z"
    completed-at: "2026-01-18T00:02:30Z"
    elapsed: 00:03:14
  - id: development
    status: in-progress
    steps:
      - id: step-0
        prompt: |
          ## Phase 1.1: Plugin Structure Setup

          Create the basic plugin structure for m42-signs:

          ### Tasks
          1. Create .claude-plugin/plugin.json with:
             - Plugin metadata (name: "m42-signs", version: "0.1.0")
             - Author, description, keywords
             - NOTE: Commands and skills are auto-discovered, not declared in plugin.json

          2. Create minimal README.md with:
             - One-line description
             - Installation instructions
             - Link to docs/ for detailed documentation (placeholder for now)

          3. Create directory structure:
             - commands/ (for command definitions)
             - skills/managing-signs/ (skill directory)
               - SKILL.md (main skill file with frontmatter)
               - references/ (reference documentation)
               - assets/ (templates)
             - scripts/ (for utility scripts)
             - docs/ (for user documentation - will be populated later)

          ### Success Criteria
          - Plugin structure follows m42-sprint patterns
          - plugin.json is valid JSON with proper metadata
          - README links to docs/ folder
          - Skill directory has correct structure
        status: completed
        phases:
          - id: plan
            status: completed
            prompt: |
              Generate binary-verifiable gherkin scenarios for this step.

              ## Your Task
              ## Phase 1.1: Plugin Structure Setup

              Create the basic plugin structure for m42-signs:

              ### Tasks
              1. Create .claude-plugin/plugin.json with:
                 - Plugin metadata (name: "m42-signs", version: "0.1.0")
                 - Author, description, keywords
                 - NOTE: Commands and skills are auto-discovered, not declared in plugin.json

              2. Create minimal README.md with:
                 - One-line description
                 - Installation instructions
                 - Link to docs/ for detailed documentation (placeholder for now)

              3. Create directory structure:
                 - commands/ (for command definitions)
                 - skills/managing-signs/ (skill directory)
                   - SKILL.md (main skill file with frontmatter)
                   - references/ (reference documentation)
                   - assets/ (templates)
                 - scripts/ (for utility scripts)
                 - docs/ (for user documentation - will be populated later)

              ### Success Criteria
              - Plugin structure follows m42-sprint patterns
              - plugin.json is valid JSON with proper metadata
              - README links to docs/ folder
              - Skill directory has correct structure


              ## Shared Context
              Read: context/_shared-context.md (project patterns, conventions, commands)
              Read: context/sprint-plan.md (how this step fits in the sprint)

              ## Instructions
              Create 4-8 gherkin scenarios that, when ALL pass, prove the step is complete.
              Each scenario MUST have:
              1. Clear Given/When/Then structure
              2. An explicit verification command that returns exit code 0 on success
              3. Binary outcome: exactly 1 (pass) or 0 (fail)

              ## Gherkin Format
              Each scenario follows this exact structure:

              ```gherkin
              Scenario: [Descriptive name]
                Given [precondition or context]
                When [action taken]
                Then [expected outcome]

              Verification: `[shell command that exits 0 on success, non-zero on failure]`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ## Example Scenarios

              ### File Existence
              ```gherkin
              Scenario: Source file exists
                Given the project structure is set up
                When I check for the module file
                Then src/auth/service.ts exists

              Verification: `test -f src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### TypeScript Compilation
              ```gherkin
              Scenario: TypeScript compiles without errors
                Given the file src/auth/service.ts exists
                When I run the TypeScript compiler
                Then no compilation errors occur

              Verification: `npx tsc --noEmit src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Function Export
              ```gherkin
              Scenario: Login function is exported
                Given src/auth/service.ts exists
                When I check for the login export
                Then the function is publicly available

              Verification: `grep -q "export.*function login\|export.*const login\|export { login" src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### Test Execution
              ```gherkin
              Scenario: Unit tests pass
                Given tests exist in src/auth/service.test.ts
                When I run the test suite
                Then all tests pass

              Verification: `npm test -- --testPathPattern="auth/service" --passWithNoTests 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Lint Check
              ```gherkin
              Scenario: Code passes linting
                Given the implementation is complete
                When I run the linter
                Then no lint errors in new files

              Verification: `npm run lint -- src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ## Output
              Create: artifacts/step-0-gherkin.md

              ```markdown
              # Gherkin Scenarios: step-0

              ## Step Task
              ## Phase 1.1: Plugin Structure Setup

              Create the basic plugin structure for m42-signs:

              ### Tasks
              1. Create .claude-plugin/plugin.json with:
                 - Plugin metadata (name: "m42-signs", version: "0.1.0")
                 - Author, description, keywords
                 - NOTE: Commands and skills are auto-discovered, not declared in plugin.json

              2. Create minimal README.md with:
                 - One-line description
                 - Installation instructions
                 - Link to docs/ for detailed documentation (placeholder for now)

              3. Create directory structure:
                 - commands/ (for command definitions)
                 - skills/managing-signs/ (skill directory)
                   - SKILL.md (main skill file with frontmatter)
                   - references/ (reference documentation)
                   - assets/ (templates)
                 - scripts/ (for utility scripts)
                 - docs/ (for user documentation - will be populated later)

              ### Success Criteria
              - Plugin structure follows m42-sprint patterns
              - plugin.json is valid JSON with proper metadata
              - README links to docs/ folder
              - Skill directory has correct structure


              ## Success Criteria
              All scenarios must pass (score = 1) for the step to be complete.
              Total scenarios: [N]
              Required score: [N]/[N]

              ---

              ## Scenario 1: [Name]
              [Full gherkin with verification as shown above]

              ---

              ## Scenario 2: [Name]
              ...

              [Continue for 4-8 scenarios]
              ```

              ## Commit
              ```bash
              git add artifacts/step-0-gherkin.md
              git commit -m "plan(step-0): define gherkin scenarios"
              ```
            started-at: "2026-01-18T00:02:34Z"
            completed-at: "2026-01-18T00:03:31Z"
            elapsed: 00:00:57
          - id: context
            status: completed
            prompt: |
              Gather step-specific context for implementation.

              ## Your Task
              ## Phase 1.1: Plugin Structure Setup

              Create the basic plugin structure for m42-signs:

              ### Tasks
              1. Create .claude-plugin/plugin.json with:
                 - Plugin metadata (name: "m42-signs", version: "0.1.0")
                 - Author, description, keywords
                 - NOTE: Commands and skills are auto-discovered, not declared in plugin.json

              2. Create minimal README.md with:
                 - One-line description
                 - Installation instructions
                 - Link to docs/ for detailed documentation (placeholder for now)

              3. Create directory structure:
                 - commands/ (for command definitions)
                 - skills/managing-signs/ (skill directory)
                   - SKILL.md (main skill file with frontmatter)
                   - references/ (reference documentation)
                   - assets/ (templates)
                 - scripts/ (for utility scripts)
                 - docs/ (for user documentation - will be populated later)

              ### Success Criteria
              - Plugin structure follows m42-sprint patterns
              - plugin.json is valid JSON with proper metadata
              - README links to docs/ folder
              - Skill directory has correct structure


              ## Shared Context
              Read: context/_shared-context.md (already has project-wide patterns)
              Read: artifacts/step-0-gherkin.md (scenarios to implement)

              ## Instructions
              Research the specific code areas this step will touch:

              1. **Related Existing Code**
                 - Find similar implementations to follow as patterns
                 - Identify modules this step will import from
                 - Note any interfaces/types to implement or extend

              2. **Dependencies**
                 - List imports needed from internal modules
                 - List any new external packages needed
                 - Check for peer dependencies or version constraints

              3. **Integration Points**
                 - How will this code be called/used?
                 - What modules will import from this step's output?
                 - Are there existing tests to extend?

              4. **Specific Patterns**
                 - Error handling patterns used in similar code
                 - Naming conventions for this area
                 - File organization patterns

              ## Output
              Create: context/step-0-context.md

              ```markdown
              # Step Context: step-0

              ## Task
              ## Phase 1.1: Plugin Structure Setup

              Create the basic plugin structure for m42-signs:

              ### Tasks
              1. Create .claude-plugin/plugin.json with:
                 - Plugin metadata (name: "m42-signs", version: "0.1.0")
                 - Author, description, keywords
                 - NOTE: Commands and skills are auto-discovered, not declared in plugin.json

              2. Create minimal README.md with:
                 - One-line description
                 - Installation instructions
                 - Link to docs/ for detailed documentation (placeholder for now)

              3. Create directory structure:
                 - commands/ (for command definitions)
                 - skills/managing-signs/ (skill directory)
                   - SKILL.md (main skill file with frontmatter)
                   - references/ (reference documentation)
                   - assets/ (templates)
                 - scripts/ (for utility scripts)
                 - docs/ (for user documentation - will be populated later)

              ### Success Criteria
              - Plugin structure follows m42-sprint patterns
              - plugin.json is valid JSON with proper metadata
              - README links to docs/ folder
              - Skill directory has correct structure


              ## Related Code Patterns

              ### Similar Implementation: [path]
              ```typescript
              // Key pattern to follow
              [relevant code snippet]
              ```

              ### Similar Implementation: [path]
              [continue as needed]

              ## Required Imports
              ### Internal
              - `[module]`: [what to import]

              ### External
              - `[package]`: [what to import]

              ## Types/Interfaces to Use
              ```typescript
              // From [source]
              interface [Name] {
                [relevant fields]
              }
              ```

              ## Integration Points
              - Called by: [who will use this]
              - Calls: [what this will call]
              - Tests: [related test files]

              ## Implementation Notes
              - [Specific note 1]
              - [Specific note 2]
              ```

              ## Commit
              ```bash
              git add context/step-0-context.md
              git commit -m "context(step-0): gather implementation context"
              ```
            started-at: "2026-01-18T00:03:34Z"
            completed-at: "2026-01-18T00:04:44Z"
            elapsed: 00:01:10
          - id: execute
            status: completed
            prompt: |
              Implement the step following gherkin scenarios and context.

              ## Your Task
              ## Phase 1.1: Plugin Structure Setup

              Create the basic plugin structure for m42-signs:

              ### Tasks
              1. Create .claude-plugin/plugin.json with:
                 - Plugin metadata (name: "m42-signs", version: "0.1.0")
                 - Author, description, keywords
                 - NOTE: Commands and skills are auto-discovered, not declared in plugin.json

              2. Create minimal README.md with:
                 - One-line description
                 - Installation instructions
                 - Link to docs/ for detailed documentation (placeholder for now)

              3. Create directory structure:
                 - commands/ (for command definitions)
                 - skills/managing-signs/ (skill directory)
                   - SKILL.md (main skill file with frontmatter)
                   - references/ (reference documentation)
                   - assets/ (templates)
                 - scripts/ (for utility scripts)
                 - docs/ (for user documentation - will be populated later)

              ### Success Criteria
              - Plugin structure follows m42-sprint patterns
              - plugin.json is valid JSON with proper metadata
              - README links to docs/ folder
              - Skill directory has correct structure


              ## MUST READ BEFORE IMPLEMENTING
              Read these files in order:
              1. context/_shared-context.md (project patterns, conventions)
              2. context/sprint-plan.md (how this fits in sprint)
              3. artifacts/step-0-gherkin.md (scenarios to satisfy)
              4. context/step-0-context.md (specific patterns, imports)

              ## Implementation Rules

              ### Follow the Gherkin
              Your implementation MUST satisfy ALL gherkin scenarios.
              Each scenario has a verification command - mentally run it to check your work.

              ### Follow the Context
              - Use patterns from similar implementations
              - Import from specified modules
              - Implement required interfaces
              - Follow naming conventions

              ### Code Quality
              - Keep code simple and focused
              - Follow existing patterns exactly
              - No over-engineering or extra abstractions
              - Only implement what's needed for the scenarios

              ### Commits
              Make atomic commits for logical units:
              ```bash
              # After each logical piece
              git add [files]
              git commit -m "[type](step-0): [description]"
              ```

              Types: feat, fix, refactor, test, docs

              ## Implementation Checklist
              Before marking complete, verify:
              - [ ] All files from gherkin scenarios exist
              - [ ] Code follows patterns from context
              - [ ] Imports are correct
              - [ ] No TypeScript errors (run typecheck mentally)
              - [ ] Each scenario's verification should pass

              ## If Blocked
              If you encounter an issue that prevents completion:
              - Document the blocker clearly
              - Set status to needs-human
              - Do NOT leave partial/broken implementation
            started-at: "2026-01-18T00:04:48Z"
            completed-at: "2026-01-18T00:06:53Z"
            elapsed: 00:02:05
          - id: qa
            status: completed
            prompt: |
              Verify implementation against gherkin scenarios.

              ## Context
              Read: artifacts/step-0-gherkin.md (scenarios with verification commands)

              ## Step 1: Run Each Verification

              For EACH scenario in the gherkin file:
              1. Run the verification command
              2. Record the result: 1 (pass) or 0 (fail)
              3. If fail, capture the error output

              ## Step 2: Calculate Score

              Score = (passed scenarios) / (total scenarios)
              - Score = 1.0 (all pass) → PASS
              - Score < 1.0 (any fail) → FAIL

              ## Step 3: Generate QA Report

              Create: artifacts/step-0-qa-report.md

              ```markdown
              # QA Report: step-0

              ## Summary
              - Total Scenarios: [N]
              - Passed: [N]
              - Failed: [N]
              - Score: [X]/[N] = [percentage]%

              ## Verification Results

              | # | Scenario | Result | Details |
              |---|----------|--------|---------|
              | 1 | [Name] | PASS/FAIL | [output or error] |
              | 2 | [Name] | PASS/FAIL | [output or error] |
              ...

              ## Detailed Results

              ### Scenario 1: [Name]
              **Verification**: `[command]`
              **Exit Code**: [0 or N]
              **Output**:
              ```
              [actual output]
              ```
              **Result**: PASS / FAIL

              ### Scenario 2: [Name]
              ...

              ## Issues Found
              [If any failures, describe each issue]

              1. **[Scenario name]**: [What failed and why]

              ## Status: PASS / FAIL
              ```

              ## Step 4: Handle Outcome

              ### If ALL scenarios PASS (Score = 100%):
              1. Ensure report shows "Status: PASS"
              2. Commit the report:
                 ```bash
                 git add artifacts/step-0-qa-report.md
                 git commit -m "qa(step-0): all scenarios passed"
                 ```
              3. Mark phase as completed

              ### If ANY scenario FAILS (Score < 100%):
              You MUST inject fix phases. Do NOT just report and continue.

              1. Ensure report shows "Status: FAIL" with specific issues

              2. Find the PROGRESS.yaml file:
                 ```bash
                 PROGRESS_FILE=$(find .claude/sprints -name "PROGRESS.yaml" -type f 2>/dev/null | head -1)
                 echo "Found: $PROGRESS_FILE"
                 ```

              3. Inject fix and re-verify phases using yq:
                 ```bash
                 yq -i '
                   (.phases[] | select(.steps) | .steps[] | select(.status == "in-progress") | .phases) +=
                   [
                     {
                       "id": "fix",
                       "status": "pending",
                       "prompt": "Fix failing scenarios for step-0.\n\n## Context\nRead: artifacts/step-0-qa-report.md\n\n## Instructions\n1. Review each FAIL scenario\n2. Fix the implementation to make it pass\n3. Re-run the verification command to confirm\n4. Make atomic commits for each fix\n\n## After Fixing\nDo NOT mark as complete until ALL verifications pass."
                     },
                     {
                       "id": "reverify",
                       "status": "pending",
                       "prompt": "Re-verify all scenarios after fixes.\n\n## Instructions\nRe-run ALL verification commands from artifacts/step-0-gherkin.md\n\n## If ALL pass:\n- Update artifacts/step-0-qa-report.md with PASS status\n- Commit the updated report\n\n## If ANY still fail:\n- Update the QA report with new results\n- Inject another fix phase using yq\n- Loop continues until all pass"
                     }
                   ]
                 ' "$PROGRESS_FILE"
                 ```

              4. Mark current QA phase as failed:
                 ```bash
                 yq -i '
                   (.. | select(.id == "qa" and .status == "in-progress")) |=
                   (.status = "failed" | .error = "step-0 QA failed - see report - fix phase injected")
                 ' "$PROGRESS_FILE"
                 ```

              5. The sprint loop will now execute fix → reverify phases

              ## Important
              - EVERY scenario must pass for the step to be complete
              - Failed QA MUST inject fix phases, not just report
              - This creates a self-healing loop until all pass
            started-at: "2026-01-18T00:06:58Z"
            completed-at: "2026-01-18T00:08:10Z"
            elapsed: 00:01:12
          - id: verify
            status: completed
            prompt: |
              Final integration verification for the step.

              ## Your Task
              ## Phase 1.1: Plugin Structure Setup

              Create the basic plugin structure for m42-signs:

              ### Tasks
              1. Create .claude-plugin/plugin.json with:
                 - Plugin metadata (name: "m42-signs", version: "0.1.0")
                 - Author, description, keywords
                 - NOTE: Commands and skills are auto-discovered, not declared in plugin.json

              2. Create minimal README.md with:
                 - One-line description
                 - Installation instructions
                 - Link to docs/ for detailed documentation (placeholder for now)

              3. Create directory structure:
                 - commands/ (for command definitions)
                 - skills/managing-signs/ (skill directory)
                   - SKILL.md (main skill file with frontmatter)
                   - references/ (reference documentation)
                   - assets/ (templates)
                 - scripts/ (for utility scripts)
                 - docs/ (for user documentation - will be populated later)

              ### Success Criteria
              - Plugin structure follows m42-sprint patterns
              - plugin.json is valid JSON with proper metadata
              - README links to docs/ folder
              - Skill directory has correct structure


              ## Context
              Read: context/_shared-context.md (build commands)
              Read: artifacts/step-0-qa-report.md (should show PASS)

              ## Step 1: Build Verification
              Run the project build to ensure this step integrates:
              ```bash
              # Use commands from _shared-context.md, typically:
              npm run build
              npm run typecheck
              ```

              ## Step 2: Integration Check
              Verify this step works with the rest of the sprint:
              - Check imports resolve correctly
              - Verify no circular dependencies
              - Ensure types are compatible

              ## Step 3: Smoke Test
              If possible, manually verify the functionality:
              - Run the code path that uses this step's output
              - Check expected behavior matches gherkin scenarios

              ## Step 4: Final Commit
              If all verification passes:
              ```bash
              git add -A
              git status  # Check for any uncommitted changes
              # Only commit if there are changes
              git diff --cached --quiet || git commit -m "verify(step-0): integration verified"
              ```

              ## Outcome
              - If integration passes: Mark step as complete
              - If integration fails: Document the issue and set status to needs-human

              ## Important
              This is the final gate before moving to the next step.
              The step's gherkin scenarios already passed in QA.
              This phase ensures the step works in the broader context.
            started-at: "2026-01-18T00:08:14Z"
            completed-at: "2026-01-18T00:09:18Z"
            elapsed: 00:01:04
      - id: step-1
        prompt: |
          ## Phase 1.2: Backlog Schema and Templates

          Create the learning backlog structure:

          ### Tasks
          1. Create skills/managing-signs/assets/backlog-template.yaml with:
             - Schema version
             - Metadata fields (extracted-from, extracted-at)
             - Empty learnings array
             - Example learning entry (commented)

          2. Create skills/managing-signs/references/backlog-schema.md documenting:
             - All fields and their purpose
             - Status enum values (pending, approved, rejected, applied)
             - Confidence levels (low, medium, high)
             - Source metadata structure
             - Include proper frontmatter (title, description, skill)

          3. Create scripts/validate-backlog.sh to:
             - Check YAML syntax
             - Validate required fields
             - Check status values are valid
             - Ensure target paths exist

          ### Success Criteria
          - Template is valid YAML
          - Reference has proper frontmatter and is LLM-optimized (dense, structured)
          - Validation script catches common errors
        status: completed
        phases:
          - id: plan
            status: completed
            prompt: |
              Generate binary-verifiable gherkin scenarios for this step.

              ## Your Task
              ## Phase 1.2: Backlog Schema and Templates

              Create the learning backlog structure:

              ### Tasks
              1. Create skills/managing-signs/assets/backlog-template.yaml with:
                 - Schema version
                 - Metadata fields (extracted-from, extracted-at)
                 - Empty learnings array
                 - Example learning entry (commented)

              2. Create skills/managing-signs/references/backlog-schema.md documenting:
                 - All fields and their purpose
                 - Status enum values (pending, approved, rejected, applied)
                 - Confidence levels (low, medium, high)
                 - Source metadata structure
                 - Include proper frontmatter (title, description, skill)

              3. Create scripts/validate-backlog.sh to:
                 - Check YAML syntax
                 - Validate required fields
                 - Check status values are valid
                 - Ensure target paths exist

              ### Success Criteria
              - Template is valid YAML
              - Reference has proper frontmatter and is LLM-optimized (dense, structured)
              - Validation script catches common errors


              ## Shared Context
              Read: context/_shared-context.md (project patterns, conventions, commands)
              Read: context/sprint-plan.md (how this step fits in the sprint)

              ## Instructions
              Create 4-8 gherkin scenarios that, when ALL pass, prove the step is complete.
              Each scenario MUST have:
              1. Clear Given/When/Then structure
              2. An explicit verification command that returns exit code 0 on success
              3. Binary outcome: exactly 1 (pass) or 0 (fail)

              ## Gherkin Format
              Each scenario follows this exact structure:

              ```gherkin
              Scenario: [Descriptive name]
                Given [precondition or context]
                When [action taken]
                Then [expected outcome]

              Verification: `[shell command that exits 0 on success, non-zero on failure]`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ## Example Scenarios

              ### File Existence
              ```gherkin
              Scenario: Source file exists
                Given the project structure is set up
                When I check for the module file
                Then src/auth/service.ts exists

              Verification: `test -f src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### TypeScript Compilation
              ```gherkin
              Scenario: TypeScript compiles without errors
                Given the file src/auth/service.ts exists
                When I run the TypeScript compiler
                Then no compilation errors occur

              Verification: `npx tsc --noEmit src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Function Export
              ```gherkin
              Scenario: Login function is exported
                Given src/auth/service.ts exists
                When I check for the login export
                Then the function is publicly available

              Verification: `grep -q "export.*function login\|export.*const login\|export { login" src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### Test Execution
              ```gherkin
              Scenario: Unit tests pass
                Given tests exist in src/auth/service.test.ts
                When I run the test suite
                Then all tests pass

              Verification: `npm test -- --testPathPattern="auth/service" --passWithNoTests 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Lint Check
              ```gherkin
              Scenario: Code passes linting
                Given the implementation is complete
                When I run the linter
                Then no lint errors in new files

              Verification: `npm run lint -- src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ## Output
              Create: artifacts/step-1-gherkin.md

              ```markdown
              # Gherkin Scenarios: step-1

              ## Step Task
              ## Phase 1.2: Backlog Schema and Templates

              Create the learning backlog structure:

              ### Tasks
              1. Create skills/managing-signs/assets/backlog-template.yaml with:
                 - Schema version
                 - Metadata fields (extracted-from, extracted-at)
                 - Empty learnings array
                 - Example learning entry (commented)

              2. Create skills/managing-signs/references/backlog-schema.md documenting:
                 - All fields and their purpose
                 - Status enum values (pending, approved, rejected, applied)
                 - Confidence levels (low, medium, high)
                 - Source metadata structure
                 - Include proper frontmatter (title, description, skill)

              3. Create scripts/validate-backlog.sh to:
                 - Check YAML syntax
                 - Validate required fields
                 - Check status values are valid
                 - Ensure target paths exist

              ### Success Criteria
              - Template is valid YAML
              - Reference has proper frontmatter and is LLM-optimized (dense, structured)
              - Validation script catches common errors


              ## Success Criteria
              All scenarios must pass (score = 1) for the step to be complete.
              Total scenarios: [N]
              Required score: [N]/[N]

              ---

              ## Scenario 1: [Name]
              [Full gherkin with verification as shown above]

              ---

              ## Scenario 2: [Name]
              ...

              [Continue for 4-8 scenarios]
              ```

              ## Commit
              ```bash
              git add artifacts/step-1-gherkin.md
              git commit -m "plan(step-1): define gherkin scenarios"
              ```
            started-at: "2026-01-18T00:09:22Z"
            completed-at: "2026-01-18T00:10:27Z"
            elapsed: 00:01:05
          - id: context
            status: completed
            prompt: |
              Gather step-specific context for implementation.

              ## Your Task
              ## Phase 1.2: Backlog Schema and Templates

              Create the learning backlog structure:

              ### Tasks
              1. Create skills/managing-signs/assets/backlog-template.yaml with:
                 - Schema version
                 - Metadata fields (extracted-from, extracted-at)
                 - Empty learnings array
                 - Example learning entry (commented)

              2. Create skills/managing-signs/references/backlog-schema.md documenting:
                 - All fields and their purpose
                 - Status enum values (pending, approved, rejected, applied)
                 - Confidence levels (low, medium, high)
                 - Source metadata structure
                 - Include proper frontmatter (title, description, skill)

              3. Create scripts/validate-backlog.sh to:
                 - Check YAML syntax
                 - Validate required fields
                 - Check status values are valid
                 - Ensure target paths exist

              ### Success Criteria
              - Template is valid YAML
              - Reference has proper frontmatter and is LLM-optimized (dense, structured)
              - Validation script catches common errors


              ## Shared Context
              Read: context/_shared-context.md (already has project-wide patterns)
              Read: artifacts/step-1-gherkin.md (scenarios to implement)

              ## Instructions
              Research the specific code areas this step will touch:

              1. **Related Existing Code**
                 - Find similar implementations to follow as patterns
                 - Identify modules this step will import from
                 - Note any interfaces/types to implement or extend

              2. **Dependencies**
                 - List imports needed from internal modules
                 - List any new external packages needed
                 - Check for peer dependencies or version constraints

              3. **Integration Points**
                 - How will this code be called/used?
                 - What modules will import from this step's output?
                 - Are there existing tests to extend?

              4. **Specific Patterns**
                 - Error handling patterns used in similar code
                 - Naming conventions for this area
                 - File organization patterns

              ## Output
              Create: context/step-1-context.md

              ```markdown
              # Step Context: step-1

              ## Task
              ## Phase 1.2: Backlog Schema and Templates

              Create the learning backlog structure:

              ### Tasks
              1. Create skills/managing-signs/assets/backlog-template.yaml with:
                 - Schema version
                 - Metadata fields (extracted-from, extracted-at)
                 - Empty learnings array
                 - Example learning entry (commented)

              2. Create skills/managing-signs/references/backlog-schema.md documenting:
                 - All fields and their purpose
                 - Status enum values (pending, approved, rejected, applied)
                 - Confidence levels (low, medium, high)
                 - Source metadata structure
                 - Include proper frontmatter (title, description, skill)

              3. Create scripts/validate-backlog.sh to:
                 - Check YAML syntax
                 - Validate required fields
                 - Check status values are valid
                 - Ensure target paths exist

              ### Success Criteria
              - Template is valid YAML
              - Reference has proper frontmatter and is LLM-optimized (dense, structured)
              - Validation script catches common errors


              ## Related Code Patterns

              ### Similar Implementation: [path]
              ```typescript
              // Key pattern to follow
              [relevant code snippet]
              ```

              ### Similar Implementation: [path]
              [continue as needed]

              ## Required Imports
              ### Internal
              - `[module]`: [what to import]

              ### External
              - `[package]`: [what to import]

              ## Types/Interfaces to Use
              ```typescript
              // From [source]
              interface [Name] {
                [relevant fields]
              }
              ```

              ## Integration Points
              - Called by: [who will use this]
              - Calls: [what this will call]
              - Tests: [related test files]

              ## Implementation Notes
              - [Specific note 1]
              - [Specific note 2]
              ```

              ## Commit
              ```bash
              git add context/step-1-context.md
              git commit -m "context(step-1): gather implementation context"
              ```
            started-at: "2026-01-18T00:10:31Z"
            completed-at: "2026-01-18T00:12:11Z"
            elapsed: 00:01:40
          - id: execute
            status: completed
            prompt: |
              Implement the step following gherkin scenarios and context.

              ## Your Task
              ## Phase 1.2: Backlog Schema and Templates

              Create the learning backlog structure:

              ### Tasks
              1. Create skills/managing-signs/assets/backlog-template.yaml with:
                 - Schema version
                 - Metadata fields (extracted-from, extracted-at)
                 - Empty learnings array
                 - Example learning entry (commented)

              2. Create skills/managing-signs/references/backlog-schema.md documenting:
                 - All fields and their purpose
                 - Status enum values (pending, approved, rejected, applied)
                 - Confidence levels (low, medium, high)
                 - Source metadata structure
                 - Include proper frontmatter (title, description, skill)

              3. Create scripts/validate-backlog.sh to:
                 - Check YAML syntax
                 - Validate required fields
                 - Check status values are valid
                 - Ensure target paths exist

              ### Success Criteria
              - Template is valid YAML
              - Reference has proper frontmatter and is LLM-optimized (dense, structured)
              - Validation script catches common errors


              ## MUST READ BEFORE IMPLEMENTING
              Read these files in order:
              1. context/_shared-context.md (project patterns, conventions)
              2. context/sprint-plan.md (how this fits in sprint)
              3. artifacts/step-1-gherkin.md (scenarios to satisfy)
              4. context/step-1-context.md (specific patterns, imports)

              ## Implementation Rules

              ### Follow the Gherkin
              Your implementation MUST satisfy ALL gherkin scenarios.
              Each scenario has a verification command - mentally run it to check your work.

              ### Follow the Context
              - Use patterns from similar implementations
              - Import from specified modules
              - Implement required interfaces
              - Follow naming conventions

              ### Code Quality
              - Keep code simple and focused
              - Follow existing patterns exactly
              - No over-engineering or extra abstractions
              - Only implement what's needed for the scenarios

              ### Commits
              Make atomic commits for logical units:
              ```bash
              # After each logical piece
              git add [files]
              git commit -m "[type](step-1): [description]"
              ```

              Types: feat, fix, refactor, test, docs

              ## Implementation Checklist
              Before marking complete, verify:
              - [ ] All files from gherkin scenarios exist
              - [ ] Code follows patterns from context
              - [ ] Imports are correct
              - [ ] No TypeScript errors (run typecheck mentally)
              - [ ] Each scenario's verification should pass

              ## If Blocked
              If you encounter an issue that prevents completion:
              - Document the blocker clearly
              - Set status to needs-human
              - Do NOT leave partial/broken implementation
            started-at: "2026-01-18T00:12:15Z"
            completed-at: "2026-01-18T00:16:11Z"
            elapsed: 00:03:56
          - id: qa
            status: completed
            prompt: |
              Verify implementation against gherkin scenarios.

              ## Context
              Read: artifacts/step-1-gherkin.md (scenarios with verification commands)

              ## Step 1: Run Each Verification

              For EACH scenario in the gherkin file:
              1. Run the verification command
              2. Record the result: 1 (pass) or 0 (fail)
              3. If fail, capture the error output

              ## Step 2: Calculate Score

              Score = (passed scenarios) / (total scenarios)
              - Score = 1.0 (all pass) → PASS
              - Score < 1.0 (any fail) → FAIL

              ## Step 3: Generate QA Report

              Create: artifacts/step-1-qa-report.md

              ```markdown
              # QA Report: step-1

              ## Summary
              - Total Scenarios: [N]
              - Passed: [N]
              - Failed: [N]
              - Score: [X]/[N] = [percentage]%

              ## Verification Results

              | # | Scenario | Result | Details |
              |---|----------|--------|---------|
              | 1 | [Name] | PASS/FAIL | [output or error] |
              | 2 | [Name] | PASS/FAIL | [output or error] |
              ...

              ## Detailed Results

              ### Scenario 1: [Name]
              **Verification**: `[command]`
              **Exit Code**: [0 or N]
              **Output**:
              ```
              [actual output]
              ```
              **Result**: PASS / FAIL

              ### Scenario 2: [Name]
              ...

              ## Issues Found
              [If any failures, describe each issue]

              1. **[Scenario name]**: [What failed and why]

              ## Status: PASS / FAIL
              ```

              ## Step 4: Handle Outcome

              ### If ALL scenarios PASS (Score = 100%):
              1. Ensure report shows "Status: PASS"
              2. Commit the report:
                 ```bash
                 git add artifacts/step-1-qa-report.md
                 git commit -m "qa(step-1): all scenarios passed"
                 ```
              3. Mark phase as completed

              ### If ANY scenario FAILS (Score < 100%):
              You MUST inject fix phases. Do NOT just report and continue.

              1. Ensure report shows "Status: FAIL" with specific issues

              2. Find the PROGRESS.yaml file:
                 ```bash
                 PROGRESS_FILE=$(find .claude/sprints -name "PROGRESS.yaml" -type f 2>/dev/null | head -1)
                 echo "Found: $PROGRESS_FILE"
                 ```

              3. Inject fix and re-verify phases using yq:
                 ```bash
                 yq -i '
                   (.phases[] | select(.steps) | .steps[] | select(.status == "in-progress") | .phases) +=
                   [
                     {
                       "id": "fix",
                       "status": "pending",
                       "prompt": "Fix failing scenarios for step-1.\n\n## Context\nRead: artifacts/step-1-qa-report.md\n\n## Instructions\n1. Review each FAIL scenario\n2. Fix the implementation to make it pass\n3. Re-run the verification command to confirm\n4. Make atomic commits for each fix\n\n## After Fixing\nDo NOT mark as complete until ALL verifications pass."
                     },
                     {
                       "id": "reverify",
                       "status": "pending",
                       "prompt": "Re-verify all scenarios after fixes.\n\n## Instructions\nRe-run ALL verification commands from artifacts/step-1-gherkin.md\n\n## If ALL pass:\n- Update artifacts/step-1-qa-report.md with PASS status\n- Commit the updated report\n\n## If ANY still fail:\n- Update the QA report with new results\n- Inject another fix phase using yq\n- Loop continues until all pass"
                     }
                   ]
                 ' "$PROGRESS_FILE"
                 ```

              4. Mark current QA phase as failed:
                 ```bash
                 yq -i '
                   (.. | select(.id == "qa" and .status == "in-progress")) |=
                   (.status = "failed" | .error = "step-1 QA failed - see report - fix phase injected")
                 ' "$PROGRESS_FILE"
                 ```

              5. The sprint loop will now execute fix → reverify phases

              ## Important
              - EVERY scenario must pass for the step to be complete
              - Failed QA MUST inject fix phases, not just report
              - This creates a self-healing loop until all pass
            started-at: "2026-01-18T00:16:15Z"
            completed-at: "2026-01-18T00:18:44Z"
            elapsed: 00:02:29
          - id: verify
            status: completed
            prompt: |
              Final integration verification for the step.

              ## Your Task
              ## Phase 1.2: Backlog Schema and Templates

              Create the learning backlog structure:

              ### Tasks
              1. Create skills/managing-signs/assets/backlog-template.yaml with:
                 - Schema version
                 - Metadata fields (extracted-from, extracted-at)
                 - Empty learnings array
                 - Example learning entry (commented)

              2. Create skills/managing-signs/references/backlog-schema.md documenting:
                 - All fields and their purpose
                 - Status enum values (pending, approved, rejected, applied)
                 - Confidence levels (low, medium, high)
                 - Source metadata structure
                 - Include proper frontmatter (title, description, skill)

              3. Create scripts/validate-backlog.sh to:
                 - Check YAML syntax
                 - Validate required fields
                 - Check status values are valid
                 - Ensure target paths exist

              ### Success Criteria
              - Template is valid YAML
              - Reference has proper frontmatter and is LLM-optimized (dense, structured)
              - Validation script catches common errors


              ## Context
              Read: context/_shared-context.md (build commands)
              Read: artifacts/step-1-qa-report.md (should show PASS)

              ## Step 1: Build Verification
              Run the project build to ensure this step integrates:
              ```bash
              # Use commands from _shared-context.md, typically:
              npm run build
              npm run typecheck
              ```

              ## Step 2: Integration Check
              Verify this step works with the rest of the sprint:
              - Check imports resolve correctly
              - Verify no circular dependencies
              - Ensure types are compatible

              ## Step 3: Smoke Test
              If possible, manually verify the functionality:
              - Run the code path that uses this step's output
              - Check expected behavior matches gherkin scenarios

              ## Step 4: Final Commit
              If all verification passes:
              ```bash
              git add -A
              git status  # Check for any uncommitted changes
              # Only commit if there are changes
              git diff --cached --quiet || git commit -m "verify(step-1): integration verified"
              ```

              ## Outcome
              - If integration passes: Mark step as complete
              - If integration fails: Document the issue and set status to needs-human

              ## Important
              This is the final gate before moving to the next step.
              The step's gherkin scenarios already passed in QA.
              This phase ensures the step works in the broader context.
            started-at: "2026-01-18T00:18:49Z"
            completed-at: "2026-01-18T00:19:58Z"
            elapsed: 00:01:09
      - id: step-2
        prompt: |
          ## Phase 1.3: Manual Sign Management Commands

          Implement /add, /list, /status commands.

          NOTE: Command files go in commands/ with simple names.
          The plugin namespace is auto-prepended, so:
          - commands/add.md becomes /m42-signs:add
          - commands/list.md becomes /m42-signs:list
          - commands/status.md becomes /m42-signs:status

          ### Tasks
          1. Create commands/add.md:
             - Proper frontmatter (description, allowed-tools, model)
             - Interactive prompts for problem/solution/target
             - Support --direct flag to skip backlog
             - Add learning to backlog.yaml or CLAUDE.md directly
             - Validation of inputs

          2. Create commands/list.md:
             - Find all CLAUDE.md files in project
             - Parse ## Signs sections
             - Display table: Location | Title | Origin
             - Support --format json option

          3. Create commands/status.md:
             - Read .claude/learnings/backlog.yaml
             - Count by status (pending/approved/rejected/applied)
             - Show summary table
             - List pending learnings if any

          4. Create commands/help.md:
             - Overview of all commands (as /m42-signs:<command>)
             - Usage examples
             - Workflow diagram

          ### Success Criteria
          - Commands have proper frontmatter
          - Commands work without backlog.yaml existing
          - Add command validates inputs
          - List finds signs in nested directories
          - Status handles missing backlog gracefully
        status: completed
        phases:
          - id: plan
            status: completed
            prompt: |
              Generate binary-verifiable gherkin scenarios for this step.

              ## Your Task
              ## Phase 1.3: Manual Sign Management Commands

              Implement /add, /list, /status commands.

              NOTE: Command files go in commands/ with simple names.
              The plugin namespace is auto-prepended, so:
              - commands/add.md becomes /m42-signs:add
              - commands/list.md becomes /m42-signs:list
              - commands/status.md becomes /m42-signs:status

              ### Tasks
              1. Create commands/add.md:
                 - Proper frontmatter (description, allowed-tools, model)
                 - Interactive prompts for problem/solution/target
                 - Support --direct flag to skip backlog
                 - Add learning to backlog.yaml or CLAUDE.md directly
                 - Validation of inputs

              2. Create commands/list.md:
                 - Find all CLAUDE.md files in project
                 - Parse ## Signs sections
                 - Display table: Location | Title | Origin
                 - Support --format json option

              3. Create commands/status.md:
                 - Read .claude/learnings/backlog.yaml
                 - Count by status (pending/approved/rejected/applied)
                 - Show summary table
                 - List pending learnings if any

              4. Create commands/help.md:
                 - Overview of all commands (as /m42-signs:<command>)
                 - Usage examples
                 - Workflow diagram

              ### Success Criteria
              - Commands have proper frontmatter
              - Commands work without backlog.yaml existing
              - Add command validates inputs
              - List finds signs in nested directories
              - Status handles missing backlog gracefully


              ## Shared Context
              Read: context/_shared-context.md (project patterns, conventions, commands)
              Read: context/sprint-plan.md (how this step fits in the sprint)

              ## Instructions
              Create 4-8 gherkin scenarios that, when ALL pass, prove the step is complete.
              Each scenario MUST have:
              1. Clear Given/When/Then structure
              2. An explicit verification command that returns exit code 0 on success
              3. Binary outcome: exactly 1 (pass) or 0 (fail)

              ## Gherkin Format
              Each scenario follows this exact structure:

              ```gherkin
              Scenario: [Descriptive name]
                Given [precondition or context]
                When [action taken]
                Then [expected outcome]

              Verification: `[shell command that exits 0 on success, non-zero on failure]`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ## Example Scenarios

              ### File Existence
              ```gherkin
              Scenario: Source file exists
                Given the project structure is set up
                When I check for the module file
                Then src/auth/service.ts exists

              Verification: `test -f src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### TypeScript Compilation
              ```gherkin
              Scenario: TypeScript compiles without errors
                Given the file src/auth/service.ts exists
                When I run the TypeScript compiler
                Then no compilation errors occur

              Verification: `npx tsc --noEmit src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Function Export
              ```gherkin
              Scenario: Login function is exported
                Given src/auth/service.ts exists
                When I check for the login export
                Then the function is publicly available

              Verification: `grep -q "export.*function login\|export.*const login\|export { login" src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### Test Execution
              ```gherkin
              Scenario: Unit tests pass
                Given tests exist in src/auth/service.test.ts
                When I run the test suite
                Then all tests pass

              Verification: `npm test -- --testPathPattern="auth/service" --passWithNoTests 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Lint Check
              ```gherkin
              Scenario: Code passes linting
                Given the implementation is complete
                When I run the linter
                Then no lint errors in new files

              Verification: `npm run lint -- src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ## Output
              Create: artifacts/step-2-gherkin.md

              ```markdown
              # Gherkin Scenarios: step-2

              ## Step Task
              ## Phase 1.3: Manual Sign Management Commands

              Implement /add, /list, /status commands.

              NOTE: Command files go in commands/ with simple names.
              The plugin namespace is auto-prepended, so:
              - commands/add.md becomes /m42-signs:add
              - commands/list.md becomes /m42-signs:list
              - commands/status.md becomes /m42-signs:status

              ### Tasks
              1. Create commands/add.md:
                 - Proper frontmatter (description, allowed-tools, model)
                 - Interactive prompts for problem/solution/target
                 - Support --direct flag to skip backlog
                 - Add learning to backlog.yaml or CLAUDE.md directly
                 - Validation of inputs

              2. Create commands/list.md:
                 - Find all CLAUDE.md files in project
                 - Parse ## Signs sections
                 - Display table: Location | Title | Origin
                 - Support --format json option

              3. Create commands/status.md:
                 - Read .claude/learnings/backlog.yaml
                 - Count by status (pending/approved/rejected/applied)
                 - Show summary table
                 - List pending learnings if any

              4. Create commands/help.md:
                 - Overview of all commands (as /m42-signs:<command>)
                 - Usage examples
                 - Workflow diagram

              ### Success Criteria
              - Commands have proper frontmatter
              - Commands work without backlog.yaml existing
              - Add command validates inputs
              - List finds signs in nested directories
              - Status handles missing backlog gracefully


              ## Success Criteria
              All scenarios must pass (score = 1) for the step to be complete.
              Total scenarios: [N]
              Required score: [N]/[N]

              ---

              ## Scenario 1: [Name]
              [Full gherkin with verification as shown above]

              ---

              ## Scenario 2: [Name]
              ...

              [Continue for 4-8 scenarios]
              ```

              ## Commit
              ```bash
              git add artifacts/step-2-gherkin.md
              git commit -m "plan(step-2): define gherkin scenarios"
              ```
          - id: context
            status: completed
            prompt: |
              Gather step-specific context for implementation.

              ## Your Task
              ## Phase 1.3: Manual Sign Management Commands

              Implement /add, /list, /status commands.

              NOTE: Command files go in commands/ with simple names.
              The plugin namespace is auto-prepended, so:
              - commands/add.md becomes /m42-signs:add
              - commands/list.md becomes /m42-signs:list
              - commands/status.md becomes /m42-signs:status

              ### Tasks
              1. Create commands/add.md:
                 - Proper frontmatter (description, allowed-tools, model)
                 - Interactive prompts for problem/solution/target
                 - Support --direct flag to skip backlog
                 - Add learning to backlog.yaml or CLAUDE.md directly
                 - Validation of inputs

              2. Create commands/list.md:
                 - Find all CLAUDE.md files in project
                 - Parse ## Signs sections
                 - Display table: Location | Title | Origin
                 - Support --format json option

              3. Create commands/status.md:
                 - Read .claude/learnings/backlog.yaml
                 - Count by status (pending/approved/rejected/applied)
                 - Show summary table
                 - List pending learnings if any

              4. Create commands/help.md:
                 - Overview of all commands (as /m42-signs:<command>)
                 - Usage examples
                 - Workflow diagram

              ### Success Criteria
              - Commands have proper frontmatter
              - Commands work without backlog.yaml existing
              - Add command validates inputs
              - List finds signs in nested directories
              - Status handles missing backlog gracefully


              ## Shared Context
              Read: context/_shared-context.md (already has project-wide patterns)
              Read: artifacts/step-2-gherkin.md (scenarios to implement)

              ## Instructions
              Research the specific code areas this step will touch:

              1. **Related Existing Code**
                 - Find similar implementations to follow as patterns
                 - Identify modules this step will import from
                 - Note any interfaces/types to implement or extend

              2. **Dependencies**
                 - List imports needed from internal modules
                 - List any new external packages needed
                 - Check for peer dependencies or version constraints

              3. **Integration Points**
                 - How will this code be called/used?
                 - What modules will import from this step's output?
                 - Are there existing tests to extend?

              4. **Specific Patterns**
                 - Error handling patterns used in similar code
                 - Naming conventions for this area
                 - File organization patterns

              ## Output
              Create: context/step-2-context.md

              ```markdown
              # Step Context: step-2

              ## Task
              ## Phase 1.3: Manual Sign Management Commands

              Implement /add, /list, /status commands.

              NOTE: Command files go in commands/ with simple names.
              The plugin namespace is auto-prepended, so:
              - commands/add.md becomes /m42-signs:add
              - commands/list.md becomes /m42-signs:list
              - commands/status.md becomes /m42-signs:status

              ### Tasks
              1. Create commands/add.md:
                 - Proper frontmatter (description, allowed-tools, model)
                 - Interactive prompts for problem/solution/target
                 - Support --direct flag to skip backlog
                 - Add learning to backlog.yaml or CLAUDE.md directly
                 - Validation of inputs

              2. Create commands/list.md:
                 - Find all CLAUDE.md files in project
                 - Parse ## Signs sections
                 - Display table: Location | Title | Origin
                 - Support --format json option

              3. Create commands/status.md:
                 - Read .claude/learnings/backlog.yaml
                 - Count by status (pending/approved/rejected/applied)
                 - Show summary table
                 - List pending learnings if any

              4. Create commands/help.md:
                 - Overview of all commands (as /m42-signs:<command>)
                 - Usage examples
                 - Workflow diagram

              ### Success Criteria
              - Commands have proper frontmatter
              - Commands work without backlog.yaml existing
              - Add command validates inputs
              - List finds signs in nested directories
              - Status handles missing backlog gracefully


              ## Related Code Patterns

              ### Similar Implementation: [path]
              ```typescript
              // Key pattern to follow
              [relevant code snippet]
              ```

              ### Similar Implementation: [path]
              [continue as needed]

              ## Required Imports
              ### Internal
              - `[module]`: [what to import]

              ### External
              - `[package]`: [what to import]

              ## Types/Interfaces to Use
              ```typescript
              // From [source]
              interface [Name] {
                [relevant fields]
              }
              ```

              ## Integration Points
              - Called by: [who will use this]
              - Calls: [what this will call]
              - Tests: [related test files]

              ## Implementation Notes
              - [Specific note 1]
              - [Specific note 2]
              ```

              ## Commit
              ```bash
              git add context/step-2-context.md
              git commit -m "context(step-2): gather implementation context"
              ```
            started-at: "2026-01-18T17:36:46Z"
            completed-at: "2026-01-18T17:38:14Z"
            elapsed: 00:01:28
          - id: execute
            status: completed
            prompt: |
              Implement the step following gherkin scenarios and context.

              ## Your Task
              ## Phase 1.3: Manual Sign Management Commands

              Implement /add, /list, /status commands.

              NOTE: Command files go in commands/ with simple names.
              The plugin namespace is auto-prepended, so:
              - commands/add.md becomes /m42-signs:add
              - commands/list.md becomes /m42-signs:list
              - commands/status.md becomes /m42-signs:status

              ### Tasks
              1. Create commands/add.md:
                 - Proper frontmatter (description, allowed-tools, model)
                 - Interactive prompts for problem/solution/target
                 - Support --direct flag to skip backlog
                 - Add learning to backlog.yaml or CLAUDE.md directly
                 - Validation of inputs

              2. Create commands/list.md:
                 - Find all CLAUDE.md files in project
                 - Parse ## Signs sections
                 - Display table: Location | Title | Origin
                 - Support --format json option

              3. Create commands/status.md:
                 - Read .claude/learnings/backlog.yaml
                 - Count by status (pending/approved/rejected/applied)
                 - Show summary table
                 - List pending learnings if any

              4. Create commands/help.md:
                 - Overview of all commands (as /m42-signs:<command>)
                 - Usage examples
                 - Workflow diagram

              ### Success Criteria
              - Commands have proper frontmatter
              - Commands work without backlog.yaml existing
              - Add command validates inputs
              - List finds signs in nested directories
              - Status handles missing backlog gracefully


              ## MUST READ BEFORE IMPLEMENTING
              Read these files in order:
              1. context/_shared-context.md (project patterns, conventions)
              2. context/sprint-plan.md (how this fits in sprint)
              3. artifacts/step-2-gherkin.md (scenarios to satisfy)
              4. context/step-2-context.md (specific patterns, imports)

              ## Implementation Rules

              ### Follow the Gherkin
              Your implementation MUST satisfy ALL gherkin scenarios.
              Each scenario has a verification command - mentally run it to check your work.

              ### Follow the Context
              - Use patterns from similar implementations
              - Import from specified modules
              - Implement required interfaces
              - Follow naming conventions

              ### Code Quality
              - Keep code simple and focused
              - Follow existing patterns exactly
              - No over-engineering or extra abstractions
              - Only implement what's needed for the scenarios

              ### Commits
              Make atomic commits for logical units:
              ```bash
              # After each logical piece
              git add [files]
              git commit -m "[type](step-2): [description]"
              ```

              Types: feat, fix, refactor, test, docs

              ## Implementation Checklist
              Before marking complete, verify:
              - [ ] All files from gherkin scenarios exist
              - [ ] Code follows patterns from context
              - [ ] Imports are correct
              - [ ] No TypeScript errors (run typecheck mentally)
              - [ ] Each scenario's verification should pass

              ## If Blocked
              If you encounter an issue that prevents completion:
              - Document the blocker clearly
              - Set status to needs-human
              - Do NOT leave partial/broken implementation
            started-at: "2026-01-18T17:38:18Z"
            completed-at: "2026-01-18T17:41:15Z"
            elapsed: 00:02:57
          - id: qa
            status: completed
            prompt: |
              Verify implementation against gherkin scenarios.

              ## Context
              Read: artifacts/step-2-gherkin.md (scenarios with verification commands)

              ## Step 1: Run Each Verification

              For EACH scenario in the gherkin file:
              1. Run the verification command
              2. Record the result: 1 (pass) or 0 (fail)
              3. If fail, capture the error output

              ## Step 2: Calculate Score

              Score = (passed scenarios) / (total scenarios)
              - Score = 1.0 (all pass) → PASS
              - Score < 1.0 (any fail) → FAIL

              ## Step 3: Generate QA Report

              Create: artifacts/step-2-qa-report.md

              ```markdown
              # QA Report: step-2

              ## Summary
              - Total Scenarios: [N]
              - Passed: [N]
              - Failed: [N]
              - Score: [X]/[N] = [percentage]%

              ## Verification Results

              | # | Scenario | Result | Details |
              |---|----------|--------|---------|
              | 1 | [Name] | PASS/FAIL | [output or error] |
              | 2 | [Name] | PASS/FAIL | [output or error] |
              ...

              ## Detailed Results

              ### Scenario 1: [Name]
              **Verification**: `[command]`
              **Exit Code**: [0 or N]
              **Output**:
              ```
              [actual output]
              ```
              **Result**: PASS / FAIL

              ### Scenario 2: [Name]
              ...

              ## Issues Found
              [If any failures, describe each issue]

              1. **[Scenario name]**: [What failed and why]

              ## Status: PASS / FAIL
              ```

              ## Step 4: Handle Outcome

              ### If ALL scenarios PASS (Score = 100%):
              1. Ensure report shows "Status: PASS"
              2. Commit the report:
                 ```bash
                 git add artifacts/step-2-qa-report.md
                 git commit -m "qa(step-2): all scenarios passed"
                 ```
              3. Mark phase as completed

              ### If ANY scenario FAILS (Score < 100%):
              You MUST inject fix phases. Do NOT just report and continue.

              1. Ensure report shows "Status: FAIL" with specific issues

              2. Find the PROGRESS.yaml file:
                 ```bash
                 PROGRESS_FILE=$(find .claude/sprints -name "PROGRESS.yaml" -type f 2>/dev/null | head -1)
                 echo "Found: $PROGRESS_FILE"
                 ```

              3. Inject fix and re-verify phases using yq:
                 ```bash
                 yq -i '
                   (.phases[] | select(.steps) | .steps[] | select(.status == "in-progress") | .phases) +=
                   [
                     {
                       "id": "fix",
                       "status": "pending",
                       "prompt": "Fix failing scenarios for step-2.\n\n## Context\nRead: artifacts/step-2-qa-report.md\n\n## Instructions\n1. Review each FAIL scenario\n2. Fix the implementation to make it pass\n3. Re-run the verification command to confirm\n4. Make atomic commits for each fix\n\n## After Fixing\nDo NOT mark as complete until ALL verifications pass."
                     },
                     {
                       "id": "reverify",
                       "status": "pending",
                       "prompt": "Re-verify all scenarios after fixes.\n\n## Instructions\nRe-run ALL verification commands from artifacts/step-2-gherkin.md\n\n## If ALL pass:\n- Update artifacts/step-2-qa-report.md with PASS status\n- Commit the updated report\n\n## If ANY still fail:\n- Update the QA report with new results\n- Inject another fix phase using yq\n- Loop continues until all pass"
                     }
                   ]
                 ' "$PROGRESS_FILE"
                 ```

              4. Mark current QA phase as failed:
                 ```bash
                 yq -i '
                   (.. | select(.id == "qa" and .status == "in-progress")) |=
                   (.status = "failed" | .error = "step-2 QA failed - see report - fix phase injected")
                 ' "$PROGRESS_FILE"
                 ```

              5. The sprint loop will now execute fix → reverify phases

              ## Important
              - EVERY scenario must pass for the step to be complete
              - Failed QA MUST inject fix phases, not just report
              - This creates a self-healing loop until all pass
            started-at: "2026-01-18T17:41:19Z"
            completed-at: "2026-01-18T17:42:11Z"
            elapsed: 00:00:52
          - id: verify
            status: completed
            prompt: |
              Final integration verification for the step.

              ## Your Task
              ## Phase 1.3: Manual Sign Management Commands

              Implement /add, /list, /status commands.

              NOTE: Command files go in commands/ with simple names.
              The plugin namespace is auto-prepended, so:
              - commands/add.md becomes /m42-signs:add
              - commands/list.md becomes /m42-signs:list
              - commands/status.md becomes /m42-signs:status

              ### Tasks
              1. Create commands/add.md:
                 - Proper frontmatter (description, allowed-tools, model)
                 - Interactive prompts for problem/solution/target
                 - Support --direct flag to skip backlog
                 - Add learning to backlog.yaml or CLAUDE.md directly
                 - Validation of inputs

              2. Create commands/list.md:
                 - Find all CLAUDE.md files in project
                 - Parse ## Signs sections
                 - Display table: Location | Title | Origin
                 - Support --format json option

              3. Create commands/status.md:
                 - Read .claude/learnings/backlog.yaml
                 - Count by status (pending/approved/rejected/applied)
                 - Show summary table
                 - List pending learnings if any

              4. Create commands/help.md:
                 - Overview of all commands (as /m42-signs:<command>)
                 - Usage examples
                 - Workflow diagram

              ### Success Criteria
              - Commands have proper frontmatter
              - Commands work without backlog.yaml existing
              - Add command validates inputs
              - List finds signs in nested directories
              - Status handles missing backlog gracefully


              ## Context
              Read: context/_shared-context.md (build commands)
              Read: artifacts/step-2-qa-report.md (should show PASS)

              ## Step 1: Build Verification
              Run the project build to ensure this step integrates:
              ```bash
              # Use commands from _shared-context.md, typically:
              npm run build
              npm run typecheck
              ```

              ## Step 2: Integration Check
              Verify this step works with the rest of the sprint:
              - Check imports resolve correctly
              - Verify no circular dependencies
              - Ensure types are compatible

              ## Step 3: Smoke Test
              If possible, manually verify the functionality:
              - Run the code path that uses this step's output
              - Check expected behavior matches gherkin scenarios

              ## Step 4: Final Commit
              If all verification passes:
              ```bash
              git add -A
              git status  # Check for any uncommitted changes
              # Only commit if there are changes
              git diff --cached --quiet || git commit -m "verify(step-2): integration verified"
              ```

              ## Outcome
              - If integration passes: Mark step as complete
              - If integration fails: Document the issue and set status to needs-human

              ## Important
              This is the final gate before moving to the next step.
              The step's gherkin scenarios already passed in QA.
              This phase ensures the step works in the broader context.
            started-at: "2026-01-18T17:42:16Z"
            completed-at: "2026-01-18T17:43:41Z"
            elapsed: 00:01:25
      - id: step-3
        prompt: |
          ## Phase 2.1: Transcript Parsing Logic

          Implement session transcript parsing:

          ### Tasks
          1. Create scripts/parse-transcript.sh:
             - Read JSONL session file
             - Extract all messages with is_error: true
             - Correlate tool_use with tool_result
             - Output: tool name, command/input, error message

          2. Create skills/managing-signs/references/transcript-format.md:
             - Include proper frontmatter (title, description, skill: managing-signs)
             - Document all message types from SESSION-TRACKING.md
             - Include jq query examples
             - Explain correlation logic
             - Keep it LLM-dense (tables, code examples, no prose)

          3. Test parsing with:
             - Find a real session file in ~/.claude/projects/
             - Run parse-transcript.sh
             - Verify error extraction works

          ### Success Criteria
          - Script handles all message types
          - Errors are correctly correlated with their tool calls
          - Output is structured and parsable
          - Reference file has frontmatter and is dense
        status: in-progress
        phases:
          - id: plan
            status: completed
            prompt: |
              Generate binary-verifiable gherkin scenarios for this step.

              ## Your Task
              ## Phase 2.1: Transcript Parsing Logic

              Implement session transcript parsing:

              ### Tasks
              1. Create scripts/parse-transcript.sh:
                 - Read JSONL session file
                 - Extract all messages with is_error: true
                 - Correlate tool_use with tool_result
                 - Output: tool name, command/input, error message

              2. Create skills/managing-signs/references/transcript-format.md:
                 - Include proper frontmatter (title, description, skill: managing-signs)
                 - Document all message types from SESSION-TRACKING.md
                 - Include jq query examples
                 - Explain correlation logic
                 - Keep it LLM-dense (tables, code examples, no prose)

              3. Test parsing with:
                 - Find a real session file in ~/.claude/projects/
                 - Run parse-transcript.sh
                 - Verify error extraction works

              ### Success Criteria
              - Script handles all message types
              - Errors are correctly correlated with their tool calls
              - Output is structured and parsable
              - Reference file has frontmatter and is dense


              ## Shared Context
              Read: context/_shared-context.md (project patterns, conventions, commands)
              Read: context/sprint-plan.md (how this step fits in the sprint)

              ## Instructions
              Create 4-8 gherkin scenarios that, when ALL pass, prove the step is complete.
              Each scenario MUST have:
              1. Clear Given/When/Then structure
              2. An explicit verification command that returns exit code 0 on success
              3. Binary outcome: exactly 1 (pass) or 0 (fail)

              ## Gherkin Format
              Each scenario follows this exact structure:

              ```gherkin
              Scenario: [Descriptive name]
                Given [precondition or context]
                When [action taken]
                Then [expected outcome]

              Verification: `[shell command that exits 0 on success, non-zero on failure]`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ## Example Scenarios

              ### File Existence
              ```gherkin
              Scenario: Source file exists
                Given the project structure is set up
                When I check for the module file
                Then src/auth/service.ts exists

              Verification: `test -f src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### TypeScript Compilation
              ```gherkin
              Scenario: TypeScript compiles without errors
                Given the file src/auth/service.ts exists
                When I run the TypeScript compiler
                Then no compilation errors occur

              Verification: `npx tsc --noEmit src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Function Export
              ```gherkin
              Scenario: Login function is exported
                Given src/auth/service.ts exists
                When I check for the login export
                Then the function is publicly available

              Verification: `grep -q "export.*function login\|export.*const login\|export { login" src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### Test Execution
              ```gherkin
              Scenario: Unit tests pass
                Given tests exist in src/auth/service.test.ts
                When I run the test suite
                Then all tests pass

              Verification: `npm test -- --testPathPattern="auth/service" --passWithNoTests 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Lint Check
              ```gherkin
              Scenario: Code passes linting
                Given the implementation is complete
                When I run the linter
                Then no lint errors in new files

              Verification: `npm run lint -- src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ## Output
              Create: artifacts/step-3-gherkin.md

              ```markdown
              # Gherkin Scenarios: step-3

              ## Step Task
              ## Phase 2.1: Transcript Parsing Logic

              Implement session transcript parsing:

              ### Tasks
              1. Create scripts/parse-transcript.sh:
                 - Read JSONL session file
                 - Extract all messages with is_error: true
                 - Correlate tool_use with tool_result
                 - Output: tool name, command/input, error message

              2. Create skills/managing-signs/references/transcript-format.md:
                 - Include proper frontmatter (title, description, skill: managing-signs)
                 - Document all message types from SESSION-TRACKING.md
                 - Include jq query examples
                 - Explain correlation logic
                 - Keep it LLM-dense (tables, code examples, no prose)

              3. Test parsing with:
                 - Find a real session file in ~/.claude/projects/
                 - Run parse-transcript.sh
                 - Verify error extraction works

              ### Success Criteria
              - Script handles all message types
              - Errors are correctly correlated with their tool calls
              - Output is structured and parsable
              - Reference file has frontmatter and is dense


              ## Success Criteria
              All scenarios must pass (score = 1) for the step to be complete.
              Total scenarios: [N]
              Required score: [N]/[N]

              ---

              ## Scenario 1: [Name]
              [Full gherkin with verification as shown above]

              ---

              ## Scenario 2: [Name]
              ...

              [Continue for 4-8 scenarios]
              ```

              ## Commit
              ```bash
              git add artifacts/step-3-gherkin.md
              git commit -m "plan(step-3): define gherkin scenarios"
              ```
            started-at: "2026-01-18T17:43:45Z"
            completed-at: "2026-01-18T17:44:54Z"
            elapsed: 00:01:09
          - id: context
            status: completed
            prompt: |
              Gather step-specific context for implementation.

              ## Your Task
              ## Phase 2.1: Transcript Parsing Logic

              Implement session transcript parsing:

              ### Tasks
              1. Create scripts/parse-transcript.sh:
                 - Read JSONL session file
                 - Extract all messages with is_error: true
                 - Correlate tool_use with tool_result
                 - Output: tool name, command/input, error message

              2. Create skills/managing-signs/references/transcript-format.md:
                 - Include proper frontmatter (title, description, skill: managing-signs)
                 - Document all message types from SESSION-TRACKING.md
                 - Include jq query examples
                 - Explain correlation logic
                 - Keep it LLM-dense (tables, code examples, no prose)

              3. Test parsing with:
                 - Find a real session file in ~/.claude/projects/
                 - Run parse-transcript.sh
                 - Verify error extraction works

              ### Success Criteria
              - Script handles all message types
              - Errors are correctly correlated with their tool calls
              - Output is structured and parsable
              - Reference file has frontmatter and is dense


              ## Shared Context
              Read: context/_shared-context.md (already has project-wide patterns)
              Read: artifacts/step-3-gherkin.md (scenarios to implement)

              ## Instructions
              Research the specific code areas this step will touch:

              1. **Related Existing Code**
                 - Find similar implementations to follow as patterns
                 - Identify modules this step will import from
                 - Note any interfaces/types to implement or extend

              2. **Dependencies**
                 - List imports needed from internal modules
                 - List any new external packages needed
                 - Check for peer dependencies or version constraints

              3. **Integration Points**
                 - How will this code be called/used?
                 - What modules will import from this step's output?
                 - Are there existing tests to extend?

              4. **Specific Patterns**
                 - Error handling patterns used in similar code
                 - Naming conventions for this area
                 - File organization patterns

              ## Output
              Create: context/step-3-context.md

              ```markdown
              # Step Context: step-3

              ## Task
              ## Phase 2.1: Transcript Parsing Logic

              Implement session transcript parsing:

              ### Tasks
              1. Create scripts/parse-transcript.sh:
                 - Read JSONL session file
                 - Extract all messages with is_error: true
                 - Correlate tool_use with tool_result
                 - Output: tool name, command/input, error message

              2. Create skills/managing-signs/references/transcript-format.md:
                 - Include proper frontmatter (title, description, skill: managing-signs)
                 - Document all message types from SESSION-TRACKING.md
                 - Include jq query examples
                 - Explain correlation logic
                 - Keep it LLM-dense (tables, code examples, no prose)

              3. Test parsing with:
                 - Find a real session file in ~/.claude/projects/
                 - Run parse-transcript.sh
                 - Verify error extraction works

              ### Success Criteria
              - Script handles all message types
              - Errors are correctly correlated with their tool calls
              - Output is structured and parsable
              - Reference file has frontmatter and is dense


              ## Related Code Patterns

              ### Similar Implementation: [path]
              ```typescript
              // Key pattern to follow
              [relevant code snippet]
              ```

              ### Similar Implementation: [path]
              [continue as needed]

              ## Required Imports
              ### Internal
              - `[module]`: [what to import]

              ### External
              - `[package]`: [what to import]

              ## Types/Interfaces to Use
              ```typescript
              // From [source]
              interface [Name] {
                [relevant fields]
              }
              ```

              ## Integration Points
              - Called by: [who will use this]
              - Calls: [what this will call]
              - Tests: [related test files]

              ## Implementation Notes
              - [Specific note 1]
              - [Specific note 2]
              ```

              ## Commit
              ```bash
              git add context/step-3-context.md
              git commit -m "context(step-3): gather implementation context"
              ```
          - id: execute
            status: pending
            prompt: |
              Implement the step following gherkin scenarios and context.

              ## Your Task
              ## Phase 2.1: Transcript Parsing Logic

              Implement session transcript parsing:

              ### Tasks
              1. Create scripts/parse-transcript.sh:
                 - Read JSONL session file
                 - Extract all messages with is_error: true
                 - Correlate tool_use with tool_result
                 - Output: tool name, command/input, error message

              2. Create skills/managing-signs/references/transcript-format.md:
                 - Include proper frontmatter (title, description, skill: managing-signs)
                 - Document all message types from SESSION-TRACKING.md
                 - Include jq query examples
                 - Explain correlation logic
                 - Keep it LLM-dense (tables, code examples, no prose)

              3. Test parsing with:
                 - Find a real session file in ~/.claude/projects/
                 - Run parse-transcript.sh
                 - Verify error extraction works

              ### Success Criteria
              - Script handles all message types
              - Errors are correctly correlated with their tool calls
              - Output is structured and parsable
              - Reference file has frontmatter and is dense


              ## MUST READ BEFORE IMPLEMENTING
              Read these files in order:
              1. context/_shared-context.md (project patterns, conventions)
              2. context/sprint-plan.md (how this fits in sprint)
              3. artifacts/step-3-gherkin.md (scenarios to satisfy)
              4. context/step-3-context.md (specific patterns, imports)

              ## Implementation Rules

              ### Follow the Gherkin
              Your implementation MUST satisfy ALL gherkin scenarios.
              Each scenario has a verification command - mentally run it to check your work.

              ### Follow the Context
              - Use patterns from similar implementations
              - Import from specified modules
              - Implement required interfaces
              - Follow naming conventions

              ### Code Quality
              - Keep code simple and focused
              - Follow existing patterns exactly
              - No over-engineering or extra abstractions
              - Only implement what's needed for the scenarios

              ### Commits
              Make atomic commits for logical units:
              ```bash
              # After each logical piece
              git add [files]
              git commit -m "[type](step-3): [description]"
              ```

              Types: feat, fix, refactor, test, docs

              ## Implementation Checklist
              Before marking complete, verify:
              - [ ] All files from gherkin scenarios exist
              - [ ] Code follows patterns from context
              - [ ] Imports are correct
              - [ ] No TypeScript errors (run typecheck mentally)
              - [ ] Each scenario's verification should pass

              ## If Blocked
              If you encounter an issue that prevents completion:
              - Document the blocker clearly
              - Set status to needs-human
              - Do NOT leave partial/broken implementation
          - id: qa
            status: pending
            prompt: |
              Verify implementation against gherkin scenarios.

              ## Context
              Read: artifacts/step-3-gherkin.md (scenarios with verification commands)

              ## Step 1: Run Each Verification

              For EACH scenario in the gherkin file:
              1. Run the verification command
              2. Record the result: 1 (pass) or 0 (fail)
              3. If fail, capture the error output

              ## Step 2: Calculate Score

              Score = (passed scenarios) / (total scenarios)
              - Score = 1.0 (all pass) → PASS
              - Score < 1.0 (any fail) → FAIL

              ## Step 3: Generate QA Report

              Create: artifacts/step-3-qa-report.md

              ```markdown
              # QA Report: step-3

              ## Summary
              - Total Scenarios: [N]
              - Passed: [N]
              - Failed: [N]
              - Score: [X]/[N] = [percentage]%

              ## Verification Results

              | # | Scenario | Result | Details |
              |---|----------|--------|---------|
              | 1 | [Name] | PASS/FAIL | [output or error] |
              | 2 | [Name] | PASS/FAIL | [output or error] |
              ...

              ## Detailed Results

              ### Scenario 1: [Name]
              **Verification**: `[command]`
              **Exit Code**: [0 or N]
              **Output**:
              ```
              [actual output]
              ```
              **Result**: PASS / FAIL

              ### Scenario 2: [Name]
              ...

              ## Issues Found
              [If any failures, describe each issue]

              1. **[Scenario name]**: [What failed and why]

              ## Status: PASS / FAIL
              ```

              ## Step 4: Handle Outcome

              ### If ALL scenarios PASS (Score = 100%):
              1. Ensure report shows "Status: PASS"
              2. Commit the report:
                 ```bash
                 git add artifacts/step-3-qa-report.md
                 git commit -m "qa(step-3): all scenarios passed"
                 ```
              3. Mark phase as completed

              ### If ANY scenario FAILS (Score < 100%):
              You MUST inject fix phases. Do NOT just report and continue.

              1. Ensure report shows "Status: FAIL" with specific issues

              2. Find the PROGRESS.yaml file:
                 ```bash
                 PROGRESS_FILE=$(find .claude/sprints -name "PROGRESS.yaml" -type f 2>/dev/null | head -1)
                 echo "Found: $PROGRESS_FILE"
                 ```

              3. Inject fix and re-verify phases using yq:
                 ```bash
                 yq -i '
                   (.phases[] | select(.steps) | .steps[] | select(.status == "in-progress") | .phases) +=
                   [
                     {
                       "id": "fix",
                       "status": "pending",
                       "prompt": "Fix failing scenarios for step-3.\n\n## Context\nRead: artifacts/step-3-qa-report.md\n\n## Instructions\n1. Review each FAIL scenario\n2. Fix the implementation to make it pass\n3. Re-run the verification command to confirm\n4. Make atomic commits for each fix\n\n## After Fixing\nDo NOT mark as complete until ALL verifications pass."
                     },
                     {
                       "id": "reverify",
                       "status": "pending",
                       "prompt": "Re-verify all scenarios after fixes.\n\n## Instructions\nRe-run ALL verification commands from artifacts/step-3-gherkin.md\n\n## If ALL pass:\n- Update artifacts/step-3-qa-report.md with PASS status\n- Commit the updated report\n\n## If ANY still fail:\n- Update the QA report with new results\n- Inject another fix phase using yq\n- Loop continues until all pass"
                     }
                   ]
                 ' "$PROGRESS_FILE"
                 ```

              4. Mark current QA phase as failed:
                 ```bash
                 yq -i '
                   (.. | select(.id == "qa" and .status == "in-progress")) |=
                   (.status = "failed" | .error = "step-3 QA failed - see report - fix phase injected")
                 ' "$PROGRESS_FILE"
                 ```

              5. The sprint loop will now execute fix → reverify phases

              ## Important
              - EVERY scenario must pass for the step to be complete
              - Failed QA MUST inject fix phases, not just report
              - This creates a self-healing loop until all pass
          - id: verify
            status: pending
            prompt: |
              Final integration verification for the step.

              ## Your Task
              ## Phase 2.1: Transcript Parsing Logic

              Implement session transcript parsing:

              ### Tasks
              1. Create scripts/parse-transcript.sh:
                 - Read JSONL session file
                 - Extract all messages with is_error: true
                 - Correlate tool_use with tool_result
                 - Output: tool name, command/input, error message

              2. Create skills/managing-signs/references/transcript-format.md:
                 - Include proper frontmatter (title, description, skill: managing-signs)
                 - Document all message types from SESSION-TRACKING.md
                 - Include jq query examples
                 - Explain correlation logic
                 - Keep it LLM-dense (tables, code examples, no prose)

              3. Test parsing with:
                 - Find a real session file in ~/.claude/projects/
                 - Run parse-transcript.sh
                 - Verify error extraction works

              ### Success Criteria
              - Script handles all message types
              - Errors are correctly correlated with their tool calls
              - Output is structured and parsable
              - Reference file has frontmatter and is dense


              ## Context
              Read: context/_shared-context.md (build commands)
              Read: artifacts/step-3-qa-report.md (should show PASS)

              ## Step 1: Build Verification
              Run the project build to ensure this step integrates:
              ```bash
              # Use commands from _shared-context.md, typically:
              npm run build
              npm run typecheck
              ```

              ## Step 2: Integration Check
              Verify this step works with the rest of the sprint:
              - Check imports resolve correctly
              - Verify no circular dependencies
              - Ensure types are compatible

              ## Step 3: Smoke Test
              If possible, manually verify the functionality:
              - Run the code path that uses this step's output
              - Check expected behavior matches gherkin scenarios

              ## Step 4: Final Commit
              If all verification passes:
              ```bash
              git add -A
              git status  # Check for any uncommitted changes
              # Only commit if there are changes
              git diff --cached --quiet || git commit -m "verify(step-3): integration verified"
              ```

              ## Outcome
              - If integration passes: Mark step as complete
              - If integration fails: Document the issue and set status to needs-human

              ## Important
              This is the final gate before moving to the next step.
              The step's gherkin scenarios already passed in QA.
              This phase ensures the step works in the broader context.
      - id: step-4
        prompt: |
          ## Phase 2.2: Error Pattern Detection

          Implement retry pattern identification:

          ### Tasks
          1. Create scripts/find-retry-patterns.sh:
             - Input: parsed transcript with errors
             - Detect sequences: error -> retry -> success
             - Extract the diff (what changed between attempts)
             - Group by tool type (Bash, Edit, etc.)

          2. Add heuristics for common patterns:
             - Command syntax fixes (quoting, escaping)
             - File path corrections
             - Permission/access fixes
             - API retry with rate limiting

          3. Create confidence scoring:
             - High: Clear fix, obvious pattern
             - Medium: Plausible fix, moderate evidence
             - Low: Unclear if fix was causal

          ### Success Criteria
          - Script detects at least 80% of retry patterns
          - Confidence scores are reasonable
          - False positives are < 20%
        status: pending
        phases:
          - id: plan
            status: pending
            prompt: |
              Generate binary-verifiable gherkin scenarios for this step.

              ## Your Task
              ## Phase 2.2: Error Pattern Detection

              Implement retry pattern identification:

              ### Tasks
              1. Create scripts/find-retry-patterns.sh:
                 - Input: parsed transcript with errors
                 - Detect sequences: error -> retry -> success
                 - Extract the diff (what changed between attempts)
                 - Group by tool type (Bash, Edit, etc.)

              2. Add heuristics for common patterns:
                 - Command syntax fixes (quoting, escaping)
                 - File path corrections
                 - Permission/access fixes
                 - API retry with rate limiting

              3. Create confidence scoring:
                 - High: Clear fix, obvious pattern
                 - Medium: Plausible fix, moderate evidence
                 - Low: Unclear if fix was causal

              ### Success Criteria
              - Script detects at least 80% of retry patterns
              - Confidence scores are reasonable
              - False positives are < 20%


              ## Shared Context
              Read: context/_shared-context.md (project patterns, conventions, commands)
              Read: context/sprint-plan.md (how this step fits in the sprint)

              ## Instructions
              Create 4-8 gherkin scenarios that, when ALL pass, prove the step is complete.
              Each scenario MUST have:
              1. Clear Given/When/Then structure
              2. An explicit verification command that returns exit code 0 on success
              3. Binary outcome: exactly 1 (pass) or 0 (fail)

              ## Gherkin Format
              Each scenario follows this exact structure:

              ```gherkin
              Scenario: [Descriptive name]
                Given [precondition or context]
                When [action taken]
                Then [expected outcome]

              Verification: `[shell command that exits 0 on success, non-zero on failure]`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ## Example Scenarios

              ### File Existence
              ```gherkin
              Scenario: Source file exists
                Given the project structure is set up
                When I check for the module file
                Then src/auth/service.ts exists

              Verification: `test -f src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### TypeScript Compilation
              ```gherkin
              Scenario: TypeScript compiles without errors
                Given the file src/auth/service.ts exists
                When I run the TypeScript compiler
                Then no compilation errors occur

              Verification: `npx tsc --noEmit src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Function Export
              ```gherkin
              Scenario: Login function is exported
                Given src/auth/service.ts exists
                When I check for the login export
                Then the function is publicly available

              Verification: `grep -q "export.*function login\|export.*const login\|export { login" src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### Test Execution
              ```gherkin
              Scenario: Unit tests pass
                Given tests exist in src/auth/service.test.ts
                When I run the test suite
                Then all tests pass

              Verification: `npm test -- --testPathPattern="auth/service" --passWithNoTests 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Lint Check
              ```gherkin
              Scenario: Code passes linting
                Given the implementation is complete
                When I run the linter
                Then no lint errors in new files

              Verification: `npm run lint -- src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ## Output
              Create: artifacts/step-4-gherkin.md

              ```markdown
              # Gherkin Scenarios: step-4

              ## Step Task
              ## Phase 2.2: Error Pattern Detection

              Implement retry pattern identification:

              ### Tasks
              1. Create scripts/find-retry-patterns.sh:
                 - Input: parsed transcript with errors
                 - Detect sequences: error -> retry -> success
                 - Extract the diff (what changed between attempts)
                 - Group by tool type (Bash, Edit, etc.)

              2. Add heuristics for common patterns:
                 - Command syntax fixes (quoting, escaping)
                 - File path corrections
                 - Permission/access fixes
                 - API retry with rate limiting

              3. Create confidence scoring:
                 - High: Clear fix, obvious pattern
                 - Medium: Plausible fix, moderate evidence
                 - Low: Unclear if fix was causal

              ### Success Criteria
              - Script detects at least 80% of retry patterns
              - Confidence scores are reasonable
              - False positives are < 20%


              ## Success Criteria
              All scenarios must pass (score = 1) for the step to be complete.
              Total scenarios: [N]
              Required score: [N]/[N]

              ---

              ## Scenario 1: [Name]
              [Full gherkin with verification as shown above]

              ---

              ## Scenario 2: [Name]
              ...

              [Continue for 4-8 scenarios]
              ```

              ## Commit
              ```bash
              git add artifacts/step-4-gherkin.md
              git commit -m "plan(step-4): define gherkin scenarios"
              ```
          - id: context
            status: pending
            prompt: |
              Gather step-specific context for implementation.

              ## Your Task
              ## Phase 2.2: Error Pattern Detection

              Implement retry pattern identification:

              ### Tasks
              1. Create scripts/find-retry-patterns.sh:
                 - Input: parsed transcript with errors
                 - Detect sequences: error -> retry -> success
                 - Extract the diff (what changed between attempts)
                 - Group by tool type (Bash, Edit, etc.)

              2. Add heuristics for common patterns:
                 - Command syntax fixes (quoting, escaping)
                 - File path corrections
                 - Permission/access fixes
                 - API retry with rate limiting

              3. Create confidence scoring:
                 - High: Clear fix, obvious pattern
                 - Medium: Plausible fix, moderate evidence
                 - Low: Unclear if fix was causal

              ### Success Criteria
              - Script detects at least 80% of retry patterns
              - Confidence scores are reasonable
              - False positives are < 20%


              ## Shared Context
              Read: context/_shared-context.md (already has project-wide patterns)
              Read: artifacts/step-4-gherkin.md (scenarios to implement)

              ## Instructions
              Research the specific code areas this step will touch:

              1. **Related Existing Code**
                 - Find similar implementations to follow as patterns
                 - Identify modules this step will import from
                 - Note any interfaces/types to implement or extend

              2. **Dependencies**
                 - List imports needed from internal modules
                 - List any new external packages needed
                 - Check for peer dependencies or version constraints

              3. **Integration Points**
                 - How will this code be called/used?
                 - What modules will import from this step's output?
                 - Are there existing tests to extend?

              4. **Specific Patterns**
                 - Error handling patterns used in similar code
                 - Naming conventions for this area
                 - File organization patterns

              ## Output
              Create: context/step-4-context.md

              ```markdown
              # Step Context: step-4

              ## Task
              ## Phase 2.2: Error Pattern Detection

              Implement retry pattern identification:

              ### Tasks
              1. Create scripts/find-retry-patterns.sh:
                 - Input: parsed transcript with errors
                 - Detect sequences: error -> retry -> success
                 - Extract the diff (what changed between attempts)
                 - Group by tool type (Bash, Edit, etc.)

              2. Add heuristics for common patterns:
                 - Command syntax fixes (quoting, escaping)
                 - File path corrections
                 - Permission/access fixes
                 - API retry with rate limiting

              3. Create confidence scoring:
                 - High: Clear fix, obvious pattern
                 - Medium: Plausible fix, moderate evidence
                 - Low: Unclear if fix was causal

              ### Success Criteria
              - Script detects at least 80% of retry patterns
              - Confidence scores are reasonable
              - False positives are < 20%


              ## Related Code Patterns

              ### Similar Implementation: [path]
              ```typescript
              // Key pattern to follow
              [relevant code snippet]
              ```

              ### Similar Implementation: [path]
              [continue as needed]

              ## Required Imports
              ### Internal
              - `[module]`: [what to import]

              ### External
              - `[package]`: [what to import]

              ## Types/Interfaces to Use
              ```typescript
              // From [source]
              interface [Name] {
                [relevant fields]
              }
              ```

              ## Integration Points
              - Called by: [who will use this]
              - Calls: [what this will call]
              - Tests: [related test files]

              ## Implementation Notes
              - [Specific note 1]
              - [Specific note 2]
              ```

              ## Commit
              ```bash
              git add context/step-4-context.md
              git commit -m "context(step-4): gather implementation context"
              ```
          - id: execute
            status: pending
            prompt: |
              Implement the step following gherkin scenarios and context.

              ## Your Task
              ## Phase 2.2: Error Pattern Detection

              Implement retry pattern identification:

              ### Tasks
              1. Create scripts/find-retry-patterns.sh:
                 - Input: parsed transcript with errors
                 - Detect sequences: error -> retry -> success
                 - Extract the diff (what changed between attempts)
                 - Group by tool type (Bash, Edit, etc.)

              2. Add heuristics for common patterns:
                 - Command syntax fixes (quoting, escaping)
                 - File path corrections
                 - Permission/access fixes
                 - API retry with rate limiting

              3. Create confidence scoring:
                 - High: Clear fix, obvious pattern
                 - Medium: Plausible fix, moderate evidence
                 - Low: Unclear if fix was causal

              ### Success Criteria
              - Script detects at least 80% of retry patterns
              - Confidence scores are reasonable
              - False positives are < 20%


              ## MUST READ BEFORE IMPLEMENTING
              Read these files in order:
              1. context/_shared-context.md (project patterns, conventions)
              2. context/sprint-plan.md (how this fits in sprint)
              3. artifacts/step-4-gherkin.md (scenarios to satisfy)
              4. context/step-4-context.md (specific patterns, imports)

              ## Implementation Rules

              ### Follow the Gherkin
              Your implementation MUST satisfy ALL gherkin scenarios.
              Each scenario has a verification command - mentally run it to check your work.

              ### Follow the Context
              - Use patterns from similar implementations
              - Import from specified modules
              - Implement required interfaces
              - Follow naming conventions

              ### Code Quality
              - Keep code simple and focused
              - Follow existing patterns exactly
              - No over-engineering or extra abstractions
              - Only implement what's needed for the scenarios

              ### Commits
              Make atomic commits for logical units:
              ```bash
              # After each logical piece
              git add [files]
              git commit -m "[type](step-4): [description]"
              ```

              Types: feat, fix, refactor, test, docs

              ## Implementation Checklist
              Before marking complete, verify:
              - [ ] All files from gherkin scenarios exist
              - [ ] Code follows patterns from context
              - [ ] Imports are correct
              - [ ] No TypeScript errors (run typecheck mentally)
              - [ ] Each scenario's verification should pass

              ## If Blocked
              If you encounter an issue that prevents completion:
              - Document the blocker clearly
              - Set status to needs-human
              - Do NOT leave partial/broken implementation
          - id: qa
            status: pending
            prompt: |
              Verify implementation against gherkin scenarios.

              ## Context
              Read: artifacts/step-4-gherkin.md (scenarios with verification commands)

              ## Step 1: Run Each Verification

              For EACH scenario in the gherkin file:
              1. Run the verification command
              2. Record the result: 1 (pass) or 0 (fail)
              3. If fail, capture the error output

              ## Step 2: Calculate Score

              Score = (passed scenarios) / (total scenarios)
              - Score = 1.0 (all pass) → PASS
              - Score < 1.0 (any fail) → FAIL

              ## Step 3: Generate QA Report

              Create: artifacts/step-4-qa-report.md

              ```markdown
              # QA Report: step-4

              ## Summary
              - Total Scenarios: [N]
              - Passed: [N]
              - Failed: [N]
              - Score: [X]/[N] = [percentage]%

              ## Verification Results

              | # | Scenario | Result | Details |
              |---|----------|--------|---------|
              | 1 | [Name] | PASS/FAIL | [output or error] |
              | 2 | [Name] | PASS/FAIL | [output or error] |
              ...

              ## Detailed Results

              ### Scenario 1: [Name]
              **Verification**: `[command]`
              **Exit Code**: [0 or N]
              **Output**:
              ```
              [actual output]
              ```
              **Result**: PASS / FAIL

              ### Scenario 2: [Name]
              ...

              ## Issues Found
              [If any failures, describe each issue]

              1. **[Scenario name]**: [What failed and why]

              ## Status: PASS / FAIL
              ```

              ## Step 4: Handle Outcome

              ### If ALL scenarios PASS (Score = 100%):
              1. Ensure report shows "Status: PASS"
              2. Commit the report:
                 ```bash
                 git add artifacts/step-4-qa-report.md
                 git commit -m "qa(step-4): all scenarios passed"
                 ```
              3. Mark phase as completed

              ### If ANY scenario FAILS (Score < 100%):
              You MUST inject fix phases. Do NOT just report and continue.

              1. Ensure report shows "Status: FAIL" with specific issues

              2. Find the PROGRESS.yaml file:
                 ```bash
                 PROGRESS_FILE=$(find .claude/sprints -name "PROGRESS.yaml" -type f 2>/dev/null | head -1)
                 echo "Found: $PROGRESS_FILE"
                 ```

              3. Inject fix and re-verify phases using yq:
                 ```bash
                 yq -i '
                   (.phases[] | select(.steps) | .steps[] | select(.status == "in-progress") | .phases) +=
                   [
                     {
                       "id": "fix",
                       "status": "pending",
                       "prompt": "Fix failing scenarios for step-4.\n\n## Context\nRead: artifacts/step-4-qa-report.md\n\n## Instructions\n1. Review each FAIL scenario\n2. Fix the implementation to make it pass\n3. Re-run the verification command to confirm\n4. Make atomic commits for each fix\n\n## After Fixing\nDo NOT mark as complete until ALL verifications pass."
                     },
                     {
                       "id": "reverify",
                       "status": "pending",
                       "prompt": "Re-verify all scenarios after fixes.\n\n## Instructions\nRe-run ALL verification commands from artifacts/step-4-gherkin.md\n\n## If ALL pass:\n- Update artifacts/step-4-qa-report.md with PASS status\n- Commit the updated report\n\n## If ANY still fail:\n- Update the QA report with new results\n- Inject another fix phase using yq\n- Loop continues until all pass"
                     }
                   ]
                 ' "$PROGRESS_FILE"
                 ```

              4. Mark current QA phase as failed:
                 ```bash
                 yq -i '
                   (.. | select(.id == "qa" and .status == "in-progress")) |=
                   (.status = "failed" | .error = "step-4 QA failed - see report - fix phase injected")
                 ' "$PROGRESS_FILE"
                 ```

              5. The sprint loop will now execute fix → reverify phases

              ## Important
              - EVERY scenario must pass for the step to be complete
              - Failed QA MUST inject fix phases, not just report
              - This creates a self-healing loop until all pass
          - id: verify
            status: pending
            prompt: |
              Final integration verification for the step.

              ## Your Task
              ## Phase 2.2: Error Pattern Detection

              Implement retry pattern identification:

              ### Tasks
              1. Create scripts/find-retry-patterns.sh:
                 - Input: parsed transcript with errors
                 - Detect sequences: error -> retry -> success
                 - Extract the diff (what changed between attempts)
                 - Group by tool type (Bash, Edit, etc.)

              2. Add heuristics for common patterns:
                 - Command syntax fixes (quoting, escaping)
                 - File path corrections
                 - Permission/access fixes
                 - API retry with rate limiting

              3. Create confidence scoring:
                 - High: Clear fix, obvious pattern
                 - Medium: Plausible fix, moderate evidence
                 - Low: Unclear if fix was causal

              ### Success Criteria
              - Script detects at least 80% of retry patterns
              - Confidence scores are reasonable
              - False positives are < 20%


              ## Context
              Read: context/_shared-context.md (build commands)
              Read: artifacts/step-4-qa-report.md (should show PASS)

              ## Step 1: Build Verification
              Run the project build to ensure this step integrates:
              ```bash
              # Use commands from _shared-context.md, typically:
              npm run build
              npm run typecheck
              ```

              ## Step 2: Integration Check
              Verify this step works with the rest of the sprint:
              - Check imports resolve correctly
              - Verify no circular dependencies
              - Ensure types are compatible

              ## Step 3: Smoke Test
              If possible, manually verify the functionality:
              - Run the code path that uses this step's output
              - Check expected behavior matches gherkin scenarios

              ## Step 4: Final Commit
              If all verification passes:
              ```bash
              git add -A
              git status  # Check for any uncommitted changes
              # Only commit if there are changes
              git diff --cached --quiet || git commit -m "verify(step-4): integration verified"
              ```

              ## Outcome
              - If integration passes: Mark step as complete
              - If integration fails: Document the issue and set status to needs-human

              ## Important
              This is the final gate before moving to the next step.
              The step's gherkin scenarios already passed in QA.
              This phase ensures the step works in the broader context.
      - id: step-5
        prompt: |
          ## Phase 2.3: Target CLAUDE.md Inference

          Implement logic to infer where signs should be stored:

          ### Tasks
          1. Create scripts/infer-target.sh:
             - Input: file paths from tool calls
             - Extract common directory prefix
             - Check for existing CLAUDE.md in hierarchy
             - Suggest target CLAUDE.md path

          2. Add rules:
             - Scripts/automation -> scripts/CLAUDE.md
             - API code -> api/CLAUDE.md
             - General/cross-cutting -> project root CLAUDE.md
             - Tool-specific -> create new CLAUDE.md if needed

          3. Support manual override in extraction

          ### Success Criteria
          - Inference is accurate for 90% of cases
          - Edge cases have reasonable defaults
          - User can override if needed
        status: pending
        phases:
          - id: plan
            status: pending
            prompt: |
              Generate binary-verifiable gherkin scenarios for this step.

              ## Your Task
              ## Phase 2.3: Target CLAUDE.md Inference

              Implement logic to infer where signs should be stored:

              ### Tasks
              1. Create scripts/infer-target.sh:
                 - Input: file paths from tool calls
                 - Extract common directory prefix
                 - Check for existing CLAUDE.md in hierarchy
                 - Suggest target CLAUDE.md path

              2. Add rules:
                 - Scripts/automation -> scripts/CLAUDE.md
                 - API code -> api/CLAUDE.md
                 - General/cross-cutting -> project root CLAUDE.md
                 - Tool-specific -> create new CLAUDE.md if needed

              3. Support manual override in extraction

              ### Success Criteria
              - Inference is accurate for 90% of cases
              - Edge cases have reasonable defaults
              - User can override if needed


              ## Shared Context
              Read: context/_shared-context.md (project patterns, conventions, commands)
              Read: context/sprint-plan.md (how this step fits in the sprint)

              ## Instructions
              Create 4-8 gherkin scenarios that, when ALL pass, prove the step is complete.
              Each scenario MUST have:
              1. Clear Given/When/Then structure
              2. An explicit verification command that returns exit code 0 on success
              3. Binary outcome: exactly 1 (pass) or 0 (fail)

              ## Gherkin Format
              Each scenario follows this exact structure:

              ```gherkin
              Scenario: [Descriptive name]
                Given [precondition or context]
                When [action taken]
                Then [expected outcome]

              Verification: `[shell command that exits 0 on success, non-zero on failure]`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ## Example Scenarios

              ### File Existence
              ```gherkin
              Scenario: Source file exists
                Given the project structure is set up
                When I check for the module file
                Then src/auth/service.ts exists

              Verification: `test -f src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### TypeScript Compilation
              ```gherkin
              Scenario: TypeScript compiles without errors
                Given the file src/auth/service.ts exists
                When I run the TypeScript compiler
                Then no compilation errors occur

              Verification: `npx tsc --noEmit src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Function Export
              ```gherkin
              Scenario: Login function is exported
                Given src/auth/service.ts exists
                When I check for the login export
                Then the function is publicly available

              Verification: `grep -q "export.*function login\|export.*const login\|export { login" src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### Test Execution
              ```gherkin
              Scenario: Unit tests pass
                Given tests exist in src/auth/service.test.ts
                When I run the test suite
                Then all tests pass

              Verification: `npm test -- --testPathPattern="auth/service" --passWithNoTests 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Lint Check
              ```gherkin
              Scenario: Code passes linting
                Given the implementation is complete
                When I run the linter
                Then no lint errors in new files

              Verification: `npm run lint -- src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ## Output
              Create: artifacts/step-5-gherkin.md

              ```markdown
              # Gherkin Scenarios: step-5

              ## Step Task
              ## Phase 2.3: Target CLAUDE.md Inference

              Implement logic to infer where signs should be stored:

              ### Tasks
              1. Create scripts/infer-target.sh:
                 - Input: file paths from tool calls
                 - Extract common directory prefix
                 - Check for existing CLAUDE.md in hierarchy
                 - Suggest target CLAUDE.md path

              2. Add rules:
                 - Scripts/automation -> scripts/CLAUDE.md
                 - API code -> api/CLAUDE.md
                 - General/cross-cutting -> project root CLAUDE.md
                 - Tool-specific -> create new CLAUDE.md if needed

              3. Support manual override in extraction

              ### Success Criteria
              - Inference is accurate for 90% of cases
              - Edge cases have reasonable defaults
              - User can override if needed


              ## Success Criteria
              All scenarios must pass (score = 1) for the step to be complete.
              Total scenarios: [N]
              Required score: [N]/[N]

              ---

              ## Scenario 1: [Name]
              [Full gherkin with verification as shown above]

              ---

              ## Scenario 2: [Name]
              ...

              [Continue for 4-8 scenarios]
              ```

              ## Commit
              ```bash
              git add artifacts/step-5-gherkin.md
              git commit -m "plan(step-5): define gherkin scenarios"
              ```
          - id: context
            status: pending
            prompt: |
              Gather step-specific context for implementation.

              ## Your Task
              ## Phase 2.3: Target CLAUDE.md Inference

              Implement logic to infer where signs should be stored:

              ### Tasks
              1. Create scripts/infer-target.sh:
                 - Input: file paths from tool calls
                 - Extract common directory prefix
                 - Check for existing CLAUDE.md in hierarchy
                 - Suggest target CLAUDE.md path

              2. Add rules:
                 - Scripts/automation -> scripts/CLAUDE.md
                 - API code -> api/CLAUDE.md
                 - General/cross-cutting -> project root CLAUDE.md
                 - Tool-specific -> create new CLAUDE.md if needed

              3. Support manual override in extraction

              ### Success Criteria
              - Inference is accurate for 90% of cases
              - Edge cases have reasonable defaults
              - User can override if needed


              ## Shared Context
              Read: context/_shared-context.md (already has project-wide patterns)
              Read: artifacts/step-5-gherkin.md (scenarios to implement)

              ## Instructions
              Research the specific code areas this step will touch:

              1. **Related Existing Code**
                 - Find similar implementations to follow as patterns
                 - Identify modules this step will import from
                 - Note any interfaces/types to implement or extend

              2. **Dependencies**
                 - List imports needed from internal modules
                 - List any new external packages needed
                 - Check for peer dependencies or version constraints

              3. **Integration Points**
                 - How will this code be called/used?
                 - What modules will import from this step's output?
                 - Are there existing tests to extend?

              4. **Specific Patterns**
                 - Error handling patterns used in similar code
                 - Naming conventions for this area
                 - File organization patterns

              ## Output
              Create: context/step-5-context.md

              ```markdown
              # Step Context: step-5

              ## Task
              ## Phase 2.3: Target CLAUDE.md Inference

              Implement logic to infer where signs should be stored:

              ### Tasks
              1. Create scripts/infer-target.sh:
                 - Input: file paths from tool calls
                 - Extract common directory prefix
                 - Check for existing CLAUDE.md in hierarchy
                 - Suggest target CLAUDE.md path

              2. Add rules:
                 - Scripts/automation -> scripts/CLAUDE.md
                 - API code -> api/CLAUDE.md
                 - General/cross-cutting -> project root CLAUDE.md
                 - Tool-specific -> create new CLAUDE.md if needed

              3. Support manual override in extraction

              ### Success Criteria
              - Inference is accurate for 90% of cases
              - Edge cases have reasonable defaults
              - User can override if needed


              ## Related Code Patterns

              ### Similar Implementation: [path]
              ```typescript
              // Key pattern to follow
              [relevant code snippet]
              ```

              ### Similar Implementation: [path]
              [continue as needed]

              ## Required Imports
              ### Internal
              - `[module]`: [what to import]

              ### External
              - `[package]`: [what to import]

              ## Types/Interfaces to Use
              ```typescript
              // From [source]
              interface [Name] {
                [relevant fields]
              }
              ```

              ## Integration Points
              - Called by: [who will use this]
              - Calls: [what this will call]
              - Tests: [related test files]

              ## Implementation Notes
              - [Specific note 1]
              - [Specific note 2]
              ```

              ## Commit
              ```bash
              git add context/step-5-context.md
              git commit -m "context(step-5): gather implementation context"
              ```
          - id: execute
            status: pending
            prompt: |
              Implement the step following gherkin scenarios and context.

              ## Your Task
              ## Phase 2.3: Target CLAUDE.md Inference

              Implement logic to infer where signs should be stored:

              ### Tasks
              1. Create scripts/infer-target.sh:
                 - Input: file paths from tool calls
                 - Extract common directory prefix
                 - Check for existing CLAUDE.md in hierarchy
                 - Suggest target CLAUDE.md path

              2. Add rules:
                 - Scripts/automation -> scripts/CLAUDE.md
                 - API code -> api/CLAUDE.md
                 - General/cross-cutting -> project root CLAUDE.md
                 - Tool-specific -> create new CLAUDE.md if needed

              3. Support manual override in extraction

              ### Success Criteria
              - Inference is accurate for 90% of cases
              - Edge cases have reasonable defaults
              - User can override if needed


              ## MUST READ BEFORE IMPLEMENTING
              Read these files in order:
              1. context/_shared-context.md (project patterns, conventions)
              2. context/sprint-plan.md (how this fits in sprint)
              3. artifacts/step-5-gherkin.md (scenarios to satisfy)
              4. context/step-5-context.md (specific patterns, imports)

              ## Implementation Rules

              ### Follow the Gherkin
              Your implementation MUST satisfy ALL gherkin scenarios.
              Each scenario has a verification command - mentally run it to check your work.

              ### Follow the Context
              - Use patterns from similar implementations
              - Import from specified modules
              - Implement required interfaces
              - Follow naming conventions

              ### Code Quality
              - Keep code simple and focused
              - Follow existing patterns exactly
              - No over-engineering or extra abstractions
              - Only implement what's needed for the scenarios

              ### Commits
              Make atomic commits for logical units:
              ```bash
              # After each logical piece
              git add [files]
              git commit -m "[type](step-5): [description]"
              ```

              Types: feat, fix, refactor, test, docs

              ## Implementation Checklist
              Before marking complete, verify:
              - [ ] All files from gherkin scenarios exist
              - [ ] Code follows patterns from context
              - [ ] Imports are correct
              - [ ] No TypeScript errors (run typecheck mentally)
              - [ ] Each scenario's verification should pass

              ## If Blocked
              If you encounter an issue that prevents completion:
              - Document the blocker clearly
              - Set status to needs-human
              - Do NOT leave partial/broken implementation
          - id: qa
            status: pending
            prompt: |
              Verify implementation against gherkin scenarios.

              ## Context
              Read: artifacts/step-5-gherkin.md (scenarios with verification commands)

              ## Step 1: Run Each Verification

              For EACH scenario in the gherkin file:
              1. Run the verification command
              2. Record the result: 1 (pass) or 0 (fail)
              3. If fail, capture the error output

              ## Step 2: Calculate Score

              Score = (passed scenarios) / (total scenarios)
              - Score = 1.0 (all pass) → PASS
              - Score < 1.0 (any fail) → FAIL

              ## Step 3: Generate QA Report

              Create: artifacts/step-5-qa-report.md

              ```markdown
              # QA Report: step-5

              ## Summary
              - Total Scenarios: [N]
              - Passed: [N]
              - Failed: [N]
              - Score: [X]/[N] = [percentage]%

              ## Verification Results

              | # | Scenario | Result | Details |
              |---|----------|--------|---------|
              | 1 | [Name] | PASS/FAIL | [output or error] |
              | 2 | [Name] | PASS/FAIL | [output or error] |
              ...

              ## Detailed Results

              ### Scenario 1: [Name]
              **Verification**: `[command]`
              **Exit Code**: [0 or N]
              **Output**:
              ```
              [actual output]
              ```
              **Result**: PASS / FAIL

              ### Scenario 2: [Name]
              ...

              ## Issues Found
              [If any failures, describe each issue]

              1. **[Scenario name]**: [What failed and why]

              ## Status: PASS / FAIL
              ```

              ## Step 4: Handle Outcome

              ### If ALL scenarios PASS (Score = 100%):
              1. Ensure report shows "Status: PASS"
              2. Commit the report:
                 ```bash
                 git add artifacts/step-5-qa-report.md
                 git commit -m "qa(step-5): all scenarios passed"
                 ```
              3. Mark phase as completed

              ### If ANY scenario FAILS (Score < 100%):
              You MUST inject fix phases. Do NOT just report and continue.

              1. Ensure report shows "Status: FAIL" with specific issues

              2. Find the PROGRESS.yaml file:
                 ```bash
                 PROGRESS_FILE=$(find .claude/sprints -name "PROGRESS.yaml" -type f 2>/dev/null | head -1)
                 echo "Found: $PROGRESS_FILE"
                 ```

              3. Inject fix and re-verify phases using yq:
                 ```bash
                 yq -i '
                   (.phases[] | select(.steps) | .steps[] | select(.status == "in-progress") | .phases) +=
                   [
                     {
                       "id": "fix",
                       "status": "pending",
                       "prompt": "Fix failing scenarios for step-5.\n\n## Context\nRead: artifacts/step-5-qa-report.md\n\n## Instructions\n1. Review each FAIL scenario\n2. Fix the implementation to make it pass\n3. Re-run the verification command to confirm\n4. Make atomic commits for each fix\n\n## After Fixing\nDo NOT mark as complete until ALL verifications pass."
                     },
                     {
                       "id": "reverify",
                       "status": "pending",
                       "prompt": "Re-verify all scenarios after fixes.\n\n## Instructions\nRe-run ALL verification commands from artifacts/step-5-gherkin.md\n\n## If ALL pass:\n- Update artifacts/step-5-qa-report.md with PASS status\n- Commit the updated report\n\n## If ANY still fail:\n- Update the QA report with new results\n- Inject another fix phase using yq\n- Loop continues until all pass"
                     }
                   ]
                 ' "$PROGRESS_FILE"
                 ```

              4. Mark current QA phase as failed:
                 ```bash
                 yq -i '
                   (.. | select(.id == "qa" and .status == "in-progress")) |=
                   (.status = "failed" | .error = "step-5 QA failed - see report - fix phase injected")
                 ' "$PROGRESS_FILE"
                 ```

              5. The sprint loop will now execute fix → reverify phases

              ## Important
              - EVERY scenario must pass for the step to be complete
              - Failed QA MUST inject fix phases, not just report
              - This creates a self-healing loop until all pass
          - id: verify
            status: pending
            prompt: |
              Final integration verification for the step.

              ## Your Task
              ## Phase 2.3: Target CLAUDE.md Inference

              Implement logic to infer where signs should be stored:

              ### Tasks
              1. Create scripts/infer-target.sh:
                 - Input: file paths from tool calls
                 - Extract common directory prefix
                 - Check for existing CLAUDE.md in hierarchy
                 - Suggest target CLAUDE.md path

              2. Add rules:
                 - Scripts/automation -> scripts/CLAUDE.md
                 - API code -> api/CLAUDE.md
                 - General/cross-cutting -> project root CLAUDE.md
                 - Tool-specific -> create new CLAUDE.md if needed

              3. Support manual override in extraction

              ### Success Criteria
              - Inference is accurate for 90% of cases
              - Edge cases have reasonable defaults
              - User can override if needed


              ## Context
              Read: context/_shared-context.md (build commands)
              Read: artifacts/step-5-qa-report.md (should show PASS)

              ## Step 1: Build Verification
              Run the project build to ensure this step integrates:
              ```bash
              # Use commands from _shared-context.md, typically:
              npm run build
              npm run typecheck
              ```

              ## Step 2: Integration Check
              Verify this step works with the rest of the sprint:
              - Check imports resolve correctly
              - Verify no circular dependencies
              - Ensure types are compatible

              ## Step 3: Smoke Test
              If possible, manually verify the functionality:
              - Run the code path that uses this step's output
              - Check expected behavior matches gherkin scenarios

              ## Step 4: Final Commit
              If all verification passes:
              ```bash
              git add -A
              git status  # Check for any uncommitted changes
              # Only commit if there are changes
              git diff --cached --quiet || git commit -m "verify(step-5): integration verified"
              ```

              ## Outcome
              - If integration passes: Mark step as complete
              - If integration fails: Document the issue and set status to needs-human

              ## Important
              This is the final gate before moving to the next step.
              The step's gherkin scenarios already passed in QA.
              This phase ensures the step works in the broader context.
      - id: step-6
        prompt: |
          ## Phase 2.4: Extraction Command

          Implement /m42-signs:extract command:

          ### Tasks
          1. Create commands/extract.md:
             - Proper frontmatter (description, allowed-tools, model)
             - Accept session ID or transcript file path
             - Find session file in ~/.claude/projects/ if ID given
             - Run parsing -> retry detection -> target inference pipeline
             - Generate learning entries in backlog format
             - Write to .claude/learnings/backlog.yaml (append mode)
             - Output summary of proposed learnings

          2. Add options:
             - --dry-run: show what would be extracted
             - --confidence-min: filter by confidence level
             - --auto-approve: skip review for high-confidence

          3. Handle edge cases:
             - No errors found -> "No learnings to extract"
             - Session file not found -> clear error
             - Malformed JSONL -> graceful failure

          ### Success Criteria
          - Extract works with session ID and file path
          - Proposed learnings are reasonable
          - Backlog is properly updated
        status: pending
        phases:
          - id: plan
            status: pending
            prompt: |
              Generate binary-verifiable gherkin scenarios for this step.

              ## Your Task
              ## Phase 2.4: Extraction Command

              Implement /m42-signs:extract command:

              ### Tasks
              1. Create commands/extract.md:
                 - Proper frontmatter (description, allowed-tools, model)
                 - Accept session ID or transcript file path
                 - Find session file in ~/.claude/projects/ if ID given
                 - Run parsing -> retry detection -> target inference pipeline
                 - Generate learning entries in backlog format
                 - Write to .claude/learnings/backlog.yaml (append mode)
                 - Output summary of proposed learnings

              2. Add options:
                 - --dry-run: show what would be extracted
                 - --confidence-min: filter by confidence level
                 - --auto-approve: skip review for high-confidence

              3. Handle edge cases:
                 - No errors found -> "No learnings to extract"
                 - Session file not found -> clear error
                 - Malformed JSONL -> graceful failure

              ### Success Criteria
              - Extract works with session ID and file path
              - Proposed learnings are reasonable
              - Backlog is properly updated


              ## Shared Context
              Read: context/_shared-context.md (project patterns, conventions, commands)
              Read: context/sprint-plan.md (how this step fits in the sprint)

              ## Instructions
              Create 4-8 gherkin scenarios that, when ALL pass, prove the step is complete.
              Each scenario MUST have:
              1. Clear Given/When/Then structure
              2. An explicit verification command that returns exit code 0 on success
              3. Binary outcome: exactly 1 (pass) or 0 (fail)

              ## Gherkin Format
              Each scenario follows this exact structure:

              ```gherkin
              Scenario: [Descriptive name]
                Given [precondition or context]
                When [action taken]
                Then [expected outcome]

              Verification: `[shell command that exits 0 on success, non-zero on failure]`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ## Example Scenarios

              ### File Existence
              ```gherkin
              Scenario: Source file exists
                Given the project structure is set up
                When I check for the module file
                Then src/auth/service.ts exists

              Verification: `test -f src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### TypeScript Compilation
              ```gherkin
              Scenario: TypeScript compiles without errors
                Given the file src/auth/service.ts exists
                When I run the TypeScript compiler
                Then no compilation errors occur

              Verification: `npx tsc --noEmit src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Function Export
              ```gherkin
              Scenario: Login function is exported
                Given src/auth/service.ts exists
                When I check for the login export
                Then the function is publicly available

              Verification: `grep -q "export.*function login\|export.*const login\|export { login" src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### Test Execution
              ```gherkin
              Scenario: Unit tests pass
                Given tests exist in src/auth/service.test.ts
                When I run the test suite
                Then all tests pass

              Verification: `npm test -- --testPathPattern="auth/service" --passWithNoTests 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Lint Check
              ```gherkin
              Scenario: Code passes linting
                Given the implementation is complete
                When I run the linter
                Then no lint errors in new files

              Verification: `npm run lint -- src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ## Output
              Create: artifacts/step-6-gherkin.md

              ```markdown
              # Gherkin Scenarios: step-6

              ## Step Task
              ## Phase 2.4: Extraction Command

              Implement /m42-signs:extract command:

              ### Tasks
              1. Create commands/extract.md:
                 - Proper frontmatter (description, allowed-tools, model)
                 - Accept session ID or transcript file path
                 - Find session file in ~/.claude/projects/ if ID given
                 - Run parsing -> retry detection -> target inference pipeline
                 - Generate learning entries in backlog format
                 - Write to .claude/learnings/backlog.yaml (append mode)
                 - Output summary of proposed learnings

              2. Add options:
                 - --dry-run: show what would be extracted
                 - --confidence-min: filter by confidence level
                 - --auto-approve: skip review for high-confidence

              3. Handle edge cases:
                 - No errors found -> "No learnings to extract"
                 - Session file not found -> clear error
                 - Malformed JSONL -> graceful failure

              ### Success Criteria
              - Extract works with session ID and file path
              - Proposed learnings are reasonable
              - Backlog is properly updated


              ## Success Criteria
              All scenarios must pass (score = 1) for the step to be complete.
              Total scenarios: [N]
              Required score: [N]/[N]

              ---

              ## Scenario 1: [Name]
              [Full gherkin with verification as shown above]

              ---

              ## Scenario 2: [Name]
              ...

              [Continue for 4-8 scenarios]
              ```

              ## Commit
              ```bash
              git add artifacts/step-6-gherkin.md
              git commit -m "plan(step-6): define gherkin scenarios"
              ```
          - id: context
            status: pending
            prompt: |
              Gather step-specific context for implementation.

              ## Your Task
              ## Phase 2.4: Extraction Command

              Implement /m42-signs:extract command:

              ### Tasks
              1. Create commands/extract.md:
                 - Proper frontmatter (description, allowed-tools, model)
                 - Accept session ID or transcript file path
                 - Find session file in ~/.claude/projects/ if ID given
                 - Run parsing -> retry detection -> target inference pipeline
                 - Generate learning entries in backlog format
                 - Write to .claude/learnings/backlog.yaml (append mode)
                 - Output summary of proposed learnings

              2. Add options:
                 - --dry-run: show what would be extracted
                 - --confidence-min: filter by confidence level
                 - --auto-approve: skip review for high-confidence

              3. Handle edge cases:
                 - No errors found -> "No learnings to extract"
                 - Session file not found -> clear error
                 - Malformed JSONL -> graceful failure

              ### Success Criteria
              - Extract works with session ID and file path
              - Proposed learnings are reasonable
              - Backlog is properly updated


              ## Shared Context
              Read: context/_shared-context.md (already has project-wide patterns)
              Read: artifacts/step-6-gherkin.md (scenarios to implement)

              ## Instructions
              Research the specific code areas this step will touch:

              1. **Related Existing Code**
                 - Find similar implementations to follow as patterns
                 - Identify modules this step will import from
                 - Note any interfaces/types to implement or extend

              2. **Dependencies**
                 - List imports needed from internal modules
                 - List any new external packages needed
                 - Check for peer dependencies or version constraints

              3. **Integration Points**
                 - How will this code be called/used?
                 - What modules will import from this step's output?
                 - Are there existing tests to extend?

              4. **Specific Patterns**
                 - Error handling patterns used in similar code
                 - Naming conventions for this area
                 - File organization patterns

              ## Output
              Create: context/step-6-context.md

              ```markdown
              # Step Context: step-6

              ## Task
              ## Phase 2.4: Extraction Command

              Implement /m42-signs:extract command:

              ### Tasks
              1. Create commands/extract.md:
                 - Proper frontmatter (description, allowed-tools, model)
                 - Accept session ID or transcript file path
                 - Find session file in ~/.claude/projects/ if ID given
                 - Run parsing -> retry detection -> target inference pipeline
                 - Generate learning entries in backlog format
                 - Write to .claude/learnings/backlog.yaml (append mode)
                 - Output summary of proposed learnings

              2. Add options:
                 - --dry-run: show what would be extracted
                 - --confidence-min: filter by confidence level
                 - --auto-approve: skip review for high-confidence

              3. Handle edge cases:
                 - No errors found -> "No learnings to extract"
                 - Session file not found -> clear error
                 - Malformed JSONL -> graceful failure

              ### Success Criteria
              - Extract works with session ID and file path
              - Proposed learnings are reasonable
              - Backlog is properly updated


              ## Related Code Patterns

              ### Similar Implementation: [path]
              ```typescript
              // Key pattern to follow
              [relevant code snippet]
              ```

              ### Similar Implementation: [path]
              [continue as needed]

              ## Required Imports
              ### Internal
              - `[module]`: [what to import]

              ### External
              - `[package]`: [what to import]

              ## Types/Interfaces to Use
              ```typescript
              // From [source]
              interface [Name] {
                [relevant fields]
              }
              ```

              ## Integration Points
              - Called by: [who will use this]
              - Calls: [what this will call]
              - Tests: [related test files]

              ## Implementation Notes
              - [Specific note 1]
              - [Specific note 2]
              ```

              ## Commit
              ```bash
              git add context/step-6-context.md
              git commit -m "context(step-6): gather implementation context"
              ```
          - id: execute
            status: pending
            prompt: |
              Implement the step following gherkin scenarios and context.

              ## Your Task
              ## Phase 2.4: Extraction Command

              Implement /m42-signs:extract command:

              ### Tasks
              1. Create commands/extract.md:
                 - Proper frontmatter (description, allowed-tools, model)
                 - Accept session ID or transcript file path
                 - Find session file in ~/.claude/projects/ if ID given
                 - Run parsing -> retry detection -> target inference pipeline
                 - Generate learning entries in backlog format
                 - Write to .claude/learnings/backlog.yaml (append mode)
                 - Output summary of proposed learnings

              2. Add options:
                 - --dry-run: show what would be extracted
                 - --confidence-min: filter by confidence level
                 - --auto-approve: skip review for high-confidence

              3. Handle edge cases:
                 - No errors found -> "No learnings to extract"
                 - Session file not found -> clear error
                 - Malformed JSONL -> graceful failure

              ### Success Criteria
              - Extract works with session ID and file path
              - Proposed learnings are reasonable
              - Backlog is properly updated


              ## MUST READ BEFORE IMPLEMENTING
              Read these files in order:
              1. context/_shared-context.md (project patterns, conventions)
              2. context/sprint-plan.md (how this fits in sprint)
              3. artifacts/step-6-gherkin.md (scenarios to satisfy)
              4. context/step-6-context.md (specific patterns, imports)

              ## Implementation Rules

              ### Follow the Gherkin
              Your implementation MUST satisfy ALL gherkin scenarios.
              Each scenario has a verification command - mentally run it to check your work.

              ### Follow the Context
              - Use patterns from similar implementations
              - Import from specified modules
              - Implement required interfaces
              - Follow naming conventions

              ### Code Quality
              - Keep code simple and focused
              - Follow existing patterns exactly
              - No over-engineering or extra abstractions
              - Only implement what's needed for the scenarios

              ### Commits
              Make atomic commits for logical units:
              ```bash
              # After each logical piece
              git add [files]
              git commit -m "[type](step-6): [description]"
              ```

              Types: feat, fix, refactor, test, docs

              ## Implementation Checklist
              Before marking complete, verify:
              - [ ] All files from gherkin scenarios exist
              - [ ] Code follows patterns from context
              - [ ] Imports are correct
              - [ ] No TypeScript errors (run typecheck mentally)
              - [ ] Each scenario's verification should pass

              ## If Blocked
              If you encounter an issue that prevents completion:
              - Document the blocker clearly
              - Set status to needs-human
              - Do NOT leave partial/broken implementation
          - id: qa
            status: pending
            prompt: |
              Verify implementation against gherkin scenarios.

              ## Context
              Read: artifacts/step-6-gherkin.md (scenarios with verification commands)

              ## Step 1: Run Each Verification

              For EACH scenario in the gherkin file:
              1. Run the verification command
              2. Record the result: 1 (pass) or 0 (fail)
              3. If fail, capture the error output

              ## Step 2: Calculate Score

              Score = (passed scenarios) / (total scenarios)
              - Score = 1.0 (all pass) → PASS
              - Score < 1.0 (any fail) → FAIL

              ## Step 3: Generate QA Report

              Create: artifacts/step-6-qa-report.md

              ```markdown
              # QA Report: step-6

              ## Summary
              - Total Scenarios: [N]
              - Passed: [N]
              - Failed: [N]
              - Score: [X]/[N] = [percentage]%

              ## Verification Results

              | # | Scenario | Result | Details |
              |---|----------|--------|---------|
              | 1 | [Name] | PASS/FAIL | [output or error] |
              | 2 | [Name] | PASS/FAIL | [output or error] |
              ...

              ## Detailed Results

              ### Scenario 1: [Name]
              **Verification**: `[command]`
              **Exit Code**: [0 or N]
              **Output**:
              ```
              [actual output]
              ```
              **Result**: PASS / FAIL

              ### Scenario 2: [Name]
              ...

              ## Issues Found
              [If any failures, describe each issue]

              1. **[Scenario name]**: [What failed and why]

              ## Status: PASS / FAIL
              ```

              ## Step 4: Handle Outcome

              ### If ALL scenarios PASS (Score = 100%):
              1. Ensure report shows "Status: PASS"
              2. Commit the report:
                 ```bash
                 git add artifacts/step-6-qa-report.md
                 git commit -m "qa(step-6): all scenarios passed"
                 ```
              3. Mark phase as completed

              ### If ANY scenario FAILS (Score < 100%):
              You MUST inject fix phases. Do NOT just report and continue.

              1. Ensure report shows "Status: FAIL" with specific issues

              2. Find the PROGRESS.yaml file:
                 ```bash
                 PROGRESS_FILE=$(find .claude/sprints -name "PROGRESS.yaml" -type f 2>/dev/null | head -1)
                 echo "Found: $PROGRESS_FILE"
                 ```

              3. Inject fix and re-verify phases using yq:
                 ```bash
                 yq -i '
                   (.phases[] | select(.steps) | .steps[] | select(.status == "in-progress") | .phases) +=
                   [
                     {
                       "id": "fix",
                       "status": "pending",
                       "prompt": "Fix failing scenarios for step-6.\n\n## Context\nRead: artifacts/step-6-qa-report.md\n\n## Instructions\n1. Review each FAIL scenario\n2. Fix the implementation to make it pass\n3. Re-run the verification command to confirm\n4. Make atomic commits for each fix\n\n## After Fixing\nDo NOT mark as complete until ALL verifications pass."
                     },
                     {
                       "id": "reverify",
                       "status": "pending",
                       "prompt": "Re-verify all scenarios after fixes.\n\n## Instructions\nRe-run ALL verification commands from artifacts/step-6-gherkin.md\n\n## If ALL pass:\n- Update artifacts/step-6-qa-report.md with PASS status\n- Commit the updated report\n\n## If ANY still fail:\n- Update the QA report with new results\n- Inject another fix phase using yq\n- Loop continues until all pass"
                     }
                   ]
                 ' "$PROGRESS_FILE"
                 ```

              4. Mark current QA phase as failed:
                 ```bash
                 yq -i '
                   (.. | select(.id == "qa" and .status == "in-progress")) |=
                   (.status = "failed" | .error = "step-6 QA failed - see report - fix phase injected")
                 ' "$PROGRESS_FILE"
                 ```

              5. The sprint loop will now execute fix → reverify phases

              ## Important
              - EVERY scenario must pass for the step to be complete
              - Failed QA MUST inject fix phases, not just report
              - This creates a self-healing loop until all pass
          - id: verify
            status: pending
            prompt: |
              Final integration verification for the step.

              ## Your Task
              ## Phase 2.4: Extraction Command

              Implement /m42-signs:extract command:

              ### Tasks
              1. Create commands/extract.md:
                 - Proper frontmatter (description, allowed-tools, model)
                 - Accept session ID or transcript file path
                 - Find session file in ~/.claude/projects/ if ID given
                 - Run parsing -> retry detection -> target inference pipeline
                 - Generate learning entries in backlog format
                 - Write to .claude/learnings/backlog.yaml (append mode)
                 - Output summary of proposed learnings

              2. Add options:
                 - --dry-run: show what would be extracted
                 - --confidence-min: filter by confidence level
                 - --auto-approve: skip review for high-confidence

              3. Handle edge cases:
                 - No errors found -> "No learnings to extract"
                 - Session file not found -> clear error
                 - Malformed JSONL -> graceful failure

              ### Success Criteria
              - Extract works with session ID and file path
              - Proposed learnings are reasonable
              - Backlog is properly updated


              ## Context
              Read: context/_shared-context.md (build commands)
              Read: artifacts/step-6-qa-report.md (should show PASS)

              ## Step 1: Build Verification
              Run the project build to ensure this step integrates:
              ```bash
              # Use commands from _shared-context.md, typically:
              npm run build
              npm run typecheck
              ```

              ## Step 2: Integration Check
              Verify this step works with the rest of the sprint:
              - Check imports resolve correctly
              - Verify no circular dependencies
              - Ensure types are compatible

              ## Step 3: Smoke Test
              If possible, manually verify the functionality:
              - Run the code path that uses this step's output
              - Check expected behavior matches gherkin scenarios

              ## Step 4: Final Commit
              If all verification passes:
              ```bash
              git add -A
              git status  # Check for any uncommitted changes
              # Only commit if there are changes
              git diff --cached --quiet || git commit -m "verify(step-6): integration verified"
              ```

              ## Outcome
              - If integration passes: Mark step as complete
              - If integration fails: Document the issue and set status to needs-human

              ## Important
              This is the final gate before moving to the next step.
              The step's gherkin scenarios already passed in QA.
              This phase ensures the step works in the broader context.
      - id: step-7
        prompt: |
          ## Phase 3.1: Interactive Review Command

          Implement /m42-signs:review command:

          ### Tasks
          1. Create commands/review.md:
             - Proper frontmatter (description, allowed-tools, model)
             - Load .claude/learnings/backlog.yaml
             - Filter to status: pending
             - For each learning:
               - Display: title, problem, solution, target, confidence
               - Show context (origin, source tool/error)
               - Prompt: [A]pprove / [R]eject / [E]dit / [S]kip / [Q]uit
             - Update status based on choice
             - Save changes after each decision

          2. Add edit mode:
             - Allow editing title, problem, solution, target
             - Re-validate edited learning
             - Update confidence if significantly changed

          3. Add batch operations:
             - --approve-all-high: auto-approve high confidence
             - --reject-all-low: auto-reject low confidence

          ### Success Criteria
          - Interactive flow is intuitive
          - Edits are validated before saving
          - Batch operations are safe (with confirmation)
        status: pending
        phases:
          - id: plan
            status: pending
            prompt: |
              Generate binary-verifiable gherkin scenarios for this step.

              ## Your Task
              ## Phase 3.1: Interactive Review Command

              Implement /m42-signs:review command:

              ### Tasks
              1. Create commands/review.md:
                 - Proper frontmatter (description, allowed-tools, model)
                 - Load .claude/learnings/backlog.yaml
                 - Filter to status: pending
                 - For each learning:
                   - Display: title, problem, solution, target, confidence
                   - Show context (origin, source tool/error)
                   - Prompt: [A]pprove / [R]eject / [E]dit / [S]kip / [Q]uit
                 - Update status based on choice
                 - Save changes after each decision

              2. Add edit mode:
                 - Allow editing title, problem, solution, target
                 - Re-validate edited learning
                 - Update confidence if significantly changed

              3. Add batch operations:
                 - --approve-all-high: auto-approve high confidence
                 - --reject-all-low: auto-reject low confidence

              ### Success Criteria
              - Interactive flow is intuitive
              - Edits are validated before saving
              - Batch operations are safe (with confirmation)


              ## Shared Context
              Read: context/_shared-context.md (project patterns, conventions, commands)
              Read: context/sprint-plan.md (how this step fits in the sprint)

              ## Instructions
              Create 4-8 gherkin scenarios that, when ALL pass, prove the step is complete.
              Each scenario MUST have:
              1. Clear Given/When/Then structure
              2. An explicit verification command that returns exit code 0 on success
              3. Binary outcome: exactly 1 (pass) or 0 (fail)

              ## Gherkin Format
              Each scenario follows this exact structure:

              ```gherkin
              Scenario: [Descriptive name]
                Given [precondition or context]
                When [action taken]
                Then [expected outcome]

              Verification: `[shell command that exits 0 on success, non-zero on failure]`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ## Example Scenarios

              ### File Existence
              ```gherkin
              Scenario: Source file exists
                Given the project structure is set up
                When I check for the module file
                Then src/auth/service.ts exists

              Verification: `test -f src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### TypeScript Compilation
              ```gherkin
              Scenario: TypeScript compiles without errors
                Given the file src/auth/service.ts exists
                When I run the TypeScript compiler
                Then no compilation errors occur

              Verification: `npx tsc --noEmit src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Function Export
              ```gherkin
              Scenario: Login function is exported
                Given src/auth/service.ts exists
                When I check for the login export
                Then the function is publicly available

              Verification: `grep -q "export.*function login\|export.*const login\|export { login" src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### Test Execution
              ```gherkin
              Scenario: Unit tests pass
                Given tests exist in src/auth/service.test.ts
                When I run the test suite
                Then all tests pass

              Verification: `npm test -- --testPathPattern="auth/service" --passWithNoTests 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Lint Check
              ```gherkin
              Scenario: Code passes linting
                Given the implementation is complete
                When I run the linter
                Then no lint errors in new files

              Verification: `npm run lint -- src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ## Output
              Create: artifacts/step-7-gherkin.md

              ```markdown
              # Gherkin Scenarios: step-7

              ## Step Task
              ## Phase 3.1: Interactive Review Command

              Implement /m42-signs:review command:

              ### Tasks
              1. Create commands/review.md:
                 - Proper frontmatter (description, allowed-tools, model)
                 - Load .claude/learnings/backlog.yaml
                 - Filter to status: pending
                 - For each learning:
                   - Display: title, problem, solution, target, confidence
                   - Show context (origin, source tool/error)
                   - Prompt: [A]pprove / [R]eject / [E]dit / [S]kip / [Q]uit
                 - Update status based on choice
                 - Save changes after each decision

              2. Add edit mode:
                 - Allow editing title, problem, solution, target
                 - Re-validate edited learning
                 - Update confidence if significantly changed

              3. Add batch operations:
                 - --approve-all-high: auto-approve high confidence
                 - --reject-all-low: auto-reject low confidence

              ### Success Criteria
              - Interactive flow is intuitive
              - Edits are validated before saving
              - Batch operations are safe (with confirmation)


              ## Success Criteria
              All scenarios must pass (score = 1) for the step to be complete.
              Total scenarios: [N]
              Required score: [N]/[N]

              ---

              ## Scenario 1: [Name]
              [Full gherkin with verification as shown above]

              ---

              ## Scenario 2: [Name]
              ...

              [Continue for 4-8 scenarios]
              ```

              ## Commit
              ```bash
              git add artifacts/step-7-gherkin.md
              git commit -m "plan(step-7): define gherkin scenarios"
              ```
          - id: context
            status: pending
            prompt: |
              Gather step-specific context for implementation.

              ## Your Task
              ## Phase 3.1: Interactive Review Command

              Implement /m42-signs:review command:

              ### Tasks
              1. Create commands/review.md:
                 - Proper frontmatter (description, allowed-tools, model)
                 - Load .claude/learnings/backlog.yaml
                 - Filter to status: pending
                 - For each learning:
                   - Display: title, problem, solution, target, confidence
                   - Show context (origin, source tool/error)
                   - Prompt: [A]pprove / [R]eject / [E]dit / [S]kip / [Q]uit
                 - Update status based on choice
                 - Save changes after each decision

              2. Add edit mode:
                 - Allow editing title, problem, solution, target
                 - Re-validate edited learning
                 - Update confidence if significantly changed

              3. Add batch operations:
                 - --approve-all-high: auto-approve high confidence
                 - --reject-all-low: auto-reject low confidence

              ### Success Criteria
              - Interactive flow is intuitive
              - Edits are validated before saving
              - Batch operations are safe (with confirmation)


              ## Shared Context
              Read: context/_shared-context.md (already has project-wide patterns)
              Read: artifacts/step-7-gherkin.md (scenarios to implement)

              ## Instructions
              Research the specific code areas this step will touch:

              1. **Related Existing Code**
                 - Find similar implementations to follow as patterns
                 - Identify modules this step will import from
                 - Note any interfaces/types to implement or extend

              2. **Dependencies**
                 - List imports needed from internal modules
                 - List any new external packages needed
                 - Check for peer dependencies or version constraints

              3. **Integration Points**
                 - How will this code be called/used?
                 - What modules will import from this step's output?
                 - Are there existing tests to extend?

              4. **Specific Patterns**
                 - Error handling patterns used in similar code
                 - Naming conventions for this area
                 - File organization patterns

              ## Output
              Create: context/step-7-context.md

              ```markdown
              # Step Context: step-7

              ## Task
              ## Phase 3.1: Interactive Review Command

              Implement /m42-signs:review command:

              ### Tasks
              1. Create commands/review.md:
                 - Proper frontmatter (description, allowed-tools, model)
                 - Load .claude/learnings/backlog.yaml
                 - Filter to status: pending
                 - For each learning:
                   - Display: title, problem, solution, target, confidence
                   - Show context (origin, source tool/error)
                   - Prompt: [A]pprove / [R]eject / [E]dit / [S]kip / [Q]uit
                 - Update status based on choice
                 - Save changes after each decision

              2. Add edit mode:
                 - Allow editing title, problem, solution, target
                 - Re-validate edited learning
                 - Update confidence if significantly changed

              3. Add batch operations:
                 - --approve-all-high: auto-approve high confidence
                 - --reject-all-low: auto-reject low confidence

              ### Success Criteria
              - Interactive flow is intuitive
              - Edits are validated before saving
              - Batch operations are safe (with confirmation)


              ## Related Code Patterns

              ### Similar Implementation: [path]
              ```typescript
              // Key pattern to follow
              [relevant code snippet]
              ```

              ### Similar Implementation: [path]
              [continue as needed]

              ## Required Imports
              ### Internal
              - `[module]`: [what to import]

              ### External
              - `[package]`: [what to import]

              ## Types/Interfaces to Use
              ```typescript
              // From [source]
              interface [Name] {
                [relevant fields]
              }
              ```

              ## Integration Points
              - Called by: [who will use this]
              - Calls: [what this will call]
              - Tests: [related test files]

              ## Implementation Notes
              - [Specific note 1]
              - [Specific note 2]
              ```

              ## Commit
              ```bash
              git add context/step-7-context.md
              git commit -m "context(step-7): gather implementation context"
              ```
          - id: execute
            status: pending
            prompt: |
              Implement the step following gherkin scenarios and context.

              ## Your Task
              ## Phase 3.1: Interactive Review Command

              Implement /m42-signs:review command:

              ### Tasks
              1. Create commands/review.md:
                 - Proper frontmatter (description, allowed-tools, model)
                 - Load .claude/learnings/backlog.yaml
                 - Filter to status: pending
                 - For each learning:
                   - Display: title, problem, solution, target, confidence
                   - Show context (origin, source tool/error)
                   - Prompt: [A]pprove / [R]eject / [E]dit / [S]kip / [Q]uit
                 - Update status based on choice
                 - Save changes after each decision

              2. Add edit mode:
                 - Allow editing title, problem, solution, target
                 - Re-validate edited learning
                 - Update confidence if significantly changed

              3. Add batch operations:
                 - --approve-all-high: auto-approve high confidence
                 - --reject-all-low: auto-reject low confidence

              ### Success Criteria
              - Interactive flow is intuitive
              - Edits are validated before saving
              - Batch operations are safe (with confirmation)


              ## MUST READ BEFORE IMPLEMENTING
              Read these files in order:
              1. context/_shared-context.md (project patterns, conventions)
              2. context/sprint-plan.md (how this fits in sprint)
              3. artifacts/step-7-gherkin.md (scenarios to satisfy)
              4. context/step-7-context.md (specific patterns, imports)

              ## Implementation Rules

              ### Follow the Gherkin
              Your implementation MUST satisfy ALL gherkin scenarios.
              Each scenario has a verification command - mentally run it to check your work.

              ### Follow the Context
              - Use patterns from similar implementations
              - Import from specified modules
              - Implement required interfaces
              - Follow naming conventions

              ### Code Quality
              - Keep code simple and focused
              - Follow existing patterns exactly
              - No over-engineering or extra abstractions
              - Only implement what's needed for the scenarios

              ### Commits
              Make atomic commits for logical units:
              ```bash
              # After each logical piece
              git add [files]
              git commit -m "[type](step-7): [description]"
              ```

              Types: feat, fix, refactor, test, docs

              ## Implementation Checklist
              Before marking complete, verify:
              - [ ] All files from gherkin scenarios exist
              - [ ] Code follows patterns from context
              - [ ] Imports are correct
              - [ ] No TypeScript errors (run typecheck mentally)
              - [ ] Each scenario's verification should pass

              ## If Blocked
              If you encounter an issue that prevents completion:
              - Document the blocker clearly
              - Set status to needs-human
              - Do NOT leave partial/broken implementation
          - id: qa
            status: pending
            prompt: |
              Verify implementation against gherkin scenarios.

              ## Context
              Read: artifacts/step-7-gherkin.md (scenarios with verification commands)

              ## Step 1: Run Each Verification

              For EACH scenario in the gherkin file:
              1. Run the verification command
              2. Record the result: 1 (pass) or 0 (fail)
              3. If fail, capture the error output

              ## Step 2: Calculate Score

              Score = (passed scenarios) / (total scenarios)
              - Score = 1.0 (all pass) → PASS
              - Score < 1.0 (any fail) → FAIL

              ## Step 3: Generate QA Report

              Create: artifacts/step-7-qa-report.md

              ```markdown
              # QA Report: step-7

              ## Summary
              - Total Scenarios: [N]
              - Passed: [N]
              - Failed: [N]
              - Score: [X]/[N] = [percentage]%

              ## Verification Results

              | # | Scenario | Result | Details |
              |---|----------|--------|---------|
              | 1 | [Name] | PASS/FAIL | [output or error] |
              | 2 | [Name] | PASS/FAIL | [output or error] |
              ...

              ## Detailed Results

              ### Scenario 1: [Name]
              **Verification**: `[command]`
              **Exit Code**: [0 or N]
              **Output**:
              ```
              [actual output]
              ```
              **Result**: PASS / FAIL

              ### Scenario 2: [Name]
              ...

              ## Issues Found
              [If any failures, describe each issue]

              1. **[Scenario name]**: [What failed and why]

              ## Status: PASS / FAIL
              ```

              ## Step 4: Handle Outcome

              ### If ALL scenarios PASS (Score = 100%):
              1. Ensure report shows "Status: PASS"
              2. Commit the report:
                 ```bash
                 git add artifacts/step-7-qa-report.md
                 git commit -m "qa(step-7): all scenarios passed"
                 ```
              3. Mark phase as completed

              ### If ANY scenario FAILS (Score < 100%):
              You MUST inject fix phases. Do NOT just report and continue.

              1. Ensure report shows "Status: FAIL" with specific issues

              2. Find the PROGRESS.yaml file:
                 ```bash
                 PROGRESS_FILE=$(find .claude/sprints -name "PROGRESS.yaml" -type f 2>/dev/null | head -1)
                 echo "Found: $PROGRESS_FILE"
                 ```

              3. Inject fix and re-verify phases using yq:
                 ```bash
                 yq -i '
                   (.phases[] | select(.steps) | .steps[] | select(.status == "in-progress") | .phases) +=
                   [
                     {
                       "id": "fix",
                       "status": "pending",
                       "prompt": "Fix failing scenarios for step-7.\n\n## Context\nRead: artifacts/step-7-qa-report.md\n\n## Instructions\n1. Review each FAIL scenario\n2. Fix the implementation to make it pass\n3. Re-run the verification command to confirm\n4. Make atomic commits for each fix\n\n## After Fixing\nDo NOT mark as complete until ALL verifications pass."
                     },
                     {
                       "id": "reverify",
                       "status": "pending",
                       "prompt": "Re-verify all scenarios after fixes.\n\n## Instructions\nRe-run ALL verification commands from artifacts/step-7-gherkin.md\n\n## If ALL pass:\n- Update artifacts/step-7-qa-report.md with PASS status\n- Commit the updated report\n\n## If ANY still fail:\n- Update the QA report with new results\n- Inject another fix phase using yq\n- Loop continues until all pass"
                     }
                   ]
                 ' "$PROGRESS_FILE"
                 ```

              4. Mark current QA phase as failed:
                 ```bash
                 yq -i '
                   (.. | select(.id == "qa" and .status == "in-progress")) |=
                   (.status = "failed" | .error = "step-7 QA failed - see report - fix phase injected")
                 ' "$PROGRESS_FILE"
                 ```

              5. The sprint loop will now execute fix → reverify phases

              ## Important
              - EVERY scenario must pass for the step to be complete
              - Failed QA MUST inject fix phases, not just report
              - This creates a self-healing loop until all pass
          - id: verify
            status: pending
            prompt: |
              Final integration verification for the step.

              ## Your Task
              ## Phase 3.1: Interactive Review Command

              Implement /m42-signs:review command:

              ### Tasks
              1. Create commands/review.md:
                 - Proper frontmatter (description, allowed-tools, model)
                 - Load .claude/learnings/backlog.yaml
                 - Filter to status: pending
                 - For each learning:
                   - Display: title, problem, solution, target, confidence
                   - Show context (origin, source tool/error)
                   - Prompt: [A]pprove / [R]eject / [E]dit / [S]kip / [Q]uit
                 - Update status based on choice
                 - Save changes after each decision

              2. Add edit mode:
                 - Allow editing title, problem, solution, target
                 - Re-validate edited learning
                 - Update confidence if significantly changed

              3. Add batch operations:
                 - --approve-all-high: auto-approve high confidence
                 - --reject-all-low: auto-reject low confidence

              ### Success Criteria
              - Interactive flow is intuitive
              - Edits are validated before saving
              - Batch operations are safe (with confirmation)


              ## Context
              Read: context/_shared-context.md (build commands)
              Read: artifacts/step-7-qa-report.md (should show PASS)

              ## Step 1: Build Verification
              Run the project build to ensure this step integrates:
              ```bash
              # Use commands from _shared-context.md, typically:
              npm run build
              npm run typecheck
              ```

              ## Step 2: Integration Check
              Verify this step works with the rest of the sprint:
              - Check imports resolve correctly
              - Verify no circular dependencies
              - Ensure types are compatible

              ## Step 3: Smoke Test
              If possible, manually verify the functionality:
              - Run the code path that uses this step's output
              - Check expected behavior matches gherkin scenarios

              ## Step 4: Final Commit
              If all verification passes:
              ```bash
              git add -A
              git status  # Check for any uncommitted changes
              # Only commit if there are changes
              git diff --cached --quiet || git commit -m "verify(step-7): integration verified"
              ```

              ## Outcome
              - If integration passes: Mark step as complete
              - If integration fails: Document the issue and set status to needs-human

              ## Important
              This is the final gate before moving to the next step.
              The step's gherkin scenarios already passed in QA.
              This phase ensures the step works in the broader context.
      - id: step-8
        prompt: |
          ## Phase 3.2: Apply Command

          Implement /m42-signs:apply command:

          ### Tasks
          1. Create commands/apply.md:
             - Proper frontmatter (description, allowed-tools, model)
             - Load backlog, filter to status: approved
             - Group learnings by target CLAUDE.md
             - For each target:
               - Read or create CLAUDE.md
               - Find or create ## Signs section
               - Append formatted learning entry
               - Update backlog: status -> applied
             - Output summary of applied changes

          2. Create skills/managing-signs/references/claude-md-format.md:
             - Proper frontmatter (title, description, skill: managing-signs)
             - Document sign format
             - Show examples with proper structure
             - Explain origin tracking
             - Keep LLM-dense

          3. Add options:
             - --commit: create git commit after applying
             - --dry-run: show what would be changed
             - --targets: apply only to specific CLAUDE.md files

          ### Success Criteria
          - CLAUDE.md files are properly formatted
          - Signs section is clearly delimited
          - Applied learnings are removed from pending
        status: pending
        phases:
          - id: plan
            status: pending
            prompt: |
              Generate binary-verifiable gherkin scenarios for this step.

              ## Your Task
              ## Phase 3.2: Apply Command

              Implement /m42-signs:apply command:

              ### Tasks
              1. Create commands/apply.md:
                 - Proper frontmatter (description, allowed-tools, model)
                 - Load backlog, filter to status: approved
                 - Group learnings by target CLAUDE.md
                 - For each target:
                   - Read or create CLAUDE.md
                   - Find or create ## Signs section
                   - Append formatted learning entry
                   - Update backlog: status -> applied
                 - Output summary of applied changes

              2. Create skills/managing-signs/references/claude-md-format.md:
                 - Proper frontmatter (title, description, skill: managing-signs)
                 - Document sign format
                 - Show examples with proper structure
                 - Explain origin tracking
                 - Keep LLM-dense

              3. Add options:
                 - --commit: create git commit after applying
                 - --dry-run: show what would be changed
                 - --targets: apply only to specific CLAUDE.md files

              ### Success Criteria
              - CLAUDE.md files are properly formatted
              - Signs section is clearly delimited
              - Applied learnings are removed from pending


              ## Shared Context
              Read: context/_shared-context.md (project patterns, conventions, commands)
              Read: context/sprint-plan.md (how this step fits in the sprint)

              ## Instructions
              Create 4-8 gherkin scenarios that, when ALL pass, prove the step is complete.
              Each scenario MUST have:
              1. Clear Given/When/Then structure
              2. An explicit verification command that returns exit code 0 on success
              3. Binary outcome: exactly 1 (pass) or 0 (fail)

              ## Gherkin Format
              Each scenario follows this exact structure:

              ```gherkin
              Scenario: [Descriptive name]
                Given [precondition or context]
                When [action taken]
                Then [expected outcome]

              Verification: `[shell command that exits 0 on success, non-zero on failure]`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ## Example Scenarios

              ### File Existence
              ```gherkin
              Scenario: Source file exists
                Given the project structure is set up
                When I check for the module file
                Then src/auth/service.ts exists

              Verification: `test -f src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### TypeScript Compilation
              ```gherkin
              Scenario: TypeScript compiles without errors
                Given the file src/auth/service.ts exists
                When I run the TypeScript compiler
                Then no compilation errors occur

              Verification: `npx tsc --noEmit src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Function Export
              ```gherkin
              Scenario: Login function is exported
                Given src/auth/service.ts exists
                When I check for the login export
                Then the function is publicly available

              Verification: `grep -q "export.*function login\|export.*const login\|export { login" src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### Test Execution
              ```gherkin
              Scenario: Unit tests pass
                Given tests exist in src/auth/service.test.ts
                When I run the test suite
                Then all tests pass

              Verification: `npm test -- --testPathPattern="auth/service" --passWithNoTests 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Lint Check
              ```gherkin
              Scenario: Code passes linting
                Given the implementation is complete
                When I run the linter
                Then no lint errors in new files

              Verification: `npm run lint -- src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ## Output
              Create: artifacts/step-8-gherkin.md

              ```markdown
              # Gherkin Scenarios: step-8

              ## Step Task
              ## Phase 3.2: Apply Command

              Implement /m42-signs:apply command:

              ### Tasks
              1. Create commands/apply.md:
                 - Proper frontmatter (description, allowed-tools, model)
                 - Load backlog, filter to status: approved
                 - Group learnings by target CLAUDE.md
                 - For each target:
                   - Read or create CLAUDE.md
                   - Find or create ## Signs section
                   - Append formatted learning entry
                   - Update backlog: status -> applied
                 - Output summary of applied changes

              2. Create skills/managing-signs/references/claude-md-format.md:
                 - Proper frontmatter (title, description, skill: managing-signs)
                 - Document sign format
                 - Show examples with proper structure
                 - Explain origin tracking
                 - Keep LLM-dense

              3. Add options:
                 - --commit: create git commit after applying
                 - --dry-run: show what would be changed
                 - --targets: apply only to specific CLAUDE.md files

              ### Success Criteria
              - CLAUDE.md files are properly formatted
              - Signs section is clearly delimited
              - Applied learnings are removed from pending


              ## Success Criteria
              All scenarios must pass (score = 1) for the step to be complete.
              Total scenarios: [N]
              Required score: [N]/[N]

              ---

              ## Scenario 1: [Name]
              [Full gherkin with verification as shown above]

              ---

              ## Scenario 2: [Name]
              ...

              [Continue for 4-8 scenarios]
              ```

              ## Commit
              ```bash
              git add artifacts/step-8-gherkin.md
              git commit -m "plan(step-8): define gherkin scenarios"
              ```
          - id: context
            status: pending
            prompt: |
              Gather step-specific context for implementation.

              ## Your Task
              ## Phase 3.2: Apply Command

              Implement /m42-signs:apply command:

              ### Tasks
              1. Create commands/apply.md:
                 - Proper frontmatter (description, allowed-tools, model)
                 - Load backlog, filter to status: approved
                 - Group learnings by target CLAUDE.md
                 - For each target:
                   - Read or create CLAUDE.md
                   - Find or create ## Signs section
                   - Append formatted learning entry
                   - Update backlog: status -> applied
                 - Output summary of applied changes

              2. Create skills/managing-signs/references/claude-md-format.md:
                 - Proper frontmatter (title, description, skill: managing-signs)
                 - Document sign format
                 - Show examples with proper structure
                 - Explain origin tracking
                 - Keep LLM-dense

              3. Add options:
                 - --commit: create git commit after applying
                 - --dry-run: show what would be changed
                 - --targets: apply only to specific CLAUDE.md files

              ### Success Criteria
              - CLAUDE.md files are properly formatted
              - Signs section is clearly delimited
              - Applied learnings are removed from pending


              ## Shared Context
              Read: context/_shared-context.md (already has project-wide patterns)
              Read: artifacts/step-8-gherkin.md (scenarios to implement)

              ## Instructions
              Research the specific code areas this step will touch:

              1. **Related Existing Code**
                 - Find similar implementations to follow as patterns
                 - Identify modules this step will import from
                 - Note any interfaces/types to implement or extend

              2. **Dependencies**
                 - List imports needed from internal modules
                 - List any new external packages needed
                 - Check for peer dependencies or version constraints

              3. **Integration Points**
                 - How will this code be called/used?
                 - What modules will import from this step's output?
                 - Are there existing tests to extend?

              4. **Specific Patterns**
                 - Error handling patterns used in similar code
                 - Naming conventions for this area
                 - File organization patterns

              ## Output
              Create: context/step-8-context.md

              ```markdown
              # Step Context: step-8

              ## Task
              ## Phase 3.2: Apply Command

              Implement /m42-signs:apply command:

              ### Tasks
              1. Create commands/apply.md:
                 - Proper frontmatter (description, allowed-tools, model)
                 - Load backlog, filter to status: approved
                 - Group learnings by target CLAUDE.md
                 - For each target:
                   - Read or create CLAUDE.md
                   - Find or create ## Signs section
                   - Append formatted learning entry
                   - Update backlog: status -> applied
                 - Output summary of applied changes

              2. Create skills/managing-signs/references/claude-md-format.md:
                 - Proper frontmatter (title, description, skill: managing-signs)
                 - Document sign format
                 - Show examples with proper structure
                 - Explain origin tracking
                 - Keep LLM-dense

              3. Add options:
                 - --commit: create git commit after applying
                 - --dry-run: show what would be changed
                 - --targets: apply only to specific CLAUDE.md files

              ### Success Criteria
              - CLAUDE.md files are properly formatted
              - Signs section is clearly delimited
              - Applied learnings are removed from pending


              ## Related Code Patterns

              ### Similar Implementation: [path]
              ```typescript
              // Key pattern to follow
              [relevant code snippet]
              ```

              ### Similar Implementation: [path]
              [continue as needed]

              ## Required Imports
              ### Internal
              - `[module]`: [what to import]

              ### External
              - `[package]`: [what to import]

              ## Types/Interfaces to Use
              ```typescript
              // From [source]
              interface [Name] {
                [relevant fields]
              }
              ```

              ## Integration Points
              - Called by: [who will use this]
              - Calls: [what this will call]
              - Tests: [related test files]

              ## Implementation Notes
              - [Specific note 1]
              - [Specific note 2]
              ```

              ## Commit
              ```bash
              git add context/step-8-context.md
              git commit -m "context(step-8): gather implementation context"
              ```
          - id: execute
            status: pending
            prompt: |
              Implement the step following gherkin scenarios and context.

              ## Your Task
              ## Phase 3.2: Apply Command

              Implement /m42-signs:apply command:

              ### Tasks
              1. Create commands/apply.md:
                 - Proper frontmatter (description, allowed-tools, model)
                 - Load backlog, filter to status: approved
                 - Group learnings by target CLAUDE.md
                 - For each target:
                   - Read or create CLAUDE.md
                   - Find or create ## Signs section
                   - Append formatted learning entry
                   - Update backlog: status -> applied
                 - Output summary of applied changes

              2. Create skills/managing-signs/references/claude-md-format.md:
                 - Proper frontmatter (title, description, skill: managing-signs)
                 - Document sign format
                 - Show examples with proper structure
                 - Explain origin tracking
                 - Keep LLM-dense

              3. Add options:
                 - --commit: create git commit after applying
                 - --dry-run: show what would be changed
                 - --targets: apply only to specific CLAUDE.md files

              ### Success Criteria
              - CLAUDE.md files are properly formatted
              - Signs section is clearly delimited
              - Applied learnings are removed from pending


              ## MUST READ BEFORE IMPLEMENTING
              Read these files in order:
              1. context/_shared-context.md (project patterns, conventions)
              2. context/sprint-plan.md (how this fits in sprint)
              3. artifacts/step-8-gherkin.md (scenarios to satisfy)
              4. context/step-8-context.md (specific patterns, imports)

              ## Implementation Rules

              ### Follow the Gherkin
              Your implementation MUST satisfy ALL gherkin scenarios.
              Each scenario has a verification command - mentally run it to check your work.

              ### Follow the Context
              - Use patterns from similar implementations
              - Import from specified modules
              - Implement required interfaces
              - Follow naming conventions

              ### Code Quality
              - Keep code simple and focused
              - Follow existing patterns exactly
              - No over-engineering or extra abstractions
              - Only implement what's needed for the scenarios

              ### Commits
              Make atomic commits for logical units:
              ```bash
              # After each logical piece
              git add [files]
              git commit -m "[type](step-8): [description]"
              ```

              Types: feat, fix, refactor, test, docs

              ## Implementation Checklist
              Before marking complete, verify:
              - [ ] All files from gherkin scenarios exist
              - [ ] Code follows patterns from context
              - [ ] Imports are correct
              - [ ] No TypeScript errors (run typecheck mentally)
              - [ ] Each scenario's verification should pass

              ## If Blocked
              If you encounter an issue that prevents completion:
              - Document the blocker clearly
              - Set status to needs-human
              - Do NOT leave partial/broken implementation
          - id: qa
            status: pending
            prompt: |
              Verify implementation against gherkin scenarios.

              ## Context
              Read: artifacts/step-8-gherkin.md (scenarios with verification commands)

              ## Step 1: Run Each Verification

              For EACH scenario in the gherkin file:
              1. Run the verification command
              2. Record the result: 1 (pass) or 0 (fail)
              3. If fail, capture the error output

              ## Step 2: Calculate Score

              Score = (passed scenarios) / (total scenarios)
              - Score = 1.0 (all pass) → PASS
              - Score < 1.0 (any fail) → FAIL

              ## Step 3: Generate QA Report

              Create: artifacts/step-8-qa-report.md

              ```markdown
              # QA Report: step-8

              ## Summary
              - Total Scenarios: [N]
              - Passed: [N]
              - Failed: [N]
              - Score: [X]/[N] = [percentage]%

              ## Verification Results

              | # | Scenario | Result | Details |
              |---|----------|--------|---------|
              | 1 | [Name] | PASS/FAIL | [output or error] |
              | 2 | [Name] | PASS/FAIL | [output or error] |
              ...

              ## Detailed Results

              ### Scenario 1: [Name]
              **Verification**: `[command]`
              **Exit Code**: [0 or N]
              **Output**:
              ```
              [actual output]
              ```
              **Result**: PASS / FAIL

              ### Scenario 2: [Name]
              ...

              ## Issues Found
              [If any failures, describe each issue]

              1. **[Scenario name]**: [What failed and why]

              ## Status: PASS / FAIL
              ```

              ## Step 4: Handle Outcome

              ### If ALL scenarios PASS (Score = 100%):
              1. Ensure report shows "Status: PASS"
              2. Commit the report:
                 ```bash
                 git add artifacts/step-8-qa-report.md
                 git commit -m "qa(step-8): all scenarios passed"
                 ```
              3. Mark phase as completed

              ### If ANY scenario FAILS (Score < 100%):
              You MUST inject fix phases. Do NOT just report and continue.

              1. Ensure report shows "Status: FAIL" with specific issues

              2. Find the PROGRESS.yaml file:
                 ```bash
                 PROGRESS_FILE=$(find .claude/sprints -name "PROGRESS.yaml" -type f 2>/dev/null | head -1)
                 echo "Found: $PROGRESS_FILE"
                 ```

              3. Inject fix and re-verify phases using yq:
                 ```bash
                 yq -i '
                   (.phases[] | select(.steps) | .steps[] | select(.status == "in-progress") | .phases) +=
                   [
                     {
                       "id": "fix",
                       "status": "pending",
                       "prompt": "Fix failing scenarios for step-8.\n\n## Context\nRead: artifacts/step-8-qa-report.md\n\n## Instructions\n1. Review each FAIL scenario\n2. Fix the implementation to make it pass\n3. Re-run the verification command to confirm\n4. Make atomic commits for each fix\n\n## After Fixing\nDo NOT mark as complete until ALL verifications pass."
                     },
                     {
                       "id": "reverify",
                       "status": "pending",
                       "prompt": "Re-verify all scenarios after fixes.\n\n## Instructions\nRe-run ALL verification commands from artifacts/step-8-gherkin.md\n\n## If ALL pass:\n- Update artifacts/step-8-qa-report.md with PASS status\n- Commit the updated report\n\n## If ANY still fail:\n- Update the QA report with new results\n- Inject another fix phase using yq\n- Loop continues until all pass"
                     }
                   ]
                 ' "$PROGRESS_FILE"
                 ```

              4. Mark current QA phase as failed:
                 ```bash
                 yq -i '
                   (.. | select(.id == "qa" and .status == "in-progress")) |=
                   (.status = "failed" | .error = "step-8 QA failed - see report - fix phase injected")
                 ' "$PROGRESS_FILE"
                 ```

              5. The sprint loop will now execute fix → reverify phases

              ## Important
              - EVERY scenario must pass for the step to be complete
              - Failed QA MUST inject fix phases, not just report
              - This creates a self-healing loop until all pass
          - id: verify
            status: pending
            prompt: |
              Final integration verification for the step.

              ## Your Task
              ## Phase 3.2: Apply Command

              Implement /m42-signs:apply command:

              ### Tasks
              1. Create commands/apply.md:
                 - Proper frontmatter (description, allowed-tools, model)
                 - Load backlog, filter to status: approved
                 - Group learnings by target CLAUDE.md
                 - For each target:
                   - Read or create CLAUDE.md
                   - Find or create ## Signs section
                   - Append formatted learning entry
                   - Update backlog: status -> applied
                 - Output summary of applied changes

              2. Create skills/managing-signs/references/claude-md-format.md:
                 - Proper frontmatter (title, description, skill: managing-signs)
                 - Document sign format
                 - Show examples with proper structure
                 - Explain origin tracking
                 - Keep LLM-dense

              3. Add options:
                 - --commit: create git commit after applying
                 - --dry-run: show what would be changed
                 - --targets: apply only to specific CLAUDE.md files

              ### Success Criteria
              - CLAUDE.md files are properly formatted
              - Signs section is clearly delimited
              - Applied learnings are removed from pending


              ## Context
              Read: context/_shared-context.md (build commands)
              Read: artifacts/step-8-qa-report.md (should show PASS)

              ## Step 1: Build Verification
              Run the project build to ensure this step integrates:
              ```bash
              # Use commands from _shared-context.md, typically:
              npm run build
              npm run typecheck
              ```

              ## Step 2: Integration Check
              Verify this step works with the rest of the sprint:
              - Check imports resolve correctly
              - Verify no circular dependencies
              - Ensure types are compatible

              ## Step 3: Smoke Test
              If possible, manually verify the functionality:
              - Run the code path that uses this step's output
              - Check expected behavior matches gherkin scenarios

              ## Step 4: Final Commit
              If all verification passes:
              ```bash
              git add -A
              git status  # Check for any uncommitted changes
              # Only commit if there are changes
              git diff --cached --quiet || git commit -m "verify(step-8): integration verified"
              ```

              ## Outcome
              - If integration passes: Mark step as complete
              - If integration fails: Document the issue and set status to needs-human

              ## Important
              This is the final gate before moving to the next step.
              The step's gherkin scenarios already passed in QA.
              This phase ensures the step works in the broader context.
      - id: step-9
        prompt: |
          ## Phase 3.3: Git Integration

          Add optional git commit support:

          ### Tasks
          1. Update commands/apply.md with git logic:
             - After applying changes, offer to commit
             - Commit message format: "signs: apply N learnings"
             - Include list of affected files
             - Support --auto-commit flag

          2. Add safety checks:
             - Verify repo is clean (or at least no conflicts)
             - Stage only CLAUDE.md and backlog.yaml changes
             - Allow user to abort before committing

          3. Handle edge cases:
             - Not in a git repo -> skip git integration
             - User declines commit -> just save changes

          ### Success Criteria
          - Commits are atomic and clear
          - No unrelated changes are included
          - User has full control over committing
        status: pending
        phases:
          - id: plan
            status: pending
            prompt: |
              Generate binary-verifiable gherkin scenarios for this step.

              ## Your Task
              ## Phase 3.3: Git Integration

              Add optional git commit support:

              ### Tasks
              1. Update commands/apply.md with git logic:
                 - After applying changes, offer to commit
                 - Commit message format: "signs: apply N learnings"
                 - Include list of affected files
                 - Support --auto-commit flag

              2. Add safety checks:
                 - Verify repo is clean (or at least no conflicts)
                 - Stage only CLAUDE.md and backlog.yaml changes
                 - Allow user to abort before committing

              3. Handle edge cases:
                 - Not in a git repo -> skip git integration
                 - User declines commit -> just save changes

              ### Success Criteria
              - Commits are atomic and clear
              - No unrelated changes are included
              - User has full control over committing


              ## Shared Context
              Read: context/_shared-context.md (project patterns, conventions, commands)
              Read: context/sprint-plan.md (how this step fits in the sprint)

              ## Instructions
              Create 4-8 gherkin scenarios that, when ALL pass, prove the step is complete.
              Each scenario MUST have:
              1. Clear Given/When/Then structure
              2. An explicit verification command that returns exit code 0 on success
              3. Binary outcome: exactly 1 (pass) or 0 (fail)

              ## Gherkin Format
              Each scenario follows this exact structure:

              ```gherkin
              Scenario: [Descriptive name]
                Given [precondition or context]
                When [action taken]
                Then [expected outcome]

              Verification: `[shell command that exits 0 on success, non-zero on failure]`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ## Example Scenarios

              ### File Existence
              ```gherkin
              Scenario: Source file exists
                Given the project structure is set up
                When I check for the module file
                Then src/auth/service.ts exists

              Verification: `test -f src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### TypeScript Compilation
              ```gherkin
              Scenario: TypeScript compiles without errors
                Given the file src/auth/service.ts exists
                When I run the TypeScript compiler
                Then no compilation errors occur

              Verification: `npx tsc --noEmit src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Function Export
              ```gherkin
              Scenario: Login function is exported
                Given src/auth/service.ts exists
                When I check for the login export
                Then the function is publicly available

              Verification: `grep -q "export.*function login\|export.*const login\|export { login" src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### Test Execution
              ```gherkin
              Scenario: Unit tests pass
                Given tests exist in src/auth/service.test.ts
                When I run the test suite
                Then all tests pass

              Verification: `npm test -- --testPathPattern="auth/service" --passWithNoTests 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Lint Check
              ```gherkin
              Scenario: Code passes linting
                Given the implementation is complete
                When I run the linter
                Then no lint errors in new files

              Verification: `npm run lint -- src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ## Output
              Create: artifacts/step-9-gherkin.md

              ```markdown
              # Gherkin Scenarios: step-9

              ## Step Task
              ## Phase 3.3: Git Integration

              Add optional git commit support:

              ### Tasks
              1. Update commands/apply.md with git logic:
                 - After applying changes, offer to commit
                 - Commit message format: "signs: apply N learnings"
                 - Include list of affected files
                 - Support --auto-commit flag

              2. Add safety checks:
                 - Verify repo is clean (or at least no conflicts)
                 - Stage only CLAUDE.md and backlog.yaml changes
                 - Allow user to abort before committing

              3. Handle edge cases:
                 - Not in a git repo -> skip git integration
                 - User declines commit -> just save changes

              ### Success Criteria
              - Commits are atomic and clear
              - No unrelated changes are included
              - User has full control over committing


              ## Success Criteria
              All scenarios must pass (score = 1) for the step to be complete.
              Total scenarios: [N]
              Required score: [N]/[N]

              ---

              ## Scenario 1: [Name]
              [Full gherkin with verification as shown above]

              ---

              ## Scenario 2: [Name]
              ...

              [Continue for 4-8 scenarios]
              ```

              ## Commit
              ```bash
              git add artifacts/step-9-gherkin.md
              git commit -m "plan(step-9): define gherkin scenarios"
              ```
          - id: context
            status: pending
            prompt: |
              Gather step-specific context for implementation.

              ## Your Task
              ## Phase 3.3: Git Integration

              Add optional git commit support:

              ### Tasks
              1. Update commands/apply.md with git logic:
                 - After applying changes, offer to commit
                 - Commit message format: "signs: apply N learnings"
                 - Include list of affected files
                 - Support --auto-commit flag

              2. Add safety checks:
                 - Verify repo is clean (or at least no conflicts)
                 - Stage only CLAUDE.md and backlog.yaml changes
                 - Allow user to abort before committing

              3. Handle edge cases:
                 - Not in a git repo -> skip git integration
                 - User declines commit -> just save changes

              ### Success Criteria
              - Commits are atomic and clear
              - No unrelated changes are included
              - User has full control over committing


              ## Shared Context
              Read: context/_shared-context.md (already has project-wide patterns)
              Read: artifacts/step-9-gherkin.md (scenarios to implement)

              ## Instructions
              Research the specific code areas this step will touch:

              1. **Related Existing Code**
                 - Find similar implementations to follow as patterns
                 - Identify modules this step will import from
                 - Note any interfaces/types to implement or extend

              2. **Dependencies**
                 - List imports needed from internal modules
                 - List any new external packages needed
                 - Check for peer dependencies or version constraints

              3. **Integration Points**
                 - How will this code be called/used?
                 - What modules will import from this step's output?
                 - Are there existing tests to extend?

              4. **Specific Patterns**
                 - Error handling patterns used in similar code
                 - Naming conventions for this area
                 - File organization patterns

              ## Output
              Create: context/step-9-context.md

              ```markdown
              # Step Context: step-9

              ## Task
              ## Phase 3.3: Git Integration

              Add optional git commit support:

              ### Tasks
              1. Update commands/apply.md with git logic:
                 - After applying changes, offer to commit
                 - Commit message format: "signs: apply N learnings"
                 - Include list of affected files
                 - Support --auto-commit flag

              2. Add safety checks:
                 - Verify repo is clean (or at least no conflicts)
                 - Stage only CLAUDE.md and backlog.yaml changes
                 - Allow user to abort before committing

              3. Handle edge cases:
                 - Not in a git repo -> skip git integration
                 - User declines commit -> just save changes

              ### Success Criteria
              - Commits are atomic and clear
              - No unrelated changes are included
              - User has full control over committing


              ## Related Code Patterns

              ### Similar Implementation: [path]
              ```typescript
              // Key pattern to follow
              [relevant code snippet]
              ```

              ### Similar Implementation: [path]
              [continue as needed]

              ## Required Imports
              ### Internal
              - `[module]`: [what to import]

              ### External
              - `[package]`: [what to import]

              ## Types/Interfaces to Use
              ```typescript
              // From [source]
              interface [Name] {
                [relevant fields]
              }
              ```

              ## Integration Points
              - Called by: [who will use this]
              - Calls: [what this will call]
              - Tests: [related test files]

              ## Implementation Notes
              - [Specific note 1]
              - [Specific note 2]
              ```

              ## Commit
              ```bash
              git add context/step-9-context.md
              git commit -m "context(step-9): gather implementation context"
              ```
          - id: execute
            status: pending
            prompt: |
              Implement the step following gherkin scenarios and context.

              ## Your Task
              ## Phase 3.3: Git Integration

              Add optional git commit support:

              ### Tasks
              1. Update commands/apply.md with git logic:
                 - After applying changes, offer to commit
                 - Commit message format: "signs: apply N learnings"
                 - Include list of affected files
                 - Support --auto-commit flag

              2. Add safety checks:
                 - Verify repo is clean (or at least no conflicts)
                 - Stage only CLAUDE.md and backlog.yaml changes
                 - Allow user to abort before committing

              3. Handle edge cases:
                 - Not in a git repo -> skip git integration
                 - User declines commit -> just save changes

              ### Success Criteria
              - Commits are atomic and clear
              - No unrelated changes are included
              - User has full control over committing


              ## MUST READ BEFORE IMPLEMENTING
              Read these files in order:
              1. context/_shared-context.md (project patterns, conventions)
              2. context/sprint-plan.md (how this fits in sprint)
              3. artifacts/step-9-gherkin.md (scenarios to satisfy)
              4. context/step-9-context.md (specific patterns, imports)

              ## Implementation Rules

              ### Follow the Gherkin
              Your implementation MUST satisfy ALL gherkin scenarios.
              Each scenario has a verification command - mentally run it to check your work.

              ### Follow the Context
              - Use patterns from similar implementations
              - Import from specified modules
              - Implement required interfaces
              - Follow naming conventions

              ### Code Quality
              - Keep code simple and focused
              - Follow existing patterns exactly
              - No over-engineering or extra abstractions
              - Only implement what's needed for the scenarios

              ### Commits
              Make atomic commits for logical units:
              ```bash
              # After each logical piece
              git add [files]
              git commit -m "[type](step-9): [description]"
              ```

              Types: feat, fix, refactor, test, docs

              ## Implementation Checklist
              Before marking complete, verify:
              - [ ] All files from gherkin scenarios exist
              - [ ] Code follows patterns from context
              - [ ] Imports are correct
              - [ ] No TypeScript errors (run typecheck mentally)
              - [ ] Each scenario's verification should pass

              ## If Blocked
              If you encounter an issue that prevents completion:
              - Document the blocker clearly
              - Set status to needs-human
              - Do NOT leave partial/broken implementation
          - id: qa
            status: pending
            prompt: |
              Verify implementation against gherkin scenarios.

              ## Context
              Read: artifacts/step-9-gherkin.md (scenarios with verification commands)

              ## Step 1: Run Each Verification

              For EACH scenario in the gherkin file:
              1. Run the verification command
              2. Record the result: 1 (pass) or 0 (fail)
              3. If fail, capture the error output

              ## Step 2: Calculate Score

              Score = (passed scenarios) / (total scenarios)
              - Score = 1.0 (all pass) → PASS
              - Score < 1.0 (any fail) → FAIL

              ## Step 3: Generate QA Report

              Create: artifacts/step-9-qa-report.md

              ```markdown
              # QA Report: step-9

              ## Summary
              - Total Scenarios: [N]
              - Passed: [N]
              - Failed: [N]
              - Score: [X]/[N] = [percentage]%

              ## Verification Results

              | # | Scenario | Result | Details |
              |---|----------|--------|---------|
              | 1 | [Name] | PASS/FAIL | [output or error] |
              | 2 | [Name] | PASS/FAIL | [output or error] |
              ...

              ## Detailed Results

              ### Scenario 1: [Name]
              **Verification**: `[command]`
              **Exit Code**: [0 or N]
              **Output**:
              ```
              [actual output]
              ```
              **Result**: PASS / FAIL

              ### Scenario 2: [Name]
              ...

              ## Issues Found
              [If any failures, describe each issue]

              1. **[Scenario name]**: [What failed and why]

              ## Status: PASS / FAIL
              ```

              ## Step 4: Handle Outcome

              ### If ALL scenarios PASS (Score = 100%):
              1. Ensure report shows "Status: PASS"
              2. Commit the report:
                 ```bash
                 git add artifacts/step-9-qa-report.md
                 git commit -m "qa(step-9): all scenarios passed"
                 ```
              3. Mark phase as completed

              ### If ANY scenario FAILS (Score < 100%):
              You MUST inject fix phases. Do NOT just report and continue.

              1. Ensure report shows "Status: FAIL" with specific issues

              2. Find the PROGRESS.yaml file:
                 ```bash
                 PROGRESS_FILE=$(find .claude/sprints -name "PROGRESS.yaml" -type f 2>/dev/null | head -1)
                 echo "Found: $PROGRESS_FILE"
                 ```

              3. Inject fix and re-verify phases using yq:
                 ```bash
                 yq -i '
                   (.phases[] | select(.steps) | .steps[] | select(.status == "in-progress") | .phases) +=
                   [
                     {
                       "id": "fix",
                       "status": "pending",
                       "prompt": "Fix failing scenarios for step-9.\n\n## Context\nRead: artifacts/step-9-qa-report.md\n\n## Instructions\n1. Review each FAIL scenario\n2. Fix the implementation to make it pass\n3. Re-run the verification command to confirm\n4. Make atomic commits for each fix\n\n## After Fixing\nDo NOT mark as complete until ALL verifications pass."
                     },
                     {
                       "id": "reverify",
                       "status": "pending",
                       "prompt": "Re-verify all scenarios after fixes.\n\n## Instructions\nRe-run ALL verification commands from artifacts/step-9-gherkin.md\n\n## If ALL pass:\n- Update artifacts/step-9-qa-report.md with PASS status\n- Commit the updated report\n\n## If ANY still fail:\n- Update the QA report with new results\n- Inject another fix phase using yq\n- Loop continues until all pass"
                     }
                   ]
                 ' "$PROGRESS_FILE"
                 ```

              4. Mark current QA phase as failed:
                 ```bash
                 yq -i '
                   (.. | select(.id == "qa" and .status == "in-progress")) |=
                   (.status = "failed" | .error = "step-9 QA failed - see report - fix phase injected")
                 ' "$PROGRESS_FILE"
                 ```

              5. The sprint loop will now execute fix → reverify phases

              ## Important
              - EVERY scenario must pass for the step to be complete
              - Failed QA MUST inject fix phases, not just report
              - This creates a self-healing loop until all pass
          - id: verify
            status: pending
            prompt: |
              Final integration verification for the step.

              ## Your Task
              ## Phase 3.3: Git Integration

              Add optional git commit support:

              ### Tasks
              1. Update commands/apply.md with git logic:
                 - After applying changes, offer to commit
                 - Commit message format: "signs: apply N learnings"
                 - Include list of affected files
                 - Support --auto-commit flag

              2. Add safety checks:
                 - Verify repo is clean (or at least no conflicts)
                 - Stage only CLAUDE.md and backlog.yaml changes
                 - Allow user to abort before committing

              3. Handle edge cases:
                 - Not in a git repo -> skip git integration
                 - User declines commit -> just save changes

              ### Success Criteria
              - Commits are atomic and clear
              - No unrelated changes are included
              - User has full control over committing


              ## Context
              Read: context/_shared-context.md (build commands)
              Read: artifacts/step-9-qa-report.md (should show PASS)

              ## Step 1: Build Verification
              Run the project build to ensure this step integrates:
              ```bash
              # Use commands from _shared-context.md, typically:
              npm run build
              npm run typecheck
              ```

              ## Step 2: Integration Check
              Verify this step works with the rest of the sprint:
              - Check imports resolve correctly
              - Verify no circular dependencies
              - Ensure types are compatible

              ## Step 3: Smoke Test
              If possible, manually verify the functionality:
              - Run the code path that uses this step's output
              - Check expected behavior matches gherkin scenarios

              ## Step 4: Final Commit
              If all verification passes:
              ```bash
              git add -A
              git status  # Check for any uncommitted changes
              # Only commit if there are changes
              git diff --cached --quiet || git commit -m "verify(step-9): integration verified"
              ```

              ## Outcome
              - If integration passes: Mark step as complete
              - If integration fails: Document the issue and set status to needs-human

              ## Important
              This is the final gate before moving to the next step.
              The step's gherkin scenarios already passed in QA.
              This phase ensures the step works in the broader context.
      - id: step-10
        prompt: |
          ## Phase 4.1: Sprint Workflow Integration

          Create workflow step template for learning extraction:

          ### Tasks
          1. Create skills/managing-signs/assets/learning-extraction-workflow.yaml:
             - Phase that runs after sprint completion
             - Receives session transcript path
             - Runs extraction with --confidence-min medium
             - Outputs backlog summary

          2. Document integration in skills/managing-signs/SKILL.md:
             - How to add learning extraction to sprint workflows
             - Session transcript variable names
             - Example workflow configurations

          3. Create example in skills/managing-signs/assets/sprint-with-learning.yaml:
             - Complete sprint workflow
             - Includes learning extraction phase
             - Shows how phases connect

          ### Success Criteria
          - Workflow template is valid YAML
          - Integration documentation is clear
          - Example works with m42-sprint
        status: pending
        phases:
          - id: plan
            status: pending
            prompt: |
              Generate binary-verifiable gherkin scenarios for this step.

              ## Your Task
              ## Phase 4.1: Sprint Workflow Integration

              Create workflow step template for learning extraction:

              ### Tasks
              1. Create skills/managing-signs/assets/learning-extraction-workflow.yaml:
                 - Phase that runs after sprint completion
                 - Receives session transcript path
                 - Runs extraction with --confidence-min medium
                 - Outputs backlog summary

              2. Document integration in skills/managing-signs/SKILL.md:
                 - How to add learning extraction to sprint workflows
                 - Session transcript variable names
                 - Example workflow configurations

              3. Create example in skills/managing-signs/assets/sprint-with-learning.yaml:
                 - Complete sprint workflow
                 - Includes learning extraction phase
                 - Shows how phases connect

              ### Success Criteria
              - Workflow template is valid YAML
              - Integration documentation is clear
              - Example works with m42-sprint


              ## Shared Context
              Read: context/_shared-context.md (project patterns, conventions, commands)
              Read: context/sprint-plan.md (how this step fits in the sprint)

              ## Instructions
              Create 4-8 gherkin scenarios that, when ALL pass, prove the step is complete.
              Each scenario MUST have:
              1. Clear Given/When/Then structure
              2. An explicit verification command that returns exit code 0 on success
              3. Binary outcome: exactly 1 (pass) or 0 (fail)

              ## Gherkin Format
              Each scenario follows this exact structure:

              ```gherkin
              Scenario: [Descriptive name]
                Given [precondition or context]
                When [action taken]
                Then [expected outcome]

              Verification: `[shell command that exits 0 on success, non-zero on failure]`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ## Example Scenarios

              ### File Existence
              ```gherkin
              Scenario: Source file exists
                Given the project structure is set up
                When I check for the module file
                Then src/auth/service.ts exists

              Verification: `test -f src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### TypeScript Compilation
              ```gherkin
              Scenario: TypeScript compiles without errors
                Given the file src/auth/service.ts exists
                When I run the TypeScript compiler
                Then no compilation errors occur

              Verification: `npx tsc --noEmit src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Function Export
              ```gherkin
              Scenario: Login function is exported
                Given src/auth/service.ts exists
                When I check for the login export
                Then the function is publicly available

              Verification: `grep -q "export.*function login\|export.*const login\|export { login" src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### Test Execution
              ```gherkin
              Scenario: Unit tests pass
                Given tests exist in src/auth/service.test.ts
                When I run the test suite
                Then all tests pass

              Verification: `npm test -- --testPathPattern="auth/service" --passWithNoTests 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Lint Check
              ```gherkin
              Scenario: Code passes linting
                Given the implementation is complete
                When I run the linter
                Then no lint errors in new files

              Verification: `npm run lint -- src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ## Output
              Create: artifacts/step-10-gherkin.md

              ```markdown
              # Gherkin Scenarios: step-10

              ## Step Task
              ## Phase 4.1: Sprint Workflow Integration

              Create workflow step template for learning extraction:

              ### Tasks
              1. Create skills/managing-signs/assets/learning-extraction-workflow.yaml:
                 - Phase that runs after sprint completion
                 - Receives session transcript path
                 - Runs extraction with --confidence-min medium
                 - Outputs backlog summary

              2. Document integration in skills/managing-signs/SKILL.md:
                 - How to add learning extraction to sprint workflows
                 - Session transcript variable names
                 - Example workflow configurations

              3. Create example in skills/managing-signs/assets/sprint-with-learning.yaml:
                 - Complete sprint workflow
                 - Includes learning extraction phase
                 - Shows how phases connect

              ### Success Criteria
              - Workflow template is valid YAML
              - Integration documentation is clear
              - Example works with m42-sprint


              ## Success Criteria
              All scenarios must pass (score = 1) for the step to be complete.
              Total scenarios: [N]
              Required score: [N]/[N]

              ---

              ## Scenario 1: [Name]
              [Full gherkin with verification as shown above]

              ---

              ## Scenario 2: [Name]
              ...

              [Continue for 4-8 scenarios]
              ```

              ## Commit
              ```bash
              git add artifacts/step-10-gherkin.md
              git commit -m "plan(step-10): define gherkin scenarios"
              ```
          - id: context
            status: pending
            prompt: |
              Gather step-specific context for implementation.

              ## Your Task
              ## Phase 4.1: Sprint Workflow Integration

              Create workflow step template for learning extraction:

              ### Tasks
              1. Create skills/managing-signs/assets/learning-extraction-workflow.yaml:
                 - Phase that runs after sprint completion
                 - Receives session transcript path
                 - Runs extraction with --confidence-min medium
                 - Outputs backlog summary

              2. Document integration in skills/managing-signs/SKILL.md:
                 - How to add learning extraction to sprint workflows
                 - Session transcript variable names
                 - Example workflow configurations

              3. Create example in skills/managing-signs/assets/sprint-with-learning.yaml:
                 - Complete sprint workflow
                 - Includes learning extraction phase
                 - Shows how phases connect

              ### Success Criteria
              - Workflow template is valid YAML
              - Integration documentation is clear
              - Example works with m42-sprint


              ## Shared Context
              Read: context/_shared-context.md (already has project-wide patterns)
              Read: artifacts/step-10-gherkin.md (scenarios to implement)

              ## Instructions
              Research the specific code areas this step will touch:

              1. **Related Existing Code**
                 - Find similar implementations to follow as patterns
                 - Identify modules this step will import from
                 - Note any interfaces/types to implement or extend

              2. **Dependencies**
                 - List imports needed from internal modules
                 - List any new external packages needed
                 - Check for peer dependencies or version constraints

              3. **Integration Points**
                 - How will this code be called/used?
                 - What modules will import from this step's output?
                 - Are there existing tests to extend?

              4. **Specific Patterns**
                 - Error handling patterns used in similar code
                 - Naming conventions for this area
                 - File organization patterns

              ## Output
              Create: context/step-10-context.md

              ```markdown
              # Step Context: step-10

              ## Task
              ## Phase 4.1: Sprint Workflow Integration

              Create workflow step template for learning extraction:

              ### Tasks
              1. Create skills/managing-signs/assets/learning-extraction-workflow.yaml:
                 - Phase that runs after sprint completion
                 - Receives session transcript path
                 - Runs extraction with --confidence-min medium
                 - Outputs backlog summary

              2. Document integration in skills/managing-signs/SKILL.md:
                 - How to add learning extraction to sprint workflows
                 - Session transcript variable names
                 - Example workflow configurations

              3. Create example in skills/managing-signs/assets/sprint-with-learning.yaml:
                 - Complete sprint workflow
                 - Includes learning extraction phase
                 - Shows how phases connect

              ### Success Criteria
              - Workflow template is valid YAML
              - Integration documentation is clear
              - Example works with m42-sprint


              ## Related Code Patterns

              ### Similar Implementation: [path]
              ```typescript
              // Key pattern to follow
              [relevant code snippet]
              ```

              ### Similar Implementation: [path]
              [continue as needed]

              ## Required Imports
              ### Internal
              - `[module]`: [what to import]

              ### External
              - `[package]`: [what to import]

              ## Types/Interfaces to Use
              ```typescript
              // From [source]
              interface [Name] {
                [relevant fields]
              }
              ```

              ## Integration Points
              - Called by: [who will use this]
              - Calls: [what this will call]
              - Tests: [related test files]

              ## Implementation Notes
              - [Specific note 1]
              - [Specific note 2]
              ```

              ## Commit
              ```bash
              git add context/step-10-context.md
              git commit -m "context(step-10): gather implementation context"
              ```
          - id: execute
            status: pending
            prompt: |
              Implement the step following gherkin scenarios and context.

              ## Your Task
              ## Phase 4.1: Sprint Workflow Integration

              Create workflow step template for learning extraction:

              ### Tasks
              1. Create skills/managing-signs/assets/learning-extraction-workflow.yaml:
                 - Phase that runs after sprint completion
                 - Receives session transcript path
                 - Runs extraction with --confidence-min medium
                 - Outputs backlog summary

              2. Document integration in skills/managing-signs/SKILL.md:
                 - How to add learning extraction to sprint workflows
                 - Session transcript variable names
                 - Example workflow configurations

              3. Create example in skills/managing-signs/assets/sprint-with-learning.yaml:
                 - Complete sprint workflow
                 - Includes learning extraction phase
                 - Shows how phases connect

              ### Success Criteria
              - Workflow template is valid YAML
              - Integration documentation is clear
              - Example works with m42-sprint


              ## MUST READ BEFORE IMPLEMENTING
              Read these files in order:
              1. context/_shared-context.md (project patterns, conventions)
              2. context/sprint-plan.md (how this fits in sprint)
              3. artifacts/step-10-gherkin.md (scenarios to satisfy)
              4. context/step-10-context.md (specific patterns, imports)

              ## Implementation Rules

              ### Follow the Gherkin
              Your implementation MUST satisfy ALL gherkin scenarios.
              Each scenario has a verification command - mentally run it to check your work.

              ### Follow the Context
              - Use patterns from similar implementations
              - Import from specified modules
              - Implement required interfaces
              - Follow naming conventions

              ### Code Quality
              - Keep code simple and focused
              - Follow existing patterns exactly
              - No over-engineering or extra abstractions
              - Only implement what's needed for the scenarios

              ### Commits
              Make atomic commits for logical units:
              ```bash
              # After each logical piece
              git add [files]
              git commit -m "[type](step-10): [description]"
              ```

              Types: feat, fix, refactor, test, docs

              ## Implementation Checklist
              Before marking complete, verify:
              - [ ] All files from gherkin scenarios exist
              - [ ] Code follows patterns from context
              - [ ] Imports are correct
              - [ ] No TypeScript errors (run typecheck mentally)
              - [ ] Each scenario's verification should pass

              ## If Blocked
              If you encounter an issue that prevents completion:
              - Document the blocker clearly
              - Set status to needs-human
              - Do NOT leave partial/broken implementation
          - id: qa
            status: pending
            prompt: |
              Verify implementation against gherkin scenarios.

              ## Context
              Read: artifacts/step-10-gherkin.md (scenarios with verification commands)

              ## Step 1: Run Each Verification

              For EACH scenario in the gherkin file:
              1. Run the verification command
              2. Record the result: 1 (pass) or 0 (fail)
              3. If fail, capture the error output

              ## Step 2: Calculate Score

              Score = (passed scenarios) / (total scenarios)
              - Score = 1.0 (all pass) → PASS
              - Score < 1.0 (any fail) → FAIL

              ## Step 3: Generate QA Report

              Create: artifacts/step-10-qa-report.md

              ```markdown
              # QA Report: step-10

              ## Summary
              - Total Scenarios: [N]
              - Passed: [N]
              - Failed: [N]
              - Score: [X]/[N] = [percentage]%

              ## Verification Results

              | # | Scenario | Result | Details |
              |---|----------|--------|---------|
              | 1 | [Name] | PASS/FAIL | [output or error] |
              | 2 | [Name] | PASS/FAIL | [output or error] |
              ...

              ## Detailed Results

              ### Scenario 1: [Name]
              **Verification**: `[command]`
              **Exit Code**: [0 or N]
              **Output**:
              ```
              [actual output]
              ```
              **Result**: PASS / FAIL

              ### Scenario 2: [Name]
              ...

              ## Issues Found
              [If any failures, describe each issue]

              1. **[Scenario name]**: [What failed and why]

              ## Status: PASS / FAIL
              ```

              ## Step 4: Handle Outcome

              ### If ALL scenarios PASS (Score = 100%):
              1. Ensure report shows "Status: PASS"
              2. Commit the report:
                 ```bash
                 git add artifacts/step-10-qa-report.md
                 git commit -m "qa(step-10): all scenarios passed"
                 ```
              3. Mark phase as completed

              ### If ANY scenario FAILS (Score < 100%):
              You MUST inject fix phases. Do NOT just report and continue.

              1. Ensure report shows "Status: FAIL" with specific issues

              2. Find the PROGRESS.yaml file:
                 ```bash
                 PROGRESS_FILE=$(find .claude/sprints -name "PROGRESS.yaml" -type f 2>/dev/null | head -1)
                 echo "Found: $PROGRESS_FILE"
                 ```

              3. Inject fix and re-verify phases using yq:
                 ```bash
                 yq -i '
                   (.phases[] | select(.steps) | .steps[] | select(.status == "in-progress") | .phases) +=
                   [
                     {
                       "id": "fix",
                       "status": "pending",
                       "prompt": "Fix failing scenarios for step-10.\n\n## Context\nRead: artifacts/step-10-qa-report.md\n\n## Instructions\n1. Review each FAIL scenario\n2. Fix the implementation to make it pass\n3. Re-run the verification command to confirm\n4. Make atomic commits for each fix\n\n## After Fixing\nDo NOT mark as complete until ALL verifications pass."
                     },
                     {
                       "id": "reverify",
                       "status": "pending",
                       "prompt": "Re-verify all scenarios after fixes.\n\n## Instructions\nRe-run ALL verification commands from artifacts/step-10-gherkin.md\n\n## If ALL pass:\n- Update artifacts/step-10-qa-report.md with PASS status\n- Commit the updated report\n\n## If ANY still fail:\n- Update the QA report with new results\n- Inject another fix phase using yq\n- Loop continues until all pass"
                     }
                   ]
                 ' "$PROGRESS_FILE"
                 ```

              4. Mark current QA phase as failed:
                 ```bash
                 yq -i '
                   (.. | select(.id == "qa" and .status == "in-progress")) |=
                   (.status = "failed" | .error = "step-10 QA failed - see report - fix phase injected")
                 ' "$PROGRESS_FILE"
                 ```

              5. The sprint loop will now execute fix → reverify phases

              ## Important
              - EVERY scenario must pass for the step to be complete
              - Failed QA MUST inject fix phases, not just report
              - This creates a self-healing loop until all pass
          - id: verify
            status: pending
            prompt: |
              Final integration verification for the step.

              ## Your Task
              ## Phase 4.1: Sprint Workflow Integration

              Create workflow step template for learning extraction:

              ### Tasks
              1. Create skills/managing-signs/assets/learning-extraction-workflow.yaml:
                 - Phase that runs after sprint completion
                 - Receives session transcript path
                 - Runs extraction with --confidence-min medium
                 - Outputs backlog summary

              2. Document integration in skills/managing-signs/SKILL.md:
                 - How to add learning extraction to sprint workflows
                 - Session transcript variable names
                 - Example workflow configurations

              3. Create example in skills/managing-signs/assets/sprint-with-learning.yaml:
                 - Complete sprint workflow
                 - Includes learning extraction phase
                 - Shows how phases connect

              ### Success Criteria
              - Workflow template is valid YAML
              - Integration documentation is clear
              - Example works with m42-sprint


              ## Context
              Read: context/_shared-context.md (build commands)
              Read: artifacts/step-10-qa-report.md (should show PASS)

              ## Step 1: Build Verification
              Run the project build to ensure this step integrates:
              ```bash
              # Use commands from _shared-context.md, typically:
              npm run build
              npm run typecheck
              ```

              ## Step 2: Integration Check
              Verify this step works with the rest of the sprint:
              - Check imports resolve correctly
              - Verify no circular dependencies
              - Ensure types are compatible

              ## Step 3: Smoke Test
              If possible, manually verify the functionality:
              - Run the code path that uses this step's output
              - Check expected behavior matches gherkin scenarios

              ## Step 4: Final Commit
              If all verification passes:
              ```bash
              git add -A
              git status  # Check for any uncommitted changes
              # Only commit if there are changes
              git diff --cached --quiet || git commit -m "verify(step-10): integration verified"
              ```

              ## Outcome
              - If integration passes: Mark step as complete
              - If integration fails: Document the issue and set status to needs-human

              ## Important
              This is the final gate before moving to the next step.
              The step's gherkin scenarios already passed in QA.
              This phase ensures the step works in the broader context.
      - id: step-11
        prompt: |
          ## Phase 5.1: Getting Started Guide

          Create the primary user documentation:

          ### Tasks
          1. Create docs/getting-started.md:
             - Prerequisites (Claude Code installed, plugin enabled)
             - Installation steps
             - First sign in 5 minutes (quick tutorial)
             - Basic workflow: add -> list -> status
             - Link to how-to guides for more

          2. Structure docs/ folder:
             ```
             docs/
               getting-started.md    # Entry point
               how-to/
                 add-sign-manually.md
                 extract-from-session.md
                 review-and-apply.md
                 integrate-with-sprint.md
               reference/
                 commands.md         # All commands reference
                 backlog-format.md   # Schema documentation
             ```

          3. Update README.md:
             - Keep it concise (installation + quick example)
             - Add "Documentation" section with link to docs/getting-started.md
             - Add badges if appropriate

          ### Success Criteria
          - Getting started guide is complete and accurate
          - New user can add their first sign in < 5 minutes
          - docs/ structure is clear and navigable
        status: pending
        phases:
          - id: plan
            status: pending
            prompt: |
              Generate binary-verifiable gherkin scenarios for this step.

              ## Your Task
              ## Phase 5.1: Getting Started Guide

              Create the primary user documentation:

              ### Tasks
              1. Create docs/getting-started.md:
                 - Prerequisites (Claude Code installed, plugin enabled)
                 - Installation steps
                 - First sign in 5 minutes (quick tutorial)
                 - Basic workflow: add -> list -> status
                 - Link to how-to guides for more

              2. Structure docs/ folder:
                 ```
                 docs/
                   getting-started.md    # Entry point
                   how-to/
                     add-sign-manually.md
                     extract-from-session.md
                     review-and-apply.md
                     integrate-with-sprint.md
                   reference/
                     commands.md         # All commands reference
                     backlog-format.md   # Schema documentation
                 ```

              3. Update README.md:
                 - Keep it concise (installation + quick example)
                 - Add "Documentation" section with link to docs/getting-started.md
                 - Add badges if appropriate

              ### Success Criteria
              - Getting started guide is complete and accurate
              - New user can add their first sign in < 5 minutes
              - docs/ structure is clear and navigable


              ## Shared Context
              Read: context/_shared-context.md (project patterns, conventions, commands)
              Read: context/sprint-plan.md (how this step fits in the sprint)

              ## Instructions
              Create 4-8 gherkin scenarios that, when ALL pass, prove the step is complete.
              Each scenario MUST have:
              1. Clear Given/When/Then structure
              2. An explicit verification command that returns exit code 0 on success
              3. Binary outcome: exactly 1 (pass) or 0 (fail)

              ## Gherkin Format
              Each scenario follows this exact structure:

              ```gherkin
              Scenario: [Descriptive name]
                Given [precondition or context]
                When [action taken]
                Then [expected outcome]

              Verification: `[shell command that exits 0 on success, non-zero on failure]`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ## Example Scenarios

              ### File Existence
              ```gherkin
              Scenario: Source file exists
                Given the project structure is set up
                When I check for the module file
                Then src/auth/service.ts exists

              Verification: `test -f src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### TypeScript Compilation
              ```gherkin
              Scenario: TypeScript compiles without errors
                Given the file src/auth/service.ts exists
                When I run the TypeScript compiler
                Then no compilation errors occur

              Verification: `npx tsc --noEmit src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Function Export
              ```gherkin
              Scenario: Login function is exported
                Given src/auth/service.ts exists
                When I check for the login export
                Then the function is publicly available

              Verification: `grep -q "export.*function login\|export.*const login\|export { login" src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### Test Execution
              ```gherkin
              Scenario: Unit tests pass
                Given tests exist in src/auth/service.test.ts
                When I run the test suite
                Then all tests pass

              Verification: `npm test -- --testPathPattern="auth/service" --passWithNoTests 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Lint Check
              ```gherkin
              Scenario: Code passes linting
                Given the implementation is complete
                When I run the linter
                Then no lint errors in new files

              Verification: `npm run lint -- src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ## Output
              Create: artifacts/step-11-gherkin.md

              ```markdown
              # Gherkin Scenarios: step-11

              ## Step Task
              ## Phase 5.1: Getting Started Guide

              Create the primary user documentation:

              ### Tasks
              1. Create docs/getting-started.md:
                 - Prerequisites (Claude Code installed, plugin enabled)
                 - Installation steps
                 - First sign in 5 minutes (quick tutorial)
                 - Basic workflow: add -> list -> status
                 - Link to how-to guides for more

              2. Structure docs/ folder:
                 ```
                 docs/
                   getting-started.md    # Entry point
                   how-to/
                     add-sign-manually.md
                     extract-from-session.md
                     review-and-apply.md
                     integrate-with-sprint.md
                   reference/
                     commands.md         # All commands reference
                     backlog-format.md   # Schema documentation
                 ```

              3. Update README.md:
                 - Keep it concise (installation + quick example)
                 - Add "Documentation" section with link to docs/getting-started.md
                 - Add badges if appropriate

              ### Success Criteria
              - Getting started guide is complete and accurate
              - New user can add their first sign in < 5 minutes
              - docs/ structure is clear and navigable


              ## Success Criteria
              All scenarios must pass (score = 1) for the step to be complete.
              Total scenarios: [N]
              Required score: [N]/[N]

              ---

              ## Scenario 1: [Name]
              [Full gherkin with verification as shown above]

              ---

              ## Scenario 2: [Name]
              ...

              [Continue for 4-8 scenarios]
              ```

              ## Commit
              ```bash
              git add artifacts/step-11-gherkin.md
              git commit -m "plan(step-11): define gherkin scenarios"
              ```
          - id: context
            status: pending
            prompt: |
              Gather step-specific context for implementation.

              ## Your Task
              ## Phase 5.1: Getting Started Guide

              Create the primary user documentation:

              ### Tasks
              1. Create docs/getting-started.md:
                 - Prerequisites (Claude Code installed, plugin enabled)
                 - Installation steps
                 - First sign in 5 minutes (quick tutorial)
                 - Basic workflow: add -> list -> status
                 - Link to how-to guides for more

              2. Structure docs/ folder:
                 ```
                 docs/
                   getting-started.md    # Entry point
                   how-to/
                     add-sign-manually.md
                     extract-from-session.md
                     review-and-apply.md
                     integrate-with-sprint.md
                   reference/
                     commands.md         # All commands reference
                     backlog-format.md   # Schema documentation
                 ```

              3. Update README.md:
                 - Keep it concise (installation + quick example)
                 - Add "Documentation" section with link to docs/getting-started.md
                 - Add badges if appropriate

              ### Success Criteria
              - Getting started guide is complete and accurate
              - New user can add their first sign in < 5 minutes
              - docs/ structure is clear and navigable


              ## Shared Context
              Read: context/_shared-context.md (already has project-wide patterns)
              Read: artifacts/step-11-gherkin.md (scenarios to implement)

              ## Instructions
              Research the specific code areas this step will touch:

              1. **Related Existing Code**
                 - Find similar implementations to follow as patterns
                 - Identify modules this step will import from
                 - Note any interfaces/types to implement or extend

              2. **Dependencies**
                 - List imports needed from internal modules
                 - List any new external packages needed
                 - Check for peer dependencies or version constraints

              3. **Integration Points**
                 - How will this code be called/used?
                 - What modules will import from this step's output?
                 - Are there existing tests to extend?

              4. **Specific Patterns**
                 - Error handling patterns used in similar code
                 - Naming conventions for this area
                 - File organization patterns

              ## Output
              Create: context/step-11-context.md

              ```markdown
              # Step Context: step-11

              ## Task
              ## Phase 5.1: Getting Started Guide

              Create the primary user documentation:

              ### Tasks
              1. Create docs/getting-started.md:
                 - Prerequisites (Claude Code installed, plugin enabled)
                 - Installation steps
                 - First sign in 5 minutes (quick tutorial)
                 - Basic workflow: add -> list -> status
                 - Link to how-to guides for more

              2. Structure docs/ folder:
                 ```
                 docs/
                   getting-started.md    # Entry point
                   how-to/
                     add-sign-manually.md
                     extract-from-session.md
                     review-and-apply.md
                     integrate-with-sprint.md
                   reference/
                     commands.md         # All commands reference
                     backlog-format.md   # Schema documentation
                 ```

              3. Update README.md:
                 - Keep it concise (installation + quick example)
                 - Add "Documentation" section with link to docs/getting-started.md
                 - Add badges if appropriate

              ### Success Criteria
              - Getting started guide is complete and accurate
              - New user can add their first sign in < 5 minutes
              - docs/ structure is clear and navigable


              ## Related Code Patterns

              ### Similar Implementation: [path]
              ```typescript
              // Key pattern to follow
              [relevant code snippet]
              ```

              ### Similar Implementation: [path]
              [continue as needed]

              ## Required Imports
              ### Internal
              - `[module]`: [what to import]

              ### External
              - `[package]`: [what to import]

              ## Types/Interfaces to Use
              ```typescript
              // From [source]
              interface [Name] {
                [relevant fields]
              }
              ```

              ## Integration Points
              - Called by: [who will use this]
              - Calls: [what this will call]
              - Tests: [related test files]

              ## Implementation Notes
              - [Specific note 1]
              - [Specific note 2]
              ```

              ## Commit
              ```bash
              git add context/step-11-context.md
              git commit -m "context(step-11): gather implementation context"
              ```
          - id: execute
            status: pending
            prompt: |
              Implement the step following gherkin scenarios and context.

              ## Your Task
              ## Phase 5.1: Getting Started Guide

              Create the primary user documentation:

              ### Tasks
              1. Create docs/getting-started.md:
                 - Prerequisites (Claude Code installed, plugin enabled)
                 - Installation steps
                 - First sign in 5 minutes (quick tutorial)
                 - Basic workflow: add -> list -> status
                 - Link to how-to guides for more

              2. Structure docs/ folder:
                 ```
                 docs/
                   getting-started.md    # Entry point
                   how-to/
                     add-sign-manually.md
                     extract-from-session.md
                     review-and-apply.md
                     integrate-with-sprint.md
                   reference/
                     commands.md         # All commands reference
                     backlog-format.md   # Schema documentation
                 ```

              3. Update README.md:
                 - Keep it concise (installation + quick example)
                 - Add "Documentation" section with link to docs/getting-started.md
                 - Add badges if appropriate

              ### Success Criteria
              - Getting started guide is complete and accurate
              - New user can add their first sign in < 5 minutes
              - docs/ structure is clear and navigable


              ## MUST READ BEFORE IMPLEMENTING
              Read these files in order:
              1. context/_shared-context.md (project patterns, conventions)
              2. context/sprint-plan.md (how this fits in sprint)
              3. artifacts/step-11-gherkin.md (scenarios to satisfy)
              4. context/step-11-context.md (specific patterns, imports)

              ## Implementation Rules

              ### Follow the Gherkin
              Your implementation MUST satisfy ALL gherkin scenarios.
              Each scenario has a verification command - mentally run it to check your work.

              ### Follow the Context
              - Use patterns from similar implementations
              - Import from specified modules
              - Implement required interfaces
              - Follow naming conventions

              ### Code Quality
              - Keep code simple and focused
              - Follow existing patterns exactly
              - No over-engineering or extra abstractions
              - Only implement what's needed for the scenarios

              ### Commits
              Make atomic commits for logical units:
              ```bash
              # After each logical piece
              git add [files]
              git commit -m "[type](step-11): [description]"
              ```

              Types: feat, fix, refactor, test, docs

              ## Implementation Checklist
              Before marking complete, verify:
              - [ ] All files from gherkin scenarios exist
              - [ ] Code follows patterns from context
              - [ ] Imports are correct
              - [ ] No TypeScript errors (run typecheck mentally)
              - [ ] Each scenario's verification should pass

              ## If Blocked
              If you encounter an issue that prevents completion:
              - Document the blocker clearly
              - Set status to needs-human
              - Do NOT leave partial/broken implementation
          - id: qa
            status: pending
            prompt: |
              Verify implementation against gherkin scenarios.

              ## Context
              Read: artifacts/step-11-gherkin.md (scenarios with verification commands)

              ## Step 1: Run Each Verification

              For EACH scenario in the gherkin file:
              1. Run the verification command
              2. Record the result: 1 (pass) or 0 (fail)
              3. If fail, capture the error output

              ## Step 2: Calculate Score

              Score = (passed scenarios) / (total scenarios)
              - Score = 1.0 (all pass) → PASS
              - Score < 1.0 (any fail) → FAIL

              ## Step 3: Generate QA Report

              Create: artifacts/step-11-qa-report.md

              ```markdown
              # QA Report: step-11

              ## Summary
              - Total Scenarios: [N]
              - Passed: [N]
              - Failed: [N]
              - Score: [X]/[N] = [percentage]%

              ## Verification Results

              | # | Scenario | Result | Details |
              |---|----------|--------|---------|
              | 1 | [Name] | PASS/FAIL | [output or error] |
              | 2 | [Name] | PASS/FAIL | [output or error] |
              ...

              ## Detailed Results

              ### Scenario 1: [Name]
              **Verification**: `[command]`
              **Exit Code**: [0 or N]
              **Output**:
              ```
              [actual output]
              ```
              **Result**: PASS / FAIL

              ### Scenario 2: [Name]
              ...

              ## Issues Found
              [If any failures, describe each issue]

              1. **[Scenario name]**: [What failed and why]

              ## Status: PASS / FAIL
              ```

              ## Step 4: Handle Outcome

              ### If ALL scenarios PASS (Score = 100%):
              1. Ensure report shows "Status: PASS"
              2. Commit the report:
                 ```bash
                 git add artifacts/step-11-qa-report.md
                 git commit -m "qa(step-11): all scenarios passed"
                 ```
              3. Mark phase as completed

              ### If ANY scenario FAILS (Score < 100%):
              You MUST inject fix phases. Do NOT just report and continue.

              1. Ensure report shows "Status: FAIL" with specific issues

              2. Find the PROGRESS.yaml file:
                 ```bash
                 PROGRESS_FILE=$(find .claude/sprints -name "PROGRESS.yaml" -type f 2>/dev/null | head -1)
                 echo "Found: $PROGRESS_FILE"
                 ```

              3. Inject fix and re-verify phases using yq:
                 ```bash
                 yq -i '
                   (.phases[] | select(.steps) | .steps[] | select(.status == "in-progress") | .phases) +=
                   [
                     {
                       "id": "fix",
                       "status": "pending",
                       "prompt": "Fix failing scenarios for step-11.\n\n## Context\nRead: artifacts/step-11-qa-report.md\n\n## Instructions\n1. Review each FAIL scenario\n2. Fix the implementation to make it pass\n3. Re-run the verification command to confirm\n4. Make atomic commits for each fix\n\n## After Fixing\nDo NOT mark as complete until ALL verifications pass."
                     },
                     {
                       "id": "reverify",
                       "status": "pending",
                       "prompt": "Re-verify all scenarios after fixes.\n\n## Instructions\nRe-run ALL verification commands from artifacts/step-11-gherkin.md\n\n## If ALL pass:\n- Update artifacts/step-11-qa-report.md with PASS status\n- Commit the updated report\n\n## If ANY still fail:\n- Update the QA report with new results\n- Inject another fix phase using yq\n- Loop continues until all pass"
                     }
                   ]
                 ' "$PROGRESS_FILE"
                 ```

              4. Mark current QA phase as failed:
                 ```bash
                 yq -i '
                   (.. | select(.id == "qa" and .status == "in-progress")) |=
                   (.status = "failed" | .error = "step-11 QA failed - see report - fix phase injected")
                 ' "$PROGRESS_FILE"
                 ```

              5. The sprint loop will now execute fix → reverify phases

              ## Important
              - EVERY scenario must pass for the step to be complete
              - Failed QA MUST inject fix phases, not just report
              - This creates a self-healing loop until all pass
          - id: verify
            status: pending
            prompt: |
              Final integration verification for the step.

              ## Your Task
              ## Phase 5.1: Getting Started Guide

              Create the primary user documentation:

              ### Tasks
              1. Create docs/getting-started.md:
                 - Prerequisites (Claude Code installed, plugin enabled)
                 - Installation steps
                 - First sign in 5 minutes (quick tutorial)
                 - Basic workflow: add -> list -> status
                 - Link to how-to guides for more

              2. Structure docs/ folder:
                 ```
                 docs/
                   getting-started.md    # Entry point
                   how-to/
                     add-sign-manually.md
                     extract-from-session.md
                     review-and-apply.md
                     integrate-with-sprint.md
                   reference/
                     commands.md         # All commands reference
                     backlog-format.md   # Schema documentation
                 ```

              3. Update README.md:
                 - Keep it concise (installation + quick example)
                 - Add "Documentation" section with link to docs/getting-started.md
                 - Add badges if appropriate

              ### Success Criteria
              - Getting started guide is complete and accurate
              - New user can add their first sign in < 5 minutes
              - docs/ structure is clear and navigable


              ## Context
              Read: context/_shared-context.md (build commands)
              Read: artifacts/step-11-qa-report.md (should show PASS)

              ## Step 1: Build Verification
              Run the project build to ensure this step integrates:
              ```bash
              # Use commands from _shared-context.md, typically:
              npm run build
              npm run typecheck
              ```

              ## Step 2: Integration Check
              Verify this step works with the rest of the sprint:
              - Check imports resolve correctly
              - Verify no circular dependencies
              - Ensure types are compatible

              ## Step 3: Smoke Test
              If possible, manually verify the functionality:
              - Run the code path that uses this step's output
              - Check expected behavior matches gherkin scenarios

              ## Step 4: Final Commit
              If all verification passes:
              ```bash
              git add -A
              git status  # Check for any uncommitted changes
              # Only commit if there are changes
              git diff --cached --quiet || git commit -m "verify(step-11): integration verified"
              ```

              ## Outcome
              - If integration passes: Mark step as complete
              - If integration fails: Document the issue and set status to needs-human

              ## Important
              This is the final gate before moving to the next step.
              The step's gherkin scenarios already passed in QA.
              This phase ensures the step works in the broader context.
      - id: step-12
        prompt: |
          ## Phase 5.2: How-To Guides

          Create task-oriented how-to guides:

          ### Tasks
          1. Create docs/how-to/add-sign-manually.md:
             - When to add signs manually vs extract
             - Step-by-step with /m42-signs:add
             - Using --direct flag
             - Examples of good sign content

          2. Create docs/how-to/extract-from-session.md:
             - Finding session IDs
             - Running /m42-signs:extract
             - Understanding confidence levels
             - Filtering and dry-run options

          3. Create docs/how-to/review-and-apply.md:
             - The review workflow
             - Editing learnings
             - Batch operations
             - Git commit integration

          4. Create docs/how-to/integrate-with-sprint.md:
             - Adding learning extraction to workflows
             - Automatic vs manual extraction
             - End-of-sprint analysis patterns

          ### Success Criteria
          - Each guide is self-contained and actionable
          - Includes concrete examples
          - Links to related guides where relevant
        status: pending
        phases:
          - id: plan
            status: pending
            prompt: |
              Generate binary-verifiable gherkin scenarios for this step.

              ## Your Task
              ## Phase 5.2: How-To Guides

              Create task-oriented how-to guides:

              ### Tasks
              1. Create docs/how-to/add-sign-manually.md:
                 - When to add signs manually vs extract
                 - Step-by-step with /m42-signs:add
                 - Using --direct flag
                 - Examples of good sign content

              2. Create docs/how-to/extract-from-session.md:
                 - Finding session IDs
                 - Running /m42-signs:extract
                 - Understanding confidence levels
                 - Filtering and dry-run options

              3. Create docs/how-to/review-and-apply.md:
                 - The review workflow
                 - Editing learnings
                 - Batch operations
                 - Git commit integration

              4. Create docs/how-to/integrate-with-sprint.md:
                 - Adding learning extraction to workflows
                 - Automatic vs manual extraction
                 - End-of-sprint analysis patterns

              ### Success Criteria
              - Each guide is self-contained and actionable
              - Includes concrete examples
              - Links to related guides where relevant


              ## Shared Context
              Read: context/_shared-context.md (project patterns, conventions, commands)
              Read: context/sprint-plan.md (how this step fits in the sprint)

              ## Instructions
              Create 4-8 gherkin scenarios that, when ALL pass, prove the step is complete.
              Each scenario MUST have:
              1. Clear Given/When/Then structure
              2. An explicit verification command that returns exit code 0 on success
              3. Binary outcome: exactly 1 (pass) or 0 (fail)

              ## Gherkin Format
              Each scenario follows this exact structure:

              ```gherkin
              Scenario: [Descriptive name]
                Given [precondition or context]
                When [action taken]
                Then [expected outcome]

              Verification: `[shell command that exits 0 on success, non-zero on failure]`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ## Example Scenarios

              ### File Existence
              ```gherkin
              Scenario: Source file exists
                Given the project structure is set up
                When I check for the module file
                Then src/auth/service.ts exists

              Verification: `test -f src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### TypeScript Compilation
              ```gherkin
              Scenario: TypeScript compiles without errors
                Given the file src/auth/service.ts exists
                When I run the TypeScript compiler
                Then no compilation errors occur

              Verification: `npx tsc --noEmit src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Function Export
              ```gherkin
              Scenario: Login function is exported
                Given src/auth/service.ts exists
                When I check for the login export
                Then the function is publicly available

              Verification: `grep -q "export.*function login\|export.*const login\|export { login" src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### Test Execution
              ```gherkin
              Scenario: Unit tests pass
                Given tests exist in src/auth/service.test.ts
                When I run the test suite
                Then all tests pass

              Verification: `npm test -- --testPathPattern="auth/service" --passWithNoTests 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Lint Check
              ```gherkin
              Scenario: Code passes linting
                Given the implementation is complete
                When I run the linter
                Then no lint errors in new files

              Verification: `npm run lint -- src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ## Output
              Create: artifacts/step-12-gherkin.md

              ```markdown
              # Gherkin Scenarios: step-12

              ## Step Task
              ## Phase 5.2: How-To Guides

              Create task-oriented how-to guides:

              ### Tasks
              1. Create docs/how-to/add-sign-manually.md:
                 - When to add signs manually vs extract
                 - Step-by-step with /m42-signs:add
                 - Using --direct flag
                 - Examples of good sign content

              2. Create docs/how-to/extract-from-session.md:
                 - Finding session IDs
                 - Running /m42-signs:extract
                 - Understanding confidence levels
                 - Filtering and dry-run options

              3. Create docs/how-to/review-and-apply.md:
                 - The review workflow
                 - Editing learnings
                 - Batch operations
                 - Git commit integration

              4. Create docs/how-to/integrate-with-sprint.md:
                 - Adding learning extraction to workflows
                 - Automatic vs manual extraction
                 - End-of-sprint analysis patterns

              ### Success Criteria
              - Each guide is self-contained and actionable
              - Includes concrete examples
              - Links to related guides where relevant


              ## Success Criteria
              All scenarios must pass (score = 1) for the step to be complete.
              Total scenarios: [N]
              Required score: [N]/[N]

              ---

              ## Scenario 1: [Name]
              [Full gherkin with verification as shown above]

              ---

              ## Scenario 2: [Name]
              ...

              [Continue for 4-8 scenarios]
              ```

              ## Commit
              ```bash
              git add artifacts/step-12-gherkin.md
              git commit -m "plan(step-12): define gherkin scenarios"
              ```
          - id: context
            status: pending
            prompt: |
              Gather step-specific context for implementation.

              ## Your Task
              ## Phase 5.2: How-To Guides

              Create task-oriented how-to guides:

              ### Tasks
              1. Create docs/how-to/add-sign-manually.md:
                 - When to add signs manually vs extract
                 - Step-by-step with /m42-signs:add
                 - Using --direct flag
                 - Examples of good sign content

              2. Create docs/how-to/extract-from-session.md:
                 - Finding session IDs
                 - Running /m42-signs:extract
                 - Understanding confidence levels
                 - Filtering and dry-run options

              3. Create docs/how-to/review-and-apply.md:
                 - The review workflow
                 - Editing learnings
                 - Batch operations
                 - Git commit integration

              4. Create docs/how-to/integrate-with-sprint.md:
                 - Adding learning extraction to workflows
                 - Automatic vs manual extraction
                 - End-of-sprint analysis patterns

              ### Success Criteria
              - Each guide is self-contained and actionable
              - Includes concrete examples
              - Links to related guides where relevant


              ## Shared Context
              Read: context/_shared-context.md (already has project-wide patterns)
              Read: artifacts/step-12-gherkin.md (scenarios to implement)

              ## Instructions
              Research the specific code areas this step will touch:

              1. **Related Existing Code**
                 - Find similar implementations to follow as patterns
                 - Identify modules this step will import from
                 - Note any interfaces/types to implement or extend

              2. **Dependencies**
                 - List imports needed from internal modules
                 - List any new external packages needed
                 - Check for peer dependencies or version constraints

              3. **Integration Points**
                 - How will this code be called/used?
                 - What modules will import from this step's output?
                 - Are there existing tests to extend?

              4. **Specific Patterns**
                 - Error handling patterns used in similar code
                 - Naming conventions for this area
                 - File organization patterns

              ## Output
              Create: context/step-12-context.md

              ```markdown
              # Step Context: step-12

              ## Task
              ## Phase 5.2: How-To Guides

              Create task-oriented how-to guides:

              ### Tasks
              1. Create docs/how-to/add-sign-manually.md:
                 - When to add signs manually vs extract
                 - Step-by-step with /m42-signs:add
                 - Using --direct flag
                 - Examples of good sign content

              2. Create docs/how-to/extract-from-session.md:
                 - Finding session IDs
                 - Running /m42-signs:extract
                 - Understanding confidence levels
                 - Filtering and dry-run options

              3. Create docs/how-to/review-and-apply.md:
                 - The review workflow
                 - Editing learnings
                 - Batch operations
                 - Git commit integration

              4. Create docs/how-to/integrate-with-sprint.md:
                 - Adding learning extraction to workflows
                 - Automatic vs manual extraction
                 - End-of-sprint analysis patterns

              ### Success Criteria
              - Each guide is self-contained and actionable
              - Includes concrete examples
              - Links to related guides where relevant


              ## Related Code Patterns

              ### Similar Implementation: [path]
              ```typescript
              // Key pattern to follow
              [relevant code snippet]
              ```

              ### Similar Implementation: [path]
              [continue as needed]

              ## Required Imports
              ### Internal
              - `[module]`: [what to import]

              ### External
              - `[package]`: [what to import]

              ## Types/Interfaces to Use
              ```typescript
              // From [source]
              interface [Name] {
                [relevant fields]
              }
              ```

              ## Integration Points
              - Called by: [who will use this]
              - Calls: [what this will call]
              - Tests: [related test files]

              ## Implementation Notes
              - [Specific note 1]
              - [Specific note 2]
              ```

              ## Commit
              ```bash
              git add context/step-12-context.md
              git commit -m "context(step-12): gather implementation context"
              ```
          - id: execute
            status: pending
            prompt: |
              Implement the step following gherkin scenarios and context.

              ## Your Task
              ## Phase 5.2: How-To Guides

              Create task-oriented how-to guides:

              ### Tasks
              1. Create docs/how-to/add-sign-manually.md:
                 - When to add signs manually vs extract
                 - Step-by-step with /m42-signs:add
                 - Using --direct flag
                 - Examples of good sign content

              2. Create docs/how-to/extract-from-session.md:
                 - Finding session IDs
                 - Running /m42-signs:extract
                 - Understanding confidence levels
                 - Filtering and dry-run options

              3. Create docs/how-to/review-and-apply.md:
                 - The review workflow
                 - Editing learnings
                 - Batch operations
                 - Git commit integration

              4. Create docs/how-to/integrate-with-sprint.md:
                 - Adding learning extraction to workflows
                 - Automatic vs manual extraction
                 - End-of-sprint analysis patterns

              ### Success Criteria
              - Each guide is self-contained and actionable
              - Includes concrete examples
              - Links to related guides where relevant


              ## MUST READ BEFORE IMPLEMENTING
              Read these files in order:
              1. context/_shared-context.md (project patterns, conventions)
              2. context/sprint-plan.md (how this fits in sprint)
              3. artifacts/step-12-gherkin.md (scenarios to satisfy)
              4. context/step-12-context.md (specific patterns, imports)

              ## Implementation Rules

              ### Follow the Gherkin
              Your implementation MUST satisfy ALL gherkin scenarios.
              Each scenario has a verification command - mentally run it to check your work.

              ### Follow the Context
              - Use patterns from similar implementations
              - Import from specified modules
              - Implement required interfaces
              - Follow naming conventions

              ### Code Quality
              - Keep code simple and focused
              - Follow existing patterns exactly
              - No over-engineering or extra abstractions
              - Only implement what's needed for the scenarios

              ### Commits
              Make atomic commits for logical units:
              ```bash
              # After each logical piece
              git add [files]
              git commit -m "[type](step-12): [description]"
              ```

              Types: feat, fix, refactor, test, docs

              ## Implementation Checklist
              Before marking complete, verify:
              - [ ] All files from gherkin scenarios exist
              - [ ] Code follows patterns from context
              - [ ] Imports are correct
              - [ ] No TypeScript errors (run typecheck mentally)
              - [ ] Each scenario's verification should pass

              ## If Blocked
              If you encounter an issue that prevents completion:
              - Document the blocker clearly
              - Set status to needs-human
              - Do NOT leave partial/broken implementation
          - id: qa
            status: pending
            prompt: |
              Verify implementation against gherkin scenarios.

              ## Context
              Read: artifacts/step-12-gherkin.md (scenarios with verification commands)

              ## Step 1: Run Each Verification

              For EACH scenario in the gherkin file:
              1. Run the verification command
              2. Record the result: 1 (pass) or 0 (fail)
              3. If fail, capture the error output

              ## Step 2: Calculate Score

              Score = (passed scenarios) / (total scenarios)
              - Score = 1.0 (all pass) → PASS
              - Score < 1.0 (any fail) → FAIL

              ## Step 3: Generate QA Report

              Create: artifacts/step-12-qa-report.md

              ```markdown
              # QA Report: step-12

              ## Summary
              - Total Scenarios: [N]
              - Passed: [N]
              - Failed: [N]
              - Score: [X]/[N] = [percentage]%

              ## Verification Results

              | # | Scenario | Result | Details |
              |---|----------|--------|---------|
              | 1 | [Name] | PASS/FAIL | [output or error] |
              | 2 | [Name] | PASS/FAIL | [output or error] |
              ...

              ## Detailed Results

              ### Scenario 1: [Name]
              **Verification**: `[command]`
              **Exit Code**: [0 or N]
              **Output**:
              ```
              [actual output]
              ```
              **Result**: PASS / FAIL

              ### Scenario 2: [Name]
              ...

              ## Issues Found
              [If any failures, describe each issue]

              1. **[Scenario name]**: [What failed and why]

              ## Status: PASS / FAIL
              ```

              ## Step 4: Handle Outcome

              ### If ALL scenarios PASS (Score = 100%):
              1. Ensure report shows "Status: PASS"
              2. Commit the report:
                 ```bash
                 git add artifacts/step-12-qa-report.md
                 git commit -m "qa(step-12): all scenarios passed"
                 ```
              3. Mark phase as completed

              ### If ANY scenario FAILS (Score < 100%):
              You MUST inject fix phases. Do NOT just report and continue.

              1. Ensure report shows "Status: FAIL" with specific issues

              2. Find the PROGRESS.yaml file:
                 ```bash
                 PROGRESS_FILE=$(find .claude/sprints -name "PROGRESS.yaml" -type f 2>/dev/null | head -1)
                 echo "Found: $PROGRESS_FILE"
                 ```

              3. Inject fix and re-verify phases using yq:
                 ```bash
                 yq -i '
                   (.phases[] | select(.steps) | .steps[] | select(.status == "in-progress") | .phases) +=
                   [
                     {
                       "id": "fix",
                       "status": "pending",
                       "prompt": "Fix failing scenarios for step-12.\n\n## Context\nRead: artifacts/step-12-qa-report.md\n\n## Instructions\n1. Review each FAIL scenario\n2. Fix the implementation to make it pass\n3. Re-run the verification command to confirm\n4. Make atomic commits for each fix\n\n## After Fixing\nDo NOT mark as complete until ALL verifications pass."
                     },
                     {
                       "id": "reverify",
                       "status": "pending",
                       "prompt": "Re-verify all scenarios after fixes.\n\n## Instructions\nRe-run ALL verification commands from artifacts/step-12-gherkin.md\n\n## If ALL pass:\n- Update artifacts/step-12-qa-report.md with PASS status\n- Commit the updated report\n\n## If ANY still fail:\n- Update the QA report with new results\n- Inject another fix phase using yq\n- Loop continues until all pass"
                     }
                   ]
                 ' "$PROGRESS_FILE"
                 ```

              4. Mark current QA phase as failed:
                 ```bash
                 yq -i '
                   (.. | select(.id == "qa" and .status == "in-progress")) |=
                   (.status = "failed" | .error = "step-12 QA failed - see report - fix phase injected")
                 ' "$PROGRESS_FILE"
                 ```

              5. The sprint loop will now execute fix → reverify phases

              ## Important
              - EVERY scenario must pass for the step to be complete
              - Failed QA MUST inject fix phases, not just report
              - This creates a self-healing loop until all pass
          - id: verify
            status: pending
            prompt: |
              Final integration verification for the step.

              ## Your Task
              ## Phase 5.2: How-To Guides

              Create task-oriented how-to guides:

              ### Tasks
              1. Create docs/how-to/add-sign-manually.md:
                 - When to add signs manually vs extract
                 - Step-by-step with /m42-signs:add
                 - Using --direct flag
                 - Examples of good sign content

              2. Create docs/how-to/extract-from-session.md:
                 - Finding session IDs
                 - Running /m42-signs:extract
                 - Understanding confidence levels
                 - Filtering and dry-run options

              3. Create docs/how-to/review-and-apply.md:
                 - The review workflow
                 - Editing learnings
                 - Batch operations
                 - Git commit integration

              4. Create docs/how-to/integrate-with-sprint.md:
                 - Adding learning extraction to workflows
                 - Automatic vs manual extraction
                 - End-of-sprint analysis patterns

              ### Success Criteria
              - Each guide is self-contained and actionable
              - Includes concrete examples
              - Links to related guides where relevant


              ## Context
              Read: context/_shared-context.md (build commands)
              Read: artifacts/step-12-qa-report.md (should show PASS)

              ## Step 1: Build Verification
              Run the project build to ensure this step integrates:
              ```bash
              # Use commands from _shared-context.md, typically:
              npm run build
              npm run typecheck
              ```

              ## Step 2: Integration Check
              Verify this step works with the rest of the sprint:
              - Check imports resolve correctly
              - Verify no circular dependencies
              - Ensure types are compatible

              ## Step 3: Smoke Test
              If possible, manually verify the functionality:
              - Run the code path that uses this step's output
              - Check expected behavior matches gherkin scenarios

              ## Step 4: Final Commit
              If all verification passes:
              ```bash
              git add -A
              git status  # Check for any uncommitted changes
              # Only commit if there are changes
              git diff --cached --quiet || git commit -m "verify(step-12): integration verified"
              ```

              ## Outcome
              - If integration passes: Mark step as complete
              - If integration fails: Document the issue and set status to needs-human

              ## Important
              This is the final gate before moving to the next step.
              The step's gherkin scenarios already passed in QA.
              This phase ensures the step works in the broader context.
      - id: step-13
        prompt: |
          ## Phase 5.3: Reference Documentation

          Create comprehensive reference docs:

          ### Tasks
          1. Create docs/reference/commands.md:
             - All commands with full syntax
             - All options/flags documented
             - Examples for each command
             - Common errors and solutions

          2. Create docs/reference/backlog-format.md:
             - Complete YAML schema
             - All fields explained
             - Status transitions
             - Example entries

          3. Create docs/reference/sign-format.md:
             - How signs appear in CLAUDE.md
             - Formatting conventions
             - Origin tracking explained

          ### Success Criteria
          - Reference is comprehensive
          - Easy to find specific information
          - Code examples are copy-pasteable
        status: pending
        phases:
          - id: plan
            status: pending
            prompt: |
              Generate binary-verifiable gherkin scenarios for this step.

              ## Your Task
              ## Phase 5.3: Reference Documentation

              Create comprehensive reference docs:

              ### Tasks
              1. Create docs/reference/commands.md:
                 - All commands with full syntax
                 - All options/flags documented
                 - Examples for each command
                 - Common errors and solutions

              2. Create docs/reference/backlog-format.md:
                 - Complete YAML schema
                 - All fields explained
                 - Status transitions
                 - Example entries

              3. Create docs/reference/sign-format.md:
                 - How signs appear in CLAUDE.md
                 - Formatting conventions
                 - Origin tracking explained

              ### Success Criteria
              - Reference is comprehensive
              - Easy to find specific information
              - Code examples are copy-pasteable


              ## Shared Context
              Read: context/_shared-context.md (project patterns, conventions, commands)
              Read: context/sprint-plan.md (how this step fits in the sprint)

              ## Instructions
              Create 4-8 gherkin scenarios that, when ALL pass, prove the step is complete.
              Each scenario MUST have:
              1. Clear Given/When/Then structure
              2. An explicit verification command that returns exit code 0 on success
              3. Binary outcome: exactly 1 (pass) or 0 (fail)

              ## Gherkin Format
              Each scenario follows this exact structure:

              ```gherkin
              Scenario: [Descriptive name]
                Given [precondition or context]
                When [action taken]
                Then [expected outcome]

              Verification: `[shell command that exits 0 on success, non-zero on failure]`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ## Example Scenarios

              ### File Existence
              ```gherkin
              Scenario: Source file exists
                Given the project structure is set up
                When I check for the module file
                Then src/auth/service.ts exists

              Verification: `test -f src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### TypeScript Compilation
              ```gherkin
              Scenario: TypeScript compiles without errors
                Given the file src/auth/service.ts exists
                When I run the TypeScript compiler
                Then no compilation errors occur

              Verification: `npx tsc --noEmit src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Function Export
              ```gherkin
              Scenario: Login function is exported
                Given src/auth/service.ts exists
                When I check for the login export
                Then the function is publicly available

              Verification: `grep -q "export.*function login\|export.*const login\|export { login" src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### Test Execution
              ```gherkin
              Scenario: Unit tests pass
                Given tests exist in src/auth/service.test.ts
                When I run the test suite
                Then all tests pass

              Verification: `npm test -- --testPathPattern="auth/service" --passWithNoTests 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Lint Check
              ```gherkin
              Scenario: Code passes linting
                Given the implementation is complete
                When I run the linter
                Then no lint errors in new files

              Verification: `npm run lint -- src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ## Output
              Create: artifacts/step-13-gherkin.md

              ```markdown
              # Gherkin Scenarios: step-13

              ## Step Task
              ## Phase 5.3: Reference Documentation

              Create comprehensive reference docs:

              ### Tasks
              1. Create docs/reference/commands.md:
                 - All commands with full syntax
                 - All options/flags documented
                 - Examples for each command
                 - Common errors and solutions

              2. Create docs/reference/backlog-format.md:
                 - Complete YAML schema
                 - All fields explained
                 - Status transitions
                 - Example entries

              3. Create docs/reference/sign-format.md:
                 - How signs appear in CLAUDE.md
                 - Formatting conventions
                 - Origin tracking explained

              ### Success Criteria
              - Reference is comprehensive
              - Easy to find specific information
              - Code examples are copy-pasteable


              ## Success Criteria
              All scenarios must pass (score = 1) for the step to be complete.
              Total scenarios: [N]
              Required score: [N]/[N]

              ---

              ## Scenario 1: [Name]
              [Full gherkin with verification as shown above]

              ---

              ## Scenario 2: [Name]
              ...

              [Continue for 4-8 scenarios]
              ```

              ## Commit
              ```bash
              git add artifacts/step-13-gherkin.md
              git commit -m "plan(step-13): define gherkin scenarios"
              ```
          - id: context
            status: pending
            prompt: |
              Gather step-specific context for implementation.

              ## Your Task
              ## Phase 5.3: Reference Documentation

              Create comprehensive reference docs:

              ### Tasks
              1. Create docs/reference/commands.md:
                 - All commands with full syntax
                 - All options/flags documented
                 - Examples for each command
                 - Common errors and solutions

              2. Create docs/reference/backlog-format.md:
                 - Complete YAML schema
                 - All fields explained
                 - Status transitions
                 - Example entries

              3. Create docs/reference/sign-format.md:
                 - How signs appear in CLAUDE.md
                 - Formatting conventions
                 - Origin tracking explained

              ### Success Criteria
              - Reference is comprehensive
              - Easy to find specific information
              - Code examples are copy-pasteable


              ## Shared Context
              Read: context/_shared-context.md (already has project-wide patterns)
              Read: artifacts/step-13-gherkin.md (scenarios to implement)

              ## Instructions
              Research the specific code areas this step will touch:

              1. **Related Existing Code**
                 - Find similar implementations to follow as patterns
                 - Identify modules this step will import from
                 - Note any interfaces/types to implement or extend

              2. **Dependencies**
                 - List imports needed from internal modules
                 - List any new external packages needed
                 - Check for peer dependencies or version constraints

              3. **Integration Points**
                 - How will this code be called/used?
                 - What modules will import from this step's output?
                 - Are there existing tests to extend?

              4. **Specific Patterns**
                 - Error handling patterns used in similar code
                 - Naming conventions for this area
                 - File organization patterns

              ## Output
              Create: context/step-13-context.md

              ```markdown
              # Step Context: step-13

              ## Task
              ## Phase 5.3: Reference Documentation

              Create comprehensive reference docs:

              ### Tasks
              1. Create docs/reference/commands.md:
                 - All commands with full syntax
                 - All options/flags documented
                 - Examples for each command
                 - Common errors and solutions

              2. Create docs/reference/backlog-format.md:
                 - Complete YAML schema
                 - All fields explained
                 - Status transitions
                 - Example entries

              3. Create docs/reference/sign-format.md:
                 - How signs appear in CLAUDE.md
                 - Formatting conventions
                 - Origin tracking explained

              ### Success Criteria
              - Reference is comprehensive
              - Easy to find specific information
              - Code examples are copy-pasteable


              ## Related Code Patterns

              ### Similar Implementation: [path]
              ```typescript
              // Key pattern to follow
              [relevant code snippet]
              ```

              ### Similar Implementation: [path]
              [continue as needed]

              ## Required Imports
              ### Internal
              - `[module]`: [what to import]

              ### External
              - `[package]`: [what to import]

              ## Types/Interfaces to Use
              ```typescript
              // From [source]
              interface [Name] {
                [relevant fields]
              }
              ```

              ## Integration Points
              - Called by: [who will use this]
              - Calls: [what this will call]
              - Tests: [related test files]

              ## Implementation Notes
              - [Specific note 1]
              - [Specific note 2]
              ```

              ## Commit
              ```bash
              git add context/step-13-context.md
              git commit -m "context(step-13): gather implementation context"
              ```
          - id: execute
            status: pending
            prompt: |
              Implement the step following gherkin scenarios and context.

              ## Your Task
              ## Phase 5.3: Reference Documentation

              Create comprehensive reference docs:

              ### Tasks
              1. Create docs/reference/commands.md:
                 - All commands with full syntax
                 - All options/flags documented
                 - Examples for each command
                 - Common errors and solutions

              2. Create docs/reference/backlog-format.md:
                 - Complete YAML schema
                 - All fields explained
                 - Status transitions
                 - Example entries

              3. Create docs/reference/sign-format.md:
                 - How signs appear in CLAUDE.md
                 - Formatting conventions
                 - Origin tracking explained

              ### Success Criteria
              - Reference is comprehensive
              - Easy to find specific information
              - Code examples are copy-pasteable


              ## MUST READ BEFORE IMPLEMENTING
              Read these files in order:
              1. context/_shared-context.md (project patterns, conventions)
              2. context/sprint-plan.md (how this fits in sprint)
              3. artifacts/step-13-gherkin.md (scenarios to satisfy)
              4. context/step-13-context.md (specific patterns, imports)

              ## Implementation Rules

              ### Follow the Gherkin
              Your implementation MUST satisfy ALL gherkin scenarios.
              Each scenario has a verification command - mentally run it to check your work.

              ### Follow the Context
              - Use patterns from similar implementations
              - Import from specified modules
              - Implement required interfaces
              - Follow naming conventions

              ### Code Quality
              - Keep code simple and focused
              - Follow existing patterns exactly
              - No over-engineering or extra abstractions
              - Only implement what's needed for the scenarios

              ### Commits
              Make atomic commits for logical units:
              ```bash
              # After each logical piece
              git add [files]
              git commit -m "[type](step-13): [description]"
              ```

              Types: feat, fix, refactor, test, docs

              ## Implementation Checklist
              Before marking complete, verify:
              - [ ] All files from gherkin scenarios exist
              - [ ] Code follows patterns from context
              - [ ] Imports are correct
              - [ ] No TypeScript errors (run typecheck mentally)
              - [ ] Each scenario's verification should pass

              ## If Blocked
              If you encounter an issue that prevents completion:
              - Document the blocker clearly
              - Set status to needs-human
              - Do NOT leave partial/broken implementation
          - id: qa
            status: pending
            prompt: |
              Verify implementation against gherkin scenarios.

              ## Context
              Read: artifacts/step-13-gherkin.md (scenarios with verification commands)

              ## Step 1: Run Each Verification

              For EACH scenario in the gherkin file:
              1. Run the verification command
              2. Record the result: 1 (pass) or 0 (fail)
              3. If fail, capture the error output

              ## Step 2: Calculate Score

              Score = (passed scenarios) / (total scenarios)
              - Score = 1.0 (all pass) → PASS
              - Score < 1.0 (any fail) → FAIL

              ## Step 3: Generate QA Report

              Create: artifacts/step-13-qa-report.md

              ```markdown
              # QA Report: step-13

              ## Summary
              - Total Scenarios: [N]
              - Passed: [N]
              - Failed: [N]
              - Score: [X]/[N] = [percentage]%

              ## Verification Results

              | # | Scenario | Result | Details |
              |---|----------|--------|---------|
              | 1 | [Name] | PASS/FAIL | [output or error] |
              | 2 | [Name] | PASS/FAIL | [output or error] |
              ...

              ## Detailed Results

              ### Scenario 1: [Name]
              **Verification**: `[command]`
              **Exit Code**: [0 or N]
              **Output**:
              ```
              [actual output]
              ```
              **Result**: PASS / FAIL

              ### Scenario 2: [Name]
              ...

              ## Issues Found
              [If any failures, describe each issue]

              1. **[Scenario name]**: [What failed and why]

              ## Status: PASS / FAIL
              ```

              ## Step 4: Handle Outcome

              ### If ALL scenarios PASS (Score = 100%):
              1. Ensure report shows "Status: PASS"
              2. Commit the report:
                 ```bash
                 git add artifacts/step-13-qa-report.md
                 git commit -m "qa(step-13): all scenarios passed"
                 ```
              3. Mark phase as completed

              ### If ANY scenario FAILS (Score < 100%):
              You MUST inject fix phases. Do NOT just report and continue.

              1. Ensure report shows "Status: FAIL" with specific issues

              2. Find the PROGRESS.yaml file:
                 ```bash
                 PROGRESS_FILE=$(find .claude/sprints -name "PROGRESS.yaml" -type f 2>/dev/null | head -1)
                 echo "Found: $PROGRESS_FILE"
                 ```

              3. Inject fix and re-verify phases using yq:
                 ```bash
                 yq -i '
                   (.phases[] | select(.steps) | .steps[] | select(.status == "in-progress") | .phases) +=
                   [
                     {
                       "id": "fix",
                       "status": "pending",
                       "prompt": "Fix failing scenarios for step-13.\n\n## Context\nRead: artifacts/step-13-qa-report.md\n\n## Instructions\n1. Review each FAIL scenario\n2. Fix the implementation to make it pass\n3. Re-run the verification command to confirm\n4. Make atomic commits for each fix\n\n## After Fixing\nDo NOT mark as complete until ALL verifications pass."
                     },
                     {
                       "id": "reverify",
                       "status": "pending",
                       "prompt": "Re-verify all scenarios after fixes.\n\n## Instructions\nRe-run ALL verification commands from artifacts/step-13-gherkin.md\n\n## If ALL pass:\n- Update artifacts/step-13-qa-report.md with PASS status\n- Commit the updated report\n\n## If ANY still fail:\n- Update the QA report with new results\n- Inject another fix phase using yq\n- Loop continues until all pass"
                     }
                   ]
                 ' "$PROGRESS_FILE"
                 ```

              4. Mark current QA phase as failed:
                 ```bash
                 yq -i '
                   (.. | select(.id == "qa" and .status == "in-progress")) |=
                   (.status = "failed" | .error = "step-13 QA failed - see report - fix phase injected")
                 ' "$PROGRESS_FILE"
                 ```

              5. The sprint loop will now execute fix → reverify phases

              ## Important
              - EVERY scenario must pass for the step to be complete
              - Failed QA MUST inject fix phases, not just report
              - This creates a self-healing loop until all pass
          - id: verify
            status: pending
            prompt: |
              Final integration verification for the step.

              ## Your Task
              ## Phase 5.3: Reference Documentation

              Create comprehensive reference docs:

              ### Tasks
              1. Create docs/reference/commands.md:
                 - All commands with full syntax
                 - All options/flags documented
                 - Examples for each command
                 - Common errors and solutions

              2. Create docs/reference/backlog-format.md:
                 - Complete YAML schema
                 - All fields explained
                 - Status transitions
                 - Example entries

              3. Create docs/reference/sign-format.md:
                 - How signs appear in CLAUDE.md
                 - Formatting conventions
                 - Origin tracking explained

              ### Success Criteria
              - Reference is comprehensive
              - Easy to find specific information
              - Code examples are copy-pasteable


              ## Context
              Read: context/_shared-context.md (build commands)
              Read: artifacts/step-13-qa-report.md (should show PASS)

              ## Step 1: Build Verification
              Run the project build to ensure this step integrates:
              ```bash
              # Use commands from _shared-context.md, typically:
              npm run build
              npm run typecheck
              ```

              ## Step 2: Integration Check
              Verify this step works with the rest of the sprint:
              - Check imports resolve correctly
              - Verify no circular dependencies
              - Ensure types are compatible

              ## Step 3: Smoke Test
              If possible, manually verify the functionality:
              - Run the code path that uses this step's output
              - Check expected behavior matches gherkin scenarios

              ## Step 4: Final Commit
              If all verification passes:
              ```bash
              git add -A
              git status  # Check for any uncommitted changes
              # Only commit if there are changes
              git diff --cached --quiet || git commit -m "verify(step-13): integration verified"
              ```

              ## Outcome
              - If integration passes: Mark step as complete
              - If integration fails: Document the issue and set status to needs-human

              ## Important
              This is the final gate before moving to the next step.
              The step's gherkin scenarios already passed in QA.
              This phase ensures the step works in the broader context.
      - id: step-14
        prompt: |
          ## Phase 5.4: Final Polish and Testing

          Complete documentation and validate:

          ### Tasks
          1. Update CONCEPT.md:
             - Mark all phases as complete
             - Add link to docs/getting-started.md
             - Document known limitations
             - Add changelog section

          2. Verify documentation:
             - All internal links work
             - Code examples are tested
             - No placeholder text remains

          3. Run full workflow test:
             - Follow getting-started guide as new user
             - Extract from real session
             - Review and approve learnings
             - Apply to test CLAUDE.md
             - Verify signs appear correctly

          4. Update skills/managing-signs/SKILL.md:
             - Proper frontmatter with trigger keywords
             - Link to docs/ for user-facing content
             - Keep skill focused on LLM behavior

          ### Success Criteria
          - Documentation is complete and accurate
          - All commands have been tested via docs
          - Plugin is ready for use
        status: pending
        phases:
          - id: plan
            status: pending
            prompt: |
              Generate binary-verifiable gherkin scenarios for this step.

              ## Your Task
              ## Phase 5.4: Final Polish and Testing

              Complete documentation and validate:

              ### Tasks
              1. Update CONCEPT.md:
                 - Mark all phases as complete
                 - Add link to docs/getting-started.md
                 - Document known limitations
                 - Add changelog section

              2. Verify documentation:
                 - All internal links work
                 - Code examples are tested
                 - No placeholder text remains

              3. Run full workflow test:
                 - Follow getting-started guide as new user
                 - Extract from real session
                 - Review and approve learnings
                 - Apply to test CLAUDE.md
                 - Verify signs appear correctly

              4. Update skills/managing-signs/SKILL.md:
                 - Proper frontmatter with trigger keywords
                 - Link to docs/ for user-facing content
                 - Keep skill focused on LLM behavior

              ### Success Criteria
              - Documentation is complete and accurate
              - All commands have been tested via docs
              - Plugin is ready for use


              ## Shared Context
              Read: context/_shared-context.md (project patterns, conventions, commands)
              Read: context/sprint-plan.md (how this step fits in the sprint)

              ## Instructions
              Create 4-8 gherkin scenarios that, when ALL pass, prove the step is complete.
              Each scenario MUST have:
              1. Clear Given/When/Then structure
              2. An explicit verification command that returns exit code 0 on success
              3. Binary outcome: exactly 1 (pass) or 0 (fail)

              ## Gherkin Format
              Each scenario follows this exact structure:

              ```gherkin
              Scenario: [Descriptive name]
                Given [precondition or context]
                When [action taken]
                Then [expected outcome]

              Verification: `[shell command that exits 0 on success, non-zero on failure]`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ## Example Scenarios

              ### File Existence
              ```gherkin
              Scenario: Source file exists
                Given the project structure is set up
                When I check for the module file
                Then src/auth/service.ts exists

              Verification: `test -f src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### TypeScript Compilation
              ```gherkin
              Scenario: TypeScript compiles without errors
                Given the file src/auth/service.ts exists
                When I run the TypeScript compiler
                Then no compilation errors occur

              Verification: `npx tsc --noEmit src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Function Export
              ```gherkin
              Scenario: Login function is exported
                Given src/auth/service.ts exists
                When I check for the login export
                Then the function is publicly available

              Verification: `grep -q "export.*function login\|export.*const login\|export { login" src/auth/service.ts`
              Pass: Exit code = 0 → Score 1
              Fail: Exit code ≠ 0 → Score 0
              ```

              ### Test Execution
              ```gherkin
              Scenario: Unit tests pass
                Given tests exist in src/auth/service.test.ts
                When I run the test suite
                Then all tests pass

              Verification: `npm test -- --testPathPattern="auth/service" --passWithNoTests 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ### Lint Check
              ```gherkin
              Scenario: Code passes linting
                Given the implementation is complete
                When I run the linter
                Then no lint errors in new files

              Verification: `npm run lint -- src/auth/service.ts 2>&1; echo $?`
              Pass: Last line = 0 → Score 1
              Fail: Last line ≠ 0 → Score 0
              ```

              ## Output
              Create: artifacts/step-14-gherkin.md

              ```markdown
              # Gherkin Scenarios: step-14

              ## Step Task
              ## Phase 5.4: Final Polish and Testing

              Complete documentation and validate:

              ### Tasks
              1. Update CONCEPT.md:
                 - Mark all phases as complete
                 - Add link to docs/getting-started.md
                 - Document known limitations
                 - Add changelog section

              2. Verify documentation:
                 - All internal links work
                 - Code examples are tested
                 - No placeholder text remains

              3. Run full workflow test:
                 - Follow getting-started guide as new user
                 - Extract from real session
                 - Review and approve learnings
                 - Apply to test CLAUDE.md
                 - Verify signs appear correctly

              4. Update skills/managing-signs/SKILL.md:
                 - Proper frontmatter with trigger keywords
                 - Link to docs/ for user-facing content
                 - Keep skill focused on LLM behavior

              ### Success Criteria
              - Documentation is complete and accurate
              - All commands have been tested via docs
              - Plugin is ready for use


              ## Success Criteria
              All scenarios must pass (score = 1) for the step to be complete.
              Total scenarios: [N]
              Required score: [N]/[N]

              ---

              ## Scenario 1: [Name]
              [Full gherkin with verification as shown above]

              ---

              ## Scenario 2: [Name]
              ...

              [Continue for 4-8 scenarios]
              ```

              ## Commit
              ```bash
              git add artifacts/step-14-gherkin.md
              git commit -m "plan(step-14): define gherkin scenarios"
              ```
          - id: context
            status: pending
            prompt: |
              Gather step-specific context for implementation.

              ## Your Task
              ## Phase 5.4: Final Polish and Testing

              Complete documentation and validate:

              ### Tasks
              1. Update CONCEPT.md:
                 - Mark all phases as complete
                 - Add link to docs/getting-started.md
                 - Document known limitations
                 - Add changelog section

              2. Verify documentation:
                 - All internal links work
                 - Code examples are tested
                 - No placeholder text remains

              3. Run full workflow test:
                 - Follow getting-started guide as new user
                 - Extract from real session
                 - Review and approve learnings
                 - Apply to test CLAUDE.md
                 - Verify signs appear correctly

              4. Update skills/managing-signs/SKILL.md:
                 - Proper frontmatter with trigger keywords
                 - Link to docs/ for user-facing content
                 - Keep skill focused on LLM behavior

              ### Success Criteria
              - Documentation is complete and accurate
              - All commands have been tested via docs
              - Plugin is ready for use


              ## Shared Context
              Read: context/_shared-context.md (already has project-wide patterns)
              Read: artifacts/step-14-gherkin.md (scenarios to implement)

              ## Instructions
              Research the specific code areas this step will touch:

              1. **Related Existing Code**
                 - Find similar implementations to follow as patterns
                 - Identify modules this step will import from
                 - Note any interfaces/types to implement or extend

              2. **Dependencies**
                 - List imports needed from internal modules
                 - List any new external packages needed
                 - Check for peer dependencies or version constraints

              3. **Integration Points**
                 - How will this code be called/used?
                 - What modules will import from this step's output?
                 - Are there existing tests to extend?

              4. **Specific Patterns**
                 - Error handling patterns used in similar code
                 - Naming conventions for this area
                 - File organization patterns

              ## Output
              Create: context/step-14-context.md

              ```markdown
              # Step Context: step-14

              ## Task
              ## Phase 5.4: Final Polish and Testing

              Complete documentation and validate:

              ### Tasks
              1. Update CONCEPT.md:
                 - Mark all phases as complete
                 - Add link to docs/getting-started.md
                 - Document known limitations
                 - Add changelog section

              2. Verify documentation:
                 - All internal links work
                 - Code examples are tested
                 - No placeholder text remains

              3. Run full workflow test:
                 - Follow getting-started guide as new user
                 - Extract from real session
                 - Review and approve learnings
                 - Apply to test CLAUDE.md
                 - Verify signs appear correctly

              4. Update skills/managing-signs/SKILL.md:
                 - Proper frontmatter with trigger keywords
                 - Link to docs/ for user-facing content
                 - Keep skill focused on LLM behavior

              ### Success Criteria
              - Documentation is complete and accurate
              - All commands have been tested via docs
              - Plugin is ready for use


              ## Related Code Patterns

              ### Similar Implementation: [path]
              ```typescript
              // Key pattern to follow
              [relevant code snippet]
              ```

              ### Similar Implementation: [path]
              [continue as needed]

              ## Required Imports
              ### Internal
              - `[module]`: [what to import]

              ### External
              - `[package]`: [what to import]

              ## Types/Interfaces to Use
              ```typescript
              // From [source]
              interface [Name] {
                [relevant fields]
              }
              ```

              ## Integration Points
              - Called by: [who will use this]
              - Calls: [what this will call]
              - Tests: [related test files]

              ## Implementation Notes
              - [Specific note 1]
              - [Specific note 2]
              ```

              ## Commit
              ```bash
              git add context/step-14-context.md
              git commit -m "context(step-14): gather implementation context"
              ```
          - id: execute
            status: pending
            prompt: |
              Implement the step following gherkin scenarios and context.

              ## Your Task
              ## Phase 5.4: Final Polish and Testing

              Complete documentation and validate:

              ### Tasks
              1. Update CONCEPT.md:
                 - Mark all phases as complete
                 - Add link to docs/getting-started.md
                 - Document known limitations
                 - Add changelog section

              2. Verify documentation:
                 - All internal links work
                 - Code examples are tested
                 - No placeholder text remains

              3. Run full workflow test:
                 - Follow getting-started guide as new user
                 - Extract from real session
                 - Review and approve learnings
                 - Apply to test CLAUDE.md
                 - Verify signs appear correctly

              4. Update skills/managing-signs/SKILL.md:
                 - Proper frontmatter with trigger keywords
                 - Link to docs/ for user-facing content
                 - Keep skill focused on LLM behavior

              ### Success Criteria
              - Documentation is complete and accurate
              - All commands have been tested via docs
              - Plugin is ready for use


              ## MUST READ BEFORE IMPLEMENTING
              Read these files in order:
              1. context/_shared-context.md (project patterns, conventions)
              2. context/sprint-plan.md (how this fits in sprint)
              3. artifacts/step-14-gherkin.md (scenarios to satisfy)
              4. context/step-14-context.md (specific patterns, imports)

              ## Implementation Rules

              ### Follow the Gherkin
              Your implementation MUST satisfy ALL gherkin scenarios.
              Each scenario has a verification command - mentally run it to check your work.

              ### Follow the Context
              - Use patterns from similar implementations
              - Import from specified modules
              - Implement required interfaces
              - Follow naming conventions

              ### Code Quality
              - Keep code simple and focused
              - Follow existing patterns exactly
              - No over-engineering or extra abstractions
              - Only implement what's needed for the scenarios

              ### Commits
              Make atomic commits for logical units:
              ```bash
              # After each logical piece
              git add [files]
              git commit -m "[type](step-14): [description]"
              ```

              Types: feat, fix, refactor, test, docs

              ## Implementation Checklist
              Before marking complete, verify:
              - [ ] All files from gherkin scenarios exist
              - [ ] Code follows patterns from context
              - [ ] Imports are correct
              - [ ] No TypeScript errors (run typecheck mentally)
              - [ ] Each scenario's verification should pass

              ## If Blocked
              If you encounter an issue that prevents completion:
              - Document the blocker clearly
              - Set status to needs-human
              - Do NOT leave partial/broken implementation
          - id: qa
            status: pending
            prompt: |
              Verify implementation against gherkin scenarios.

              ## Context
              Read: artifacts/step-14-gherkin.md (scenarios with verification commands)

              ## Step 1: Run Each Verification

              For EACH scenario in the gherkin file:
              1. Run the verification command
              2. Record the result: 1 (pass) or 0 (fail)
              3. If fail, capture the error output

              ## Step 2: Calculate Score

              Score = (passed scenarios) / (total scenarios)
              - Score = 1.0 (all pass) → PASS
              - Score < 1.0 (any fail) → FAIL

              ## Step 3: Generate QA Report

              Create: artifacts/step-14-qa-report.md

              ```markdown
              # QA Report: step-14

              ## Summary
              - Total Scenarios: [N]
              - Passed: [N]
              - Failed: [N]
              - Score: [X]/[N] = [percentage]%

              ## Verification Results

              | # | Scenario | Result | Details |
              |---|----------|--------|---------|
              | 1 | [Name] | PASS/FAIL | [output or error] |
              | 2 | [Name] | PASS/FAIL | [output or error] |
              ...

              ## Detailed Results

              ### Scenario 1: [Name]
              **Verification**: `[command]`
              **Exit Code**: [0 or N]
              **Output**:
              ```
              [actual output]
              ```
              **Result**: PASS / FAIL

              ### Scenario 2: [Name]
              ...

              ## Issues Found
              [If any failures, describe each issue]

              1. **[Scenario name]**: [What failed and why]

              ## Status: PASS / FAIL
              ```

              ## Step 4: Handle Outcome

              ### If ALL scenarios PASS (Score = 100%):
              1. Ensure report shows "Status: PASS"
              2. Commit the report:
                 ```bash
                 git add artifacts/step-14-qa-report.md
                 git commit -m "qa(step-14): all scenarios passed"
                 ```
              3. Mark phase as completed

              ### If ANY scenario FAILS (Score < 100%):
              You MUST inject fix phases. Do NOT just report and continue.

              1. Ensure report shows "Status: FAIL" with specific issues

              2. Find the PROGRESS.yaml file:
                 ```bash
                 PROGRESS_FILE=$(find .claude/sprints -name "PROGRESS.yaml" -type f 2>/dev/null | head -1)
                 echo "Found: $PROGRESS_FILE"
                 ```

              3. Inject fix and re-verify phases using yq:
                 ```bash
                 yq -i '
                   (.phases[] | select(.steps) | .steps[] | select(.status == "in-progress") | .phases) +=
                   [
                     {
                       "id": "fix",
                       "status": "pending",
                       "prompt": "Fix failing scenarios for step-14.\n\n## Context\nRead: artifacts/step-14-qa-report.md\n\n## Instructions\n1. Review each FAIL scenario\n2. Fix the implementation to make it pass\n3. Re-run the verification command to confirm\n4. Make atomic commits for each fix\n\n## After Fixing\nDo NOT mark as complete until ALL verifications pass."
                     },
                     {
                       "id": "reverify",
                       "status": "pending",
                       "prompt": "Re-verify all scenarios after fixes.\n\n## Instructions\nRe-run ALL verification commands from artifacts/step-14-gherkin.md\n\n## If ALL pass:\n- Update artifacts/step-14-qa-report.md with PASS status\n- Commit the updated report\n\n## If ANY still fail:\n- Update the QA report with new results\n- Inject another fix phase using yq\n- Loop continues until all pass"
                     }
                   ]
                 ' "$PROGRESS_FILE"
                 ```

              4. Mark current QA phase as failed:
                 ```bash
                 yq -i '
                   (.. | select(.id == "qa" and .status == "in-progress")) |=
                   (.status = "failed" | .error = "step-14 QA failed - see report - fix phase injected")
                 ' "$PROGRESS_FILE"
                 ```

              5. The sprint loop will now execute fix → reverify phases

              ## Important
              - EVERY scenario must pass for the step to be complete
              - Failed QA MUST inject fix phases, not just report
              - This creates a self-healing loop until all pass
          - id: verify
            status: pending
            prompt: |
              Final integration verification for the step.

              ## Your Task
              ## Phase 5.4: Final Polish and Testing

              Complete documentation and validate:

              ### Tasks
              1. Update CONCEPT.md:
                 - Mark all phases as complete
                 - Add link to docs/getting-started.md
                 - Document known limitations
                 - Add changelog section

              2. Verify documentation:
                 - All internal links work
                 - Code examples are tested
                 - No placeholder text remains

              3. Run full workflow test:
                 - Follow getting-started guide as new user
                 - Extract from real session
                 - Review and approve learnings
                 - Apply to test CLAUDE.md
                 - Verify signs appear correctly

              4. Update skills/managing-signs/SKILL.md:
                 - Proper frontmatter with trigger keywords
                 - Link to docs/ for user-facing content
                 - Keep skill focused on LLM behavior

              ### Success Criteria
              - Documentation is complete and accurate
              - All commands have been tested via docs
              - Plugin is ready for use


              ## Context
              Read: context/_shared-context.md (build commands)
              Read: artifacts/step-14-qa-report.md (should show PASS)

              ## Step 1: Build Verification
              Run the project build to ensure this step integrates:
              ```bash
              # Use commands from _shared-context.md, typically:
              npm run build
              npm run typecheck
              ```

              ## Step 2: Integration Check
              Verify this step works with the rest of the sprint:
              - Check imports resolve correctly
              - Verify no circular dependencies
              - Ensure types are compatible

              ## Step 3: Smoke Test
              If possible, manually verify the functionality:
              - Run the code path that uses this step's output
              - Check expected behavior matches gherkin scenarios

              ## Step 4: Final Commit
              If all verification passes:
              ```bash
              git add -A
              git status  # Check for any uncommitted changes
              # Only commit if there are changes
              git diff --cached --quiet || git commit -m "verify(step-14): integration verified"
              ```

              ## Outcome
              - If integration passes: Mark step as complete
              - If integration fails: Document the issue and set status to needs-human

              ## Important
              This is the final gate before moving to the next step.
              The step's gherkin scenarios already passed in QA.
              This phase ensures the step works in the broader context.
  - id: final-qa
    status: pending
    prompt: |
      Comprehensive Quality Assurance for the entire sprint.

      ## Context
      Read: context/_shared-context.md for build/test commands
      Read: context/sprint-plan.md for success criteria

      ## Step 1: Full Build Verification
      Run ALL build checks:
      ```bash
      # Identify commands from _shared-context.md, typically:
      npm run build
      npm run typecheck
      npm run lint
      ```

      Record each result in the QA report.

      ## Step 2: Complete Test Suite
      Run the full test suite:
      ```bash
      npm test
      ```

      Record test results and any failures.

      ## Step 3: Integration Verification
      Verify all steps work together:
      - Check that modules properly import each other
      - Verify no circular dependencies introduced
      - Test end-to-end flow if applicable

      ## Step 4: Regression Check
      Compare against main branch:
      ```bash
      git diff main...HEAD --stat
      ```

      Verify:
      - No unintended changes to existing functionality
      - All modified files are expected per sprint-plan.md
      - No temporary/debug code left in

      ## Step 5: Review All Step QA Reports
      Read all artifacts/step-*-qa-report.md files
      - Verify all steps show PASS status
      - Consolidate any warnings or notes

      ## Step 6: Generate Sprint QA Report
      Create: artifacts/sprint-qa-report.md

      ```markdown
      # Sprint QA Report: 2026-01-18_m42-signs-implementation

      ## Build Verification
      | Check | Result | Output |
      |-------|--------|--------|
      | Build | PASS/FAIL | [summary] |
      | TypeCheck | PASS/FAIL | [summary] |
      | Lint | PASS/FAIL | [summary] |

      ## Test Suite
      | Metric | Value |
      |--------|-------|
      | Tests Run | [count] |
      | Passed | [count] |
      | Failed | [count] |
      | Skipped | [count] |

      ## Integration Verification
      - [ ] Modules import correctly
      - [ ] No circular dependencies
      - [ ] End-to-end flow works

      ## Step QA Summary
      | Step | Status | Notes |
      |------|--------|-------|
      | step-0 | PASS | [brief note] |
      | step-1 | PASS | [brief note] |
      ...

      ## Regression Analysis
      [Summary of changes vs main branch]

      ## Issues Found
      [List any issues, or "None"]

      ## Overall Status: PASS / FAIL
      ```

      ## Step 7: Handle Outcome

      ### If PASS:
      - Commit the QA report:
        ```bash
        git add artifacts/sprint-qa-report.md
        git commit -m "qa: sprint-level verification passed"
        ```

      ### If FAIL:
      - Document specific failures in the report
      - Set status to needs-human with details of what failed
      - The sprint cannot proceed to summary/PR until issues are resolved
  - id: summary
    status: pending
    prompt: |
      Generate sprint summary deliverable for user review.

      ## Context
      Read: context/sprint-plan.md for original goals
      Read: artifacts/sprint-qa-report.md for verification results
      Read: All artifacts/step-*-qa-report.md for step details

      ## Step 1: Collect Commit History
      ```bash
      git log main..HEAD --oneline --no-decorate
      ```

      ## Step 2: Collect File Changes
      ```bash
      git diff main..HEAD --stat
      ```

      ## Step 3: Generate Sprint Summary
      Create: artifacts/sprint-summary.md

      ```markdown
      # Sprint Summary: 2026-01-18_m42-signs-implementation

      ## What Was Accomplished

      ### Step 0: [Step title]
      - [Key accomplishment 1]
      - [Key accomplishment 2]
      **Files**: [list of files created/modified]

      ### Step 1: [Step title]
      ...

      ## Files Changed
      | File | Change Type | Description |
      |------|-------------|-------------|
      | [path] | Created/Modified/Deleted | [brief description] |

      ## Commits Made
      | Hash | Message |
      |------|---------|
      | [short hash] | [commit message] |

      ## Test Coverage
      [Summary from QA report]

      ## Verification Status
      - Build: PASS
      - TypeCheck: PASS
      - Lint: PASS
      - Tests: [X/Y passed]
      - Integration: PASS

      ## Known Issues / Follow-ups
      [List any, or "None identified"]

      ## Sprint Statistics
      - Steps completed: [X/Y]
      - Total commits: [count]
      - Files changed: [count]
      - Lines added: [count]
      - Lines removed: [count]
      ```

      ## Step 4: Commit Summary
      ```bash
      git add artifacts/sprint-summary.md
      git commit -m "docs: add sprint summary"
      ```
  - id: pr-create
    status: completed
    prompt: "Push the sprint branch and create a pull request.\n\n## Context\nRead: artifacts/sprint-summary.md for PR body content\nRead: artifacts/sprint-qa-report.md for verification checklist\n\n## Step 1: Ensure All Changes Committed\n```bash\ngit status\n```\nIf there are uncommitted changes, commit them appropriately.\n\n## Step 2: Push Branch\n```bash\ngit push -u origin sprint/2026-01-18_m42-signs-implementation\n```\n\n## Step 3: Create Pull Request\nUse the sprint summary to create a well-structured PR:\n\n```bash\ngh pr create \\\n  --title \"Sprint: 2026-01-18_m42-signs-implementation\" \\\n  --body \"$(cat <<'EOF'\n## Summary\n[Extract key points from sprint-summary.md]\n\n## Changes\n[List of major changes from summary]\n\n## Verification Checklist\n- [x] Build passes\n- [x] TypeCheck passes\n- [x] Lint passes\n- [x] Tests pass\n- [x] Integration verified\n- [x] No regressions\n\n## Test Results\n[Extract from sprint-qa-report.md]\n\n## Files Changed\n[File list from summary]\n\n---\nFull details in `artifacts/sprint-summary.md`\n\n\U0001F916 Generated with Sprint Workflow\nEOF\n)\"\n```\n\n## Step 4: Output PR URL\nCapture and display the PR URL:\n```bash\ngh pr view --json url -q '.url'\n```\n\n## Output\n- Branch pushed to remote\n- Pull request created\n- PR URL displayed for user\n"
    steps:
      - phases:
          - started-at: "2026-01-18T02:30:21Z"
current:
  phase: 1
  step: 3
  sub-phase: 2
stats:
  started-at: "2026-01-17T23:59:15Z"
  total-phases: 80
  completed-phases: 0
  total-steps: 15
  completed-steps: 0
  max-iterations: 1000000
  current-iteration: 6
  completed-at: "2026-01-18T17:35:21Z"
  elapsed: 17:36:06
