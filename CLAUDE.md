# Claude Code Configuration - m42-claude-plugins

## Learnings

- **Delegate technical planning to specialized commands**: When using `/m42-meta-toolkit:create-command`, `/m42-meta-toolkit:create-skill`, or similar, describe the issue and goal only. Don't prescribe implementation details - that's what the command is specialized for.

- **Use `plugin-development` workflow for sprints**: This is the standard workflow for this project. It uses TDD (RED/GREEN/REFACTOR) with operator-driven subagent delegation, includes documentation and tooling updates, and runs in isolated worktrees for parallel development.

- **Version bump decisions require analyzing change nature, not just counting commits**: When deciding version bumps (MAJOR.MINOR.PATCH), it's tempting to just count commits or look at commit messages. But semantic versioning requires understanding the nature of changes: Breaking changes → MAJOR, New features → MINOR, Bug fixes and patches → PATCH. Solution: Follow systematic version bump analysis pattern: 1) Read sprint context (SPRINT.yaml title and description, step descriptions), 2) Analyze actual changes using git diff to see code modifications and categorize as bug fixes (PATCH), new features (MINOR), breaking API changes (MAJOR), or internal refactoring (usually PATCH), 3) Determine compatibility (backwards compatible? breaks APIs? adds new public functionality?), 4) Choose version by prioritizing the highest severity change level and documenting rationale. This structured approach ensures version numbers accurately reflect change impact.

- **Follow systematic discovery sequence for plugin codebases**: When researching a plugin's architecture, use this discovery sequence: 1) Read root package.json for build/test commands, 2) Read plugin.json for command/skill/agent registry, 3) Read main README.md for architecture overview, 4) Read specific command .md files for workflows, 5) Read subagent .md files for delegation patterns, 6) Read skill SKILL.md files for domain knowledge. This follows the dependency chain: high-level → implementation → domain.

- **Delegate broad codebase exploration to Task(Explore) subagent**: Use Task tool with subagent_type="Explore" for tasks like "Understand project structure", "Find all X in the codebase", "How does Y work?", or initial research before creating artifacts. The Explore agent returns a focused summary that informs next steps without polluting context with dozens of file reads.

- **Project test directory structure**: Test structure is: `tests/` (root) for integration tests that span plugins, `plugins/*/tests/` for plugin-specific unit tests, and `plugins/*/e2e/` for end-to-end tests for specific plugins. Integration tests use shell scripts (.sh) and test cross-plugin workflows.

- **Bash scenario test pattern**: This project uses Bash scenario tests (located in tests/*.sh) with a SCORE/TOTAL scoring pattern. Each test checks multiple scenarios, increments SCORE on pass, and exits 0 if SCORE == TOTAL. Tests use `set -euo pipefail` for safety and include file existence, frontmatter validation, and required content checks.

- **Operator pattern separates orchestration from domain logic**: Commands can become bloated (400+ lines) when they mix orchestration logic with domain knowledge. Use the operator pattern - commands contain only argument parsing, preflight checks, Task() orchestration, and output aggregation. All domain logic moves to skills that subagents invoke with Skill(). This enables parallel subagent processing while keeping domain knowledge centralized and reusable.

- **Write tool requires Read before overwriting existing files**: When using Write tool to overwrite an existing file, forgetting to Read it first causes an error: "File has not been read yet. Read it first before writing to it." Always Read the file first before calling Write to overwrite it. The workflow should be: 1) Glob or check if file exists, 2) Read the existing file to load its content into context, 3) Write the new content to overwrite it. This is a safety mechanism to prevent accidental overwrites without seeing current content.

- **Delegate skill creation to creating-skills skill**: When asked to create a skill, invoke the creating-skills skill via `Skill(skill="m42-meta-toolkit:creating-skills", args="Create [skill-name] skill at [path]...")`. The skill handles: skill vs command vs subagent validation, SKILL.md structure and frontmatter, reference file organization and frontmatter, and consistent formatting. This ensures consistency across all skill artifacts.

- **Extract domain logic from commands into skills for subagent reuse**: Commands mixing orchestration (argument parsing, Task() calls, result aggregation) with domain knowledge (taxonomies, quality criteria, extraction patterns) become bloated (400+ lines) and prevent domain knowledge reuse. Apply the operator pattern: Commands contain only orchestration, Skills contain all domain knowledge, and Subagents invoke skills via Skill() tool. This enables parallel subagent processing (each loads the same skill), domain knowledge reuse across multiple subagents, and smaller focused command files (~150 lines).

- **Touch command bypasses Write tool file existence requirement**: Write tool requires files to exist and be read before writing. Use `Bash(touch <filepath>)` to create empty file, optionally followed by `Read(<filepath>)` to load into context, then use Write tool. Alternatively, for files needing complete content from scratch, use `Bash(cat > <file> << 'EOF'...EOF')` heredoc pattern which bypasses the read requirement entirely.

- **Bash with heredoc creates files without Read requirement**: For creating new files with complete content known upfront, use Bash with heredoc pattern - `cat > <filepath> << 'EOF'...content...EOF` or `cat > <filepath> << 'DELIMITER'...content...DELIMITER`. Use single quotes around delimiter (`'EOF'`) to prevent shell expansion. This bypasses Write tool's read requirement and works in one step.

- **Execute step reveals registration issues invisible during creation**: The execute/test phase is critical for discovering integration issues that creation phases cannot detect: missing plugin registry entries, incorrect subagent naming conventions, skill trigger patterns not matching invocation, tool permission mismatches. Cannot rely on successful artifact creation as evidence of working implementation. Must include end-to-end execution test that exercises all Task() and Skill() invocations. For operator pattern refactors, this means testing the complete multi-stage workflow with real input. Consider adding plugin validation command that checks .md files against plugin.json registry and reports unregistered artifacts.

- **Task() error messages include list of available registered agents**: When debugging Task() invocation failures: 1) Check the "Available agents:" list in the error message, 2) Verify if other agents from same plugin are registered (indicates plugin is loaded), 3) Use this to distinguish between plugin loading issues vs specific agent registration gaps. The available agents list is a diagnostic tool for understanding registration state. Seeing an existing plugin agent in the list confirms plugin.json is being read and helps isolate the issue to specific unregistered artifacts rather than plugin-wide loading failure.

- **Preflight checks verify script dependencies before workflow execution**: Preflight checks should validate external dependencies (scripts, binaries, config files) that workflows rely on. Use `test -f` for file existence. Echo warnings for optional dependencies (fallback behavior exists). Exit with error for required dependencies (no workaround available). For required dependencies, use pattern: `test -f <path> || { echo "Error: <file> not found"; exit 1; }`

- **Edit tool race condition with file watchers and formatters**: When using Edit tool multiple times on files in quick succession, formatters or linters watching those files may modify them between read and write operations, causing error "File has been modified since read, either by the user or by a linter. Read it again before attempting to write it." This occurs particularly with documentation files (.md) in directories with active file watchers. Solution: If Edit fails with this error, re-read the file and retry the edit. The file content is the same, just re-read to satisfy the safety check.

- **Grep-then-edit pattern for systematic feature removal**: When removing deprecated features from codebase or documentation, use this pattern: 1) Grep across all relevant files for the feature name using regex patterns to capture variations, 2) Read matching files to understand usage context, 3) Edit files to remove sections while preserving related but distinct features, 4) Verify removal with additional targeted greps, 5) Commit changes in logical groupings (by area or category). This ensures complete removal while preventing accidental deletion of similarly-named active features.

- **Commit documentation changes by category for clear history**: When updating documentation across multiple areas, create separate commits per documentation category using conventional commit format: "docs(category): description". Categories include: getting-started, user-guide, reference, concepts, etc. This creates clear git history showing which documentation areas were updated, makes changes easier to review, and enables targeted reverts if needed. Each commit should be scoped to files within that category.

- **Use systematic subagent review for multi-artifact validation**: When a feature spans multiple commands and skills, manual review is error-prone. Need to ensure no artifacts contain stale references. Spawn subagents to review all commands and all skills in parallel. Each subagent checks for deprecated patterns and returns status (unchanged vs needs update). Aggregate results to identify files needing updates. This parallelizes review and ensures completeness.

- **Remove deprecated features from all documentation layers systematically**: When removing a feature from a system, documentation exists at multiple layers (user-facing docs like USER-GUIDE.md and getting-started, reference docs like schema specifications and API docs, skill references that AI reads when helping users). Each layer must be updated to prevent confusion and ensure consistency. Update documentation in this order: 1) Reference documentation - Remove from schema specs, API docs, 2) User guides - Remove examples, tutorials, how-to sections, 3) Getting started - Remove feature mentions from overview/index, 4) Skill references - Remove from AI guidance documents. Use separate commits for each layer to track what was changed where. Example pattern from m42-sprint depends-on removal: docs(reference): remove deprecated feature from reference docs, docs(user-guide): remove deprecated feature, docs(getting-started): remove deprecated feature, docs(creating-sprints): sync with implementation.

- **Track documentation removal systematically with line counts per file**: When removing deprecated features across multiple documentation files, it's easy to miss files or sections. Need a systematic way to verify complete removal and communicate scope of changes. Use structured tracking in commit messages and summary artifacts: 1) Commit messages include per-file line counts: "docs(reference): remove deprecated feature" with "- sprint-yaml-schema.md: Remove field from table (38 lines), - progress-yaml-schema.md: Remove interfaces (149 lines), - api.md: Remove entire section (298 lines)"; 2) Create summary artifact with table showing File, Lines Removed, What Was Removed; 3) Track totals by category (Reference docs: 494 lines removed, User guides: 237 lines removed, Getting started: 1 line removed). This provides clear verification of completeness and helps with changelog generation.

- **Use separate git commits for each documentation layer when removing features**: Documentation updates span multiple concerns (reference, user guide, getting started). Bundling all changes into one commit makes it hard to review what changed in each layer, revert specific documentation updates if needed, generate accurate changelogs, and understand scope of changes. When updating documentation for a feature removal/change, create separate commits for each documentation layer: docs(reference): remove deprecated feature from reference docs, docs(user-guide): remove deprecated feature, docs(getting-started): remove deprecated feature, docs(skill-name): sync with implementation. Order commits from technical → user-facing: Reference docs first (schema, API), User guides second (tutorials, how-tos), Getting started last (overview, index), Skills last (AI guidance). Include specific file changes in each commit: Reference commit touches schema.md, api.md, interfaces.md; User guide commit touches USER-GUIDE.md, guides/*.md. This enables easier code review (review one layer at a time), selective reverts if needed, better git log clarity, and accurate changelog generation.
